# Redis学习总结
>> [Redis官网](https://redis.io/)
>> [Redis中文官网](http://www.redis.cn/)
>> [Redis 教程](https://www.runoob.com/redis/redis-tutorial.html)
>> [Redis 高级教程](http://www.shouce.ren/api/view/a/6229)
>> [参考书籍：Redis开发与运维](https://www.baidu.com)
>> [《Redis开发与运维》勘误列表](https://cachecloud.github.io/2017/02/17/%E3%80%8ARedis%E5%BC%80%E5%8F%91%E4%B8%8E%E8%BF%90%E7%BB%B4%E3%80%8B%E5%8B%98%E8%AF%AF/)
>> [参考书籍：Redis深度历险：核心原理与应用实践](https://www.baidu.com)
>> [Redis 3.2.8 源码剖析注释](https://blog.csdn.net/men_wen/category_9268758.html)
>> [Jedis源码](https://github.com/redis/jedis)
>> [Jedis源码分析](https://blog.csdn.net/liuqinen/article/details/104008793)
>> [CacheCloud-Redis云管理平台](https://github.com/sohutv/cachecloud)
## 一.Redis
[Redis的最常被问到知识点总结](https://www.cnblogs.com/Young111/p/11518346.html)
[Redis 数据结构与对象编码 (Object Encoding)](https://www.cnblogs.com/buttercup/p/13853114.html)
[Redis三种特殊类型](https://www.cnblogs.com/zoe-zyq/p/13838575.html)
[一文读懂Redis常见对象类型的底层数据结构](https://www.cnblogs.com/chentianming/p/13838347.html)
[深度长文整理-Redis进阶](https://www.cnblogs.com/ZhuChangwu/p/13697951.html)
### 0.redis安装登录
[Redis基础安装与简单使用](https://www.cnblogs.com/ZhuChangwu/p/11150535.html)
[Redis make编译报错解决方法](https://blog.csdn.net/R_s_x/article/details/99732320)
[linux安装redis make编译报错解决方法](https://blog.csdn.net/yangqjiayou/article/details/52231507)
[ubuntu安装redis时遇到的fatal error: stdlib.h](https://blog.csdn.net/weixin_37551036/article/details/104094618)
[Linux安装Redis-6.0.6](https://blog.csdn.net/Mr_YeShaoFei/article/details/107686607)
```markdown
>> redis服务器指定配置文件启动 /usr/local/redis/src/redis-server /usr/local/redis/etc/redis.conf
>> redis服务器指定端口启动 redis-server --port 6830
>> redis客户端连接(交互式) redis-cli -h 127.0.0.1 -p 6379
>> redis客户端连接(命令式) redis-cli -h 127.0.0.1 -p 6379 get hello 直接获取命令的返回结果
    (如果没有-h参数，那么默认连接127.0.0.1；如 果没有-p，那么默认6379端口，也就是说如果-h和-p都没写就是连接 127.0.0.1：6379这个Redis实例)
>> 停止Redis服务 redis-cli shutdown 可以在后面指定一个参数，nosave|save表示在关闭前是否生产持久化文件
```
### Redis一些终端命令
```markdown
插入key&value的键值对：set hello world
插入列表类型的键值对：rpush mylist a b c d e f g
获取所有key的value值：keys *
获取指定前缀的key: keys abc:*
删除指定前缀的key：keys abc:*|xargs DEL
获取键的总数： dbsize (dbsize不是遍历所有的键，而是直接获取键总数 ，时间复杂度为O(1))
检查键是否存在：exists keyname
删除键：del keyname  删除一个或者多个 name | name1 name2 name3 ....
设置键过期：expire key seconds  expire hello 10 键hello在10秒后过期 (返回值有三种：大于0的数：键剩余过期时间、-1：键没有设置过期时间、-2键不存在)
    expireat key timestamp：键在秒级时间戳timestamp后过期，pexpire key milliseconds：键在milliseconds毫秒后过期，pexpireat key milliseconds-timestamp键在毫秒级时间戳timestamp后过期。
查看键的过期时间：ttl keyname   ttl hello
查看键的数据类型：type keyname 键存在返回none
键重命名：rname key newkey 会强行覆盖rename，renamenx命令，确保只有newKey不存在的时候才被覆盖。
随机返回一个键：randomkey
迁移键：move、dump+restore、migrate三组迁移键的方法，它们的实现方式以及 使用的场景不太相同。move key db,dump key,restore key ttl value
遍历键:1.全量遍历键 keys pattern 2.渐进式遍历 scan cursor [match pattern] [count number]
获取信息指令：> info  # 获取所有信息 > info memory # 获取内存相关信息 > info replication # 获取复制相关信息
    > info server # 获取服务器运行信息 > info clients # 获取客户端信息 > info persistence 获取持久化信息
    > info cpu # 获取CPU信息 > info cluster # 获取集群信息 >info keyspace # 获取键值对统计数量信息
    > redis-cli info stats |grep ops # 每秒执行多少次指令
```
### Redis JavaAPI
```markdown
//1. 生成一个Jedis对象，这个对象负责和指定Redis实例进行通信
            jedis = new Jedis("192.168.101.222", 6379);
            //Jedis jedis = new Jedis("192.168.101.222", 6379,客户端连接超时时间,客户端读写超时时间);
            //2. jedis执行set操作
            String set = jedis.set("hello", "world");
            //输出结果：ok
            System.out.println(set);
            System.out.println("------");
            //3. jedis执行get操作, value="world"
            //输出结果：world
            String hello = jedis.get("hello");
            System.out.println(hello);
// Java StringRedisTemplate 根据key前缀批量删除key
    Set<String> keys = redisTemplate.keys("前缀字符串" + "*");//根据指定的key前缀 + "*"（* 号一定要有），查询出所有匹配到的key
    redisTemplate.delete(keys);//调用StringRedisTemplate的delete方法，把当前获取到的指定前缀key的集合传进去
```
#### JedisPool
```java
//用try-with-resource语句来保护Jedis对象。因为doSomething方法抛出了异常的话，从连接池中拿出来的Jedis对象将无法归还给连接池。造成阻塞。
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;
public class JedisTest {
    public static void main(String[] args) {
        JedisPool pool = new JedisPool();
        //Jedis jedis = pool.getResource(); // 拿出 Jedis 链接对象
        //doSomething(jedis);
        //jedis.close(); // 归还链接
        try(Jedis jedis = pool.getResource()){ // 用完自动close()
            doSomething(jedis);
        }
    }
    private static void doSomething(Jedis jedis) {
        // code it here
    } 
}
```
#### JedisPool
```java
//用try-with-resource语句来保护Jedis对象。因为doSomething方法抛出了异常的话，从连接池中拿出来的Jedis对象将无法归还给连接池。造成阻塞。
import redis.clients.jedis.Jedis;
import redis.clients.jedis.JedisPool;
interface CallWithJedis {
    public void call(Jedis jedis);
}
class RedisPool {
    private JedisPool pool;
    public RedisPool() {
        this.pool = new JedisPool();
    }
    public void execute(CallWithJedis caller) {
        try (Jedis jedis = pool.getResource()) {
        caller.call(jedis);
        }
    }
public class JedisTest {
    public static void main(String[] args) {
        RedisPool redis = new RedisPool();
        redis.execute(new CallWithJedis() {
            @Override
            public void call(Jedis jedis) {
            // do something with jedis
            }
        });
        // 使用Lambda表达式简化
        // redis.execute(jedis->{ // do something with jedis });
    } 
}
```
### 1.什么是Redis&Reids的特点【5+】
```markdown
Redis是一个基于内存的高性能key-value分布式内存数据库,基于内存运行,并支持持久化的Nosql数据库。 
Redis本质上是一个Key-Value类型的内存数据库，整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。
    因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过10万次读写操作，是已知性能最快的Key-ValueDB。
    Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像memcached只能保存1MB的数据，
    因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。
    另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一个功能加强版的memcached来用。
**Redis的主要缺点**是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。
为什么redis需要把所有数据放到内存中?　
    Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。
    所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。
    如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。
为什么Redis使用单线程模 型会达到每秒万级别的处理能力呢？
    第一，纯内存访问，Redis将所有数据放在内存中，内存的响应时长大 约为100纳秒，这是Redis达到每秒万级别访问的重要基础。
    第二，非阻塞I/O，Redis使用epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间。
    第三，单线程避免了线程切换和竞态产生的消耗。
```
### 2.Redis优势 【5+】
[硬核！15张图解Redis为什么这么快](https://www.cnblogs.com/caoyier/p/13896319.html)
```markdown
(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 
    redis是单线程，快的原因：
    ​ 1）完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，优势就是查找和操作的时间复杂度都是O(1)；
    ​ 2）数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
    ​ 3）采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
    ​ 4）使用多路I/O复用模型，一个线程处理多个IO流。非阻塞IO；
    ​ 5）使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；
(2) 支持丰富数据类型，支持string，list，set，sorted set，hash 
    1）String
    常用命令：set/get/decr/incr/mget等；
    应用场景：String是最常用的一种数据类型，普通的key/value存储都可以归为此类；
    实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr、decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。
    2）Hash
    常用命令：hget/hset/hgetall等
    应用场景：我们要存储一个用户信息对象数据，其中包括用户ID、用户姓名、年龄和生日，通过用户ID我们希望获取该用户的姓名或者年龄或者生日；
    实现方式：Redis的Hash实际是内部存储的Value为一个HashMap，并提供了直接存取这个Map成员的接口。如图所示，Key是用户ID, value是一个Map。
    这个Map的key是成员的属性名，value是属性值。这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field), 
    也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据。当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存
    会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，这时对应的value的redisObject的encoding为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。
    3）List
    常用命令：lpush/rpush/lpop/rpop/lrange等；
    应用场景：Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现；
    实现方式：Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。
    4）Set
    常用命令：sadd/spop/smembers/sunion等；
    应用场景：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，
    set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的；
    实现方式：set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。
    5）Sorted Set
    常用命令：zadd/zrange/zrem/zcard等；
    应用场景：Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，
    并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。
    实现方式：Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，
    排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。  
(3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 
(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除。
(5) 持久化和主从复制，高可用和分布式
```
### 3.redis适用于的场景【5+】
```markdown
Redis最适合所有数据in-momory的场景，如：
（1）、会话缓存（Session Cache）
　　最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。
（2）、全页缓存（FPC）
　　除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。
（3）、队列
　　Reids在内存存储引擎领域的一大优点是提供list和set操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对list的push/pop操作。
　　如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。
    例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。
（4）、排行榜/计数器
　　Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，
    Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：
　　当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：
　　ZRANGE user_scores 0 10 WITHSCORES
　　Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。
（5）、发布/订阅
　　最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。消息队列系统
```
### 4.redis的5种常用数据结构，及其实现原理【10+】
```markdown
Redis主要有5种数据类型，包括String，List，Set，Zset，Hash，BitMap。可以通过终端命令查询内部编码：object encoding keyname
类型	       存储值	        内部编码                应用场景                 终端命令
String	字符串、整数、浮点数 raw/int/embstr	    简单的键值对缓存             set key value
List	  列表	          linkedlist/ziplist   存储列表型数据结构，例如：评论列表、商品列表 lpush key v1 v2 v3 ...
Set	      无序集合	      hashtable/intset    适合交集、并集、查集操作，例如朋友关系 sadd key values
Zset	 有序集合	      skiplist/ziplist      去重后排序，适合排名场景
Hash	   哈希	           hashtable/ziplist    结构化数据，比如存储对象  hset key filed value
```
#### 1.String字符串终端命令、内部编码及应用场景
```markdown
String字符串:字符串类型是Redis最基础的数据结构，首先键都是字符串类型，而且其他几种数据结构都是在字符串类型基础上构建的，
    经常使用的set key value命令就是字符串。常用在缓存、计数、共享Session、限速等。
    字符串类型的值实际可以是字符串（简单的字符串、复杂的字符串（例如JSON、XML））、数字 （整数、浮点数），甚至是二进制（图片、音频、视频），但是值最大不能 超过512MB。
    常用终端命令：
        （1）设置值 set key value [ex seconds] [px milliseconds] [nx|xx] 
            ex seconds：为键设置秒级过期时间。
            px milliseconds：为键设置毫秒级过期时间。
            nx：键必须不存在，才可以设置成功，用于添加。
            xx：与nx相反，键必须存在，才可以设置成功，用于更新。
            除了set选项，Redis还提供了setex和setnx两个命令，它们的作用和ex和nx选项是一样的。
        （2）获取值 get key
        （3）批量设置值 mset key value [key value ...]
        （4）批量获取值 mget key [key ...]
        （5）计数 incr key incr命令用于对值做自增操作，值不是整数，返回错误。值是整数，返回自增后的结果。·键不存在，按照值为0自增，返回结果为1。
            除了incr命令，Redis提供了decr（自减）、incrby（自增指定数字）、 decrby（自减指定数字）、incrbyfloat（自增浮点数）
            decr key ，incrby key increment ，decrby key decrement ，incrbyfloat key increment
    不常用命令：
        （1）追加值 append key value append可以向字符串尾部追加值，例如：append key world
        （2）字符串长度 strlen key 例如，当前值为redisworld，所以返回值为10。
        （3）设置并返回原值 getset key value getset和set一样会设置值，但是不同的是，它同时会返回键原来的值。
        （4）设置指定位置的字符 setrange key offeset value
        （5）获取部分字符串 getrange key start end start和end分别是开始和结束的偏移量，偏移量从0开始计算
字符串类型的内部编码有3种： 
    ·int：8个字节的长整型。 
    ·embstr：小于等于44个字节的字符串。 
    ·raw：大于44个字节的字符串。 
    Redis会根据当前值的类型和长度决定使用哪种内部编码实现。可以通过终端命令查询内部编码：object encoding keyname
应用场景：1.缓存功能，2.计数，3.共享session，4.限速（限制用户每分钟获取验证码的频率）
数据结构：
    struct SDS<T>{
        T capacity; // 数组容量
        T len;// 数组长度
        byte flags;// 特殊标识位
        byte[] content;// 数组内容
    }
    // 字符串扩容 类似于ArrayList
    sds sdscatlen(sds s,const void *t,size_t len){
        size_t curlen = sdslen(s);//原字符串长度
        s = sdsMakeRoomFor(s,len);
        if(s==NULL) return NULL;// 内存不足
        memcpy(s+curlen,t,len);// 追加目标字符串的内容到字节数组中
        sdssetlen(s,curlen+len); //设置追加后的长度值
        s[curlen+len] = '\0';// 让字符串以'\0'结尾
        return s;
    }
```
#### 2.Hash哈希终端命令、内部编码及应用场景
```markdown
Hash哈希:在Redis中，哈希类型是指键值本身又是一个键值对结构，哈希可以用来存放用户信息，比如实现购物车。
    常用命令：
        （1）设置值 hset key field value   hset user:1 name tom 如果设置成功会返回1，反之会返回0。
            Redis提供了hsetnx命令，它们的关系就像set和setnx命令一样，只不过作用域由键变为field。
        （2）获取值 hget key field   hget user:1 name 获取user：1的name域（属性）对应的值
        （3）删除field hdel key field [field ...] hdel会删除一个或多个field，返回结果为成功删除field的个数
        （4）计算field个数 hlen key
        （5）批量设置或获取field-value hmget key field [field ...] hmset key field value [field value ...]
        （6）判断field是否存在 hexists key field
        （7）获取所有field hkeys key
        （8）获取所有value hvals key
        （9）获取所有的field-value hgetall key
        （10）hincrby hincrbyfloat hincrby和hincrbyfloat，就像incrby和incrbyfloat命令一样，但是它们的作 用域是filed。
        （11）计算value的字符串长度（需要Redis3.2以上） hstrlen key field
哈希类型的内部编码有两种：
    ziplist（压缩列表）：当哈希类型元素个数小于hash-max-ziplist-entries 配置（默认512个）、同时所有值都小于hash-max-ziplist-value配置（默认64 字节）时，
        Redis会使用ziplist作为哈希的内部实现，ziplist使用更加紧凑的 结构实现多个元素的连续存储，所以在节省内存方面比hashtable更加优秀。
    hashtable（哈希表）：当哈希类型无法满足ziplist的条件时，Redis会使用hashtable作为哈希的内部实现，因为此时ziplist的读写效率会下降，而hashtable的读写时间复杂度为O（1）。
使用场景:
    相比于使用字符串序列化缓存用户信息，哈希类型变得更加直观，并且在更新操作上会更加便捷。
dict数据结构：hash结构的数据会用到字典，zset集合中存储是用dict结构实现。
    struct RedisDb{
        dict* dict; // all keys key => value
        dict* epires; // all expired keys key=>long(timestamp)
        ....
    }
    struct zset{
        dict *dict;// all values value => score
        zskiplist *zsl;
    }
```
#### 3.List列表终端命令、内部编码及应用场景
```markdown
List列表（双向链表）:列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。
    列表类型有两个特点：
        第一、列表中的元素是有序的，这就意味着可以 通过索引下标获取某个元素或者某个范围内的元素列表。
        第二、列表中的元素可以是重复的。
    常见命令：
        1.添加操作
            （1）从右边插入元素 rpush key value [value ...] lrange0-1命令可以从左到右获取列表的所有元素：lrange listkey 0 -1
            （2）从左边插入元素 lpush key value [value ...] 使用方法和rpush相同，只不过从左侧插入。
            （3）向某个元素前或者后插入元素 linsert key before|after pivot value ，linsert listkey before b java 在列表的元素b前插入 java
        2.查找
            （1）获取指定范围内的元素列表 lrange key start end ，lrange操作会获取列表指定索引范围所有的元素。
                第一，索引下标从左到右分别是0到N-1，但是从右到左分别是-1到-N。
                第二，lrange中的end选项包含了自身，这个和很多编程语言不包含end不太 相同，例如想获取列表的第2到第4个元素，可以执行如下操作：lrange listkey 1 3
            （2）获取列表指定索引下标的元素 lindex key index
            （3）获取列表长度 llen key
        3.删除
            （1）从列表左侧弹出元素 lpop key
            （2）从列表右侧弹出 rpop key
            （3）删除指定元素 lrem key count value，count>0，从左到右，删除最多count个元素。count<0，从右到左，删除最多count绝对值个元素。count=0，删除所有。
            （4）按照索引范围修剪列表 ltrim key start end 只保留列表listkey第2个到第4个元素：ltrim listkey 1 3
        4.修改
            修改指定索引下标的元素： lset key index newValue ，index从0开始，将列表listkey中的第3个元素设置为python：lset listkey 2 python
        5.阻塞操作
            阻塞式弹出如下：blpop key [key ...] timeout和brpop key [key ...] timeout ，blpop和brpop是lpop和rpop的阻塞版本，它们除了弹出方向不同，使用方法基本相同
列表类型的内部编码有两种：
    ziplist（压缩列表）：当列表的元素个数小于list-max-ziplist-entries配置 （默认512个），同时列表中每个元素的值都小于list-max-ziplist-value配置时 （默认64字节），Redis会选用ziplist来作为列表的内部实现来减少内存的使用。
    linkedlist（链表）：当列表类型无法满足ziplist的条件时，Redis会使用 linkedlist作为列表的内部实现。
    Redis3.2版本提供了quicklist内部编码，简单地说它是以一个ziplist为节 点的linkedlist，它结合了ziplist和linkedlist两者的优势，为列表类型提供了一 种更为优秀的内部编码实现。
使用场景：1.消息队列，2.文章列表，3.
quicklist数据结构：
    struct quicklistNode {
        quicklistNode* prev;
        quicklistNode* next;
        ziplist* zl; // 指向压缩列表
        int32 size; // ziplist 的字节总数
        int16 count; // ziplist 中的元素数量
        int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储
        ...
    }
    struct quicklist {
        quicklistNode* head;
        quicklistNode* tail;
        long count; // 元素总数
        int nodes; // ziplist 节点的个数
        int compressDepth; // LZF 算法压缩深度
        ...
    }
```
#### 4.Set集合终端命令、内部编码及应用场景
```markdown
Set集合：集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的，
    不能通过索引下标获取元素。利用Set的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
    Redis除了支持集合内的增删改查，同时还支持多个集合取交集、并 集、差集，合理地使用好集合类型，能在实际开发中解决很多实际问题。
    常见命令：
        1.集合内操作 
            （1）添加元素 sadd key element [element ...] 返回结果为添加成功的元素个数
            （2）删除元素 srem key element [element ...] 返回结果为成功删除元素个数
            （3）计算元素个数 scard key scard的时间复杂度为O（1），它不会遍历集合所有元素，而是直接用 Redis内部的变量。
            （4）判断元素是否在集合中 sismember key element 如果给定元素element在集合内返回1，反之返回0。
            （5）随机从集合返回指定个数元素 srandmember key [count] [count]是可选参数，如果不写默认为1。
            （6）从集合随机弹出元素 spop key spop操作可以从集合中随机弹出一个元素。
                srandmember和spop都是随机从集合选出元素，两者不同的是spop命令 执行后，元素会从集合中删除，而srandmember不会。
            （7）获取所有元素 smembers key 获取集合myset所有元素，并且返回结果是无序的。
        2.集合间操作
            （1）求多个集合的交集 sinter key [key ...]
            （2）求多个集合的并集 suinon key [key ...]
            （3）求多个集合的差集 sdiff key [key ...]
            （4）将交集、并集、差集的结果保存 sinterstore destination key [key ...] suionstore destination key [key ...] sdiffstore destination key [key ...]
集合类型的内部编码有两种：
    intset（整数集合）：当集合中的元素都是整数且元素个数小于set-max- intset-entries配置（默认512个）时，Redis会选用intset来作为集合的内部实 现，从而减少内存的使用。
    hashtable（哈希表）：当集合类型无法满足intset的条件时，Redis会使 用hashtable作为集合的内部实现。
应用场景：
    集合类型比较典型的使用场景是标签（tag）。例如一个用户可能对娱乐、体育比较感兴趣，另一个用户可能对历史、新闻比较感兴趣，这些兴趣点就是标签。
```
#### 5.ZSet有序列表终端命令、内部编码及应用场景
```markdown
ZSet有序列表（跳表实现）：ZSet多了一个权重参数Score，集合中的元素能够按Score进行排列。可以做排行榜应用，取TOP N操作。
终端命令：
    1.集合内
        （1）添加成员 zadd key score member [score member ...]
            Redis3.2为zadd命令添加了nx、xx、ch、incr四个选项：·nx：member必须不存在，才可以设置成功，用于添加。 ·xx：member必须存在，才可以设置成功，用于更新。 ·ch：返回此次操作后，有序集合元素和分数发生变化的个数 ·incr：对score做增加，相当于后面介绍的zincrby。
        （2）计算成员个数 zcard key
        （3）计算某个成员的分数 zscore key member
        （4）计算成员的排名 zrank key member，zrevrank key member，zrank是从分数从低到高返回排名，zrevrank反之。
        （5）删除成员 zrem key member [member ...]
        （6）增加成员的分数 zincrby key increment member
        （7）返回指定排名范围的成员 zrange key start end [withscores]和zrevrange key start end [withscores] 有序集合是按照分值排名的，zrange是从低到高返回，zrevrange反之。
        （8）返回指定分数范围的成员 zrangebyscore key min max [withscores] [limit offset count] zrevrangebyscore key max min [withscores] [limit offset count] 其中zrangebyscore按照分数从低到高返回，zrevrangebyscore反之。
        （9）返回指定分数范围成员个数 zcount key min max
        （10）删除指定排名内的升序元素 zremrangebyrank key start end
        （11）删除指定分数范围的成员 zremrangebyscore key min max
    2.集合间的操作
        （1）交集 zinterstore destination numkeys key [key ...] [weights weight [weight ...]] [aggregate sum|min|max]
            ·destination：交集计算结果保存到这个键。 ·numkeys：需要做交集计算键的个数。 ·key[key...]：需要做交集计算的键。139
            ·weights weight[weight...]：每个键的权重，在做交集计算时，每个键中 的每个member会将自己分数乘以这个权重，每个键的权重默认是1。 ·aggregate sum|min|max：计算成员交集后，分值可以按照sum（和）、 min（最小值）、max（最大值）做汇总，默认值是sum。
        （2）并集 zunionstore destination numkeys key [key ...] [weights weight [weight ...]] [aggregate sum|min|max]
有序集合类型的内部编码有两种：
    ziplist（压缩列表）：当有序集合的元素个数小于zset-max-ziplist- entries配置（默认128个），同时每个元素的值都小于zset-max-ziplist-value配 置（默认64字节）时，Redis会用ziplist来作为有序集合的内部实现，ziplist 可以有效减少内存的使用。
    skiplist（跳跃表）：当ziplist条件不满足时，有序集合会使用skiplist作 为内部实现，因为此时ziplist的读写效率会下降。
使用场景：（1）添加用户赞数（2）取消用户赞数（3）展示获取赞数最多的十个用户（4）展示用户信息以及用户分数
ziplist数据结构：
    struct ziplist<T> {
     int32 zlbytes; // 整个压缩列表占用字节数
     int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点
     int16 zllength; // 元素个数
     T[] entries; // 元素内容列表，挨个挨个紧凑存储
     int8 zlend; // 标志压缩列表的结束，值恒为 0xFF
    }
skiplist中zslnode数据结构：
    struct zslnode {
     string value;
     double score;
     zslnode*[] forwards; // 多层连接指针
     zslnode* backward; // 回溯指针
    }
    struct zsl {
     zslnode* header; // 跳跃列表头指针
     int maxLevel; // 跳跃列表当前的最高层
     map<string, zslnode*> ht; // hash 结构的所有键值对
    }
skiplist中listpack数据结构：
    struct listpack<T> {
     int32 total_bytes; // 占用的总字节数
     int16 size; // 元素个数
     T[] entries; // 紧凑排列的元素列表
     int8 end; // 同 zlend 一样，恒为 0xFF
    }
```
### Redis的一些其他功能
[Redis还可以做哪些事？](https://www.cnblogs.com/zhixie/p/13918144.html)
```markdown
·慢查询分析：通过慢查询分析，找到有问题的命令进行优化。 
    所谓慢查询日志就是系统在命令执行前后**计算每条命令的执行时间**，当超过预设阀值，就将这条命令的相关信息（例如：发生时间，耗时，命令的详细信息）记录下来，Redis也提供了类似的功能。
    预设阀值:Redis提供了slowlog-log-slower-than单位是微秒秒，默认是10000（10毫秒）和slowlog-max-len说明慢查询日志列表的最大长度。LRU淘汰机制
        如果slowlog-log-slower-than=0会记录所有的命令，slowlog-log-slower- than<0对于任何命令都不会进行记录。
    在Redis中有两种修改配置的方法，一种是修改配置文件，另一种是使用config set命令动态修改。
    例如下面使用config set命令将slowlog-log-slower- than设置为20000微秒，slowlog-max-len设置为1000：config set slowlog-log-slower-than 20000 config set slowlog-max-len 1000 config rewrite
    如果要Redis将配置持久化到本地配置文件，需要执行config rewrite命令。
    （1）获取慢查询日志 slowlog get [n] 参数n可以指定条数 每个慢查询日志有4个属性组成，分别是慢查询日志的标识 id、发生时间戳、命令耗时、执行命令和参数。
    （2）获取慢查询日志列表当前的长度 slowlog len
    （3）慢查询日志重置 slowlog reset 实际是对列表做清理操作
·Redis Shell：功能强大的Redis Shell会有意想不到的实用功能。
    Redis提供了redis-cli、redis-server、redis-benchmark等Shell工具。
    redis-cli详解，可以执行redis-cli-help命令来进行查看
        -r（repeat）选项代表将命令执行多次
        -i（interval）选项代表每隔几秒执行一次命令，但是-i选项必须和-r选项一起使用
        -x选项代表从标准输入（stdin）读取数据作为redis-cli的最后一个参数
        -c（cluster）选项是连接Redis Cluster节点时需要使用的，-c选项可以防 止moved和ask异常
        -a 如果Redis配置了密码，可以用-a（auth）选项，有了这个选项就不需要手动输入auth命令。
        --scan选项和--pattern选项用于扫描指定模式的键，相当于使用scan命令。
        --slave选项是把当前客户端模拟成当前Redis节点的从节点，可以用来 获取当前Redis节点的更新操作。
        --rdb选项会请求Redis实例生成并发送RDB持久化文件，保存在本地。
        --pipe选项用于将命令封装成Redis通信协议定义的数据格式，批量发送 给Redis执行。
        --bigkeys选项使用scan命令对Redis的键进行采样，从中找到内存占用比较大的键值，这些键可能是系统的瓶颈。
        --eval选项用于执行指定Lua脚本
        --latency有三个选项，分别是--latency、--latency-history、--latency-dist。 它们都可以检测网络延迟，对于Redis的开发和运维非常有帮助。
        --stat选项可以实时获取Redis的重要统计信息，虽然info命令中的统计信息更全，但是能实时看到一些增量的数据（例如requests）
        --no-raw选项是要求命令的返回结果必须是原始的格式，--raw恰恰相反，返回格式化后的结果。
    redis-server详解
        redis-server除了启动Redis外，还有一个--test-memory选项。
        redis-server- -test-memory可以用来检测当前操作系统能否稳定地分配指定容量的内存给Redis，通过这种检测可以有效避免因为内存问题造成Redis崩溃。
        redis-server --test-memory 1024 检测当前操作系统能否提供1G的内存给Redis
    redis-benchmark可以为Redis做基准性能测试，它提供了很多选项帮助开 发和运维人员测试Redis的相关性能
        -c（clients）选项代表客户端的并发数量（默认是50）。
        -n（num）选项代表客户端请求总量（默认是100000）。
        -q选项仅仅显示redis-benchmark的requests per second信息。
·Pipeline：通过Pipeline（管道或者流水线）机制有效提高客户端性能。
    Pipeline可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。
        使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。
    对于单线程阻塞式的Redis，Pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。
        Pipelining可以提高批量处理性能，提升的原因主要是TCP连接中减少了“交互往返”的时间。
        pipeline 底层是通过把所有的操作封装成流，redis有定义自己的出入输出流。
        在sync()方法执行操作，每次请求放在队列里面，解析响应包。 
·事务与Lua：制作自己的专属原子命令。 
·Bitmaps：通过在字符串数据结构上使用位操作，有效节省内存，为开发提供新的思路。 
·HyperLogLog：一种基于概率的新算法，难以想象地节省内存空间。 HyperLogLog 提供不精确的去重计数方案，标准误差是 0.81%。
    通过HyperLogLog可以利用极小的内存空间完成独立总数 的统计，数据集可以是IP、Email、ID等。HyperLogLog提供了3个命令： pfadd、pfcount、pfmerge。
    1.添加 pfadd key element [element …] pfadd用于向HyperLogLog添加元素，如果添加成功返回1。
    2.计算独立用户数 pfcount key [key …] pfcount用于计算一个或多个HyperLogLog的独立总数。
    3.合并 pfmerge destkey sourcekey [sourcekey ...] pfmerge可以求出多个HyperLogLog的并集并赋值给destkey
    //当我们加入第 100 个元素时，结果开始出现了不一致。接下来我们将数据增加到 10w个，看看总量差距有多大。
    public class PfTest {
        public static void main(String[] args) {
            Jedis jedis = new Jedis();
            for (int i = 0; i < 1000; i++) {
                jedis.pfadd("codehole", "user" + i);
                long total = jedis.pfcount("codehole");
                if (total != i + 1) {
                    System.out.printf("%d %d\n", total, i + 1);
                    break;
                }
            }
            jedis.close();
        } 
    }
    HyperLogLog实现原理：
·发布订阅：基于发布订阅模式的消息通信机制。 
    [Redis 发布订阅](https://www.cnblogs.com/goodAndyxublog/p/13716071.html)
    Redis提供了基于“发布/订阅”模式的消息机制，此种模式下，消息发布者和订阅者不进行直接通信，发布者客户端向指定的频道（channel）发布消息，订阅该频道的每个客户端都可以收到该消息。
    Redis主要提供了发布消息、订阅频道、取消订阅以及按照模式订阅和 取消订阅等命令。
        1.发布消息 publish channel message 下面操作会向channel：sports频道发布一条消息，返回结果为订阅者个数，因为此时没有订阅，所以返回结果为0：publish channel:sports "Tim won the championship"
        2.订阅消息 subscribe channel [channel ...] 订阅者可以订阅一个或多个频道，下面操作为当前客户端订阅了 channel：sports频道：subscribe channel:sports
        3.取消订阅 unsubscribe [channel [channel ...]] 客户端可以通过unsubscribe命令取消对指定频道的订阅，取消成功后， 不会再收到该频道的发布消息 
        4.按照模式订阅和取消订阅 psubscribe pattern [pattern...]和punsubscribe [pattern [pattern ...]] 例如下面操作订阅以it开头的所有频道：psubscribe:it*
        5.查询订阅  （1）查看活跃的频道 pubsub channels [pattern] 所谓活跃的频道是指当前频道至少有一个订阅者，其中[pattern]是可以 指定具体的模式。
                   （2）查看频道订阅数 pubsub numsub [channel ...]
                    （3）查看模式订阅数 pubsub numpat
·GEO：Redis3.2提供了基于地理位置信息的功能。 建议Geo的数据使用单独的Redis实例部署，不使用集群环境。
    1.增加地理位置信息 geoadd key longitude latitude member [longitude latitude member ...] ，longitude、latitude、member分别是该地理位置的经度、纬度、成员
    2.获取地理位置信息 geopos key member [member ...]
    3.获取两个地理位置的距离 geodist key member1 member2 [unit] 其中unit代表返回结果的单位m（meters）代表米。 ·km（kilometers）代表公里 ·mi（miles）代表英里 ·ft（feet）代表尺。
    4.获取指定位置范围内的地理信息位置集合 georadius和georadiusbymember两个命令的作用是一样的，都是以一个地 理位置为中心算出指定半径内的其他地理信息位置
        # 范围 20 公里以内最多 3 个元素按距离正排，它不会排除自身
        127.0.0.1:6379> georadiusbymember company ireader 20 km count 3 asc
        # 范围 20 公里以内最多 3 个元素按距离倒排
        127.0.0.1:6379> georadiusbymember company ireader 20 km count 3 desc
        # 三个可选参数 withcoord withdist withhash 用来携带附加参数
        # withdist 很有用，它可以用来显示距离
        127.0.0.1:6379> georadiusbymember company ireader 20 km withcoord withdist withhash count 3 asc
    5.获取geohash geohash key member [member ...] 将二维经纬度转换为一维字符串
    6.删除地理位置信息 zrem key member
```
### 5.redis缓存和数据库的数据一致性【10+】
[高并发情况下如何保证缓存与数据库的双写一致性](https://blog.csdn.net/shuangyueliao/article/details/90384236)
```markdown
Cache Aside Pattern：**读的时候从缓存中读，如果没有就从数据库中读并放入缓存。更新数据时，先更新数据库再删除缓存。**
原因：
    1.频繁更新浪费资源
    2.缓存数据计算复杂
    3.两种情况都具备
双写一致方案
    一、先更新数据库，再删除缓存。
        （1）更新数据库失败，无影响
        （2）更新数据库成功，删除缓存失败。数据不一致，需要将数据库操作回滚或执行方法二
        （3）更新数据库成功，删除缓存成功，无影响
    二、先删除缓存，再更新数据库。
        （1）删除缓存失败，更新数据库不再继续执行，无影响
        （2）删除缓存成功，更新数据库失败，无影响
        （3）删除缓存成功，更新数据库成功，高并发下可能数据不一致，解决办法在上方
方式一：
​    读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况。
    串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。
方式二：
​    先更新数据库，假如读缓存失败，先读数据库，再回写缓存的方式实现。
        1.合理设置缓存的过期时间
        2.新增，更改，删除数据库操作时同步更新Redis，可以使用事务机制来保证数据的一致性。
```
### 6.Redis持久化机制【10+】
[Redis持久化之RDB与AOF详解](https://www.cnblogs.com/jojop/p/13941195.html)
```markdown
Redis持久化就是把内存中的数据持久化到本地磁盘，防止服务器宕机了内存数据丢失。
Redis提供两种持久化机制RDB（默认）和AOF机制
    RDB：是Redis DataBase缩写快照
    RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。
        通过配置文件中的save参数来定义快照的周期。save m n:表示m秒内数据集存在n次修改时，自动触发bgsave。
​        优点：
​        1）只有一个文件dump.rdb，方便持久化；RDB文件保存在dir配置指定的目录下，文件名通过dbfilename配置指定。
​        2）容灾性好，一个文件可以保存到安全的磁盘。
​        3）性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化。使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能。
​        4）相对于数据集大时，比AOF的启动效率更高。
​        缺点：
​        1）数据安全性低。RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
    AOF：持久化，开启AOF功能需要设置配置：appendonly yes，默认不开启。
​        AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。
​        优点：
​        1）数据安全，aof持久化可以配置append fsync属性，有always，每进行一次 命令操作就记录到aof文件中一次。
​        2）通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题。
        缺点：
​        1）AOF文件比RDB文件大，且恢复速度慢。
​        2）数据集大的时候，比rdb启动效率低。
    Redis4.0混合持久化：将rdb文件的内容和增量的AOF日志文件存在一起。
        在Redis重启的时候，可以先加载rdb的内容，然后再重放增量AOF日志就可以完全替代之前的AOF全量文件重放，重启效率因此大幅得到提升。
bgsave做镜像全量持久化，AOF做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。
在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。
对方追问那如果突然机器掉电会怎样？取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。
    但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。
对方追问bgsave的原理是什么？fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，
    子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。
RDB和AOF持久化的过程及可能存在的问题？
```
### 8.redis内存管理和过期淘汰策略【5+】
```markdown
Redis内存分析：
    查看内存相关指标命令：info memory
    内存消耗划分：自身内存、对象内存、缓冲内存、内存碎片
Redis内存管理：
    1.设置内存上限 maxmemory参数限制最大可用内存。（主要目的：用于缓存场景LRU和防止使用的内存超过服务器物理内存）
    2.动态调整内存上限 config set maxmemory xG 终端命令动态调整内存上限
在Redis中，用户可以在server.maxmemory设置最大使用内存。Redis内存数据达到一定的大小时，就会实施内存淘汰策略。
过期策略：即对存储在redis数据库中的值可以设置一个过期时间
    0.定时删除：设置键过期时间的同时就设置一个定时器，让定时器在键的过期时间来临时就将其删除。
    1.定期删除：redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除
    2.惰性删除：定期删除可能会导致很多过期key到了时间并没有被删除掉。所以就有了惰性删除。
        假如你的过期key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个key，才会被redis给删除掉
        如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？redis内存淘汰机制
        1）全局的键空间选择性移除
    ​   noeviction：禁止驱逐数据，当内存不足以容纳新写入数据时，新写入操作会报错。
    ​   allkeys-lru：在键空间中，移除最近最少使用的key。（这个是最常用的）
    ​   allkeys-random：在键空间中，随机移除某个key。
        2）设置过期时间的键空间选择性移除
    ​   volatile-lru：在设置了过期时间的键空间中，移除最近最少使用的key。
    ​   volatile-random：在设置了过期时间的键空间中，随机移除某个key。
    ​   volatile-ttl：在设置了过期时间的键空间中，有更早过期时间的key优先移除。
内存优化的思路：
    1.精简键值对象大小，键值字面量精简，使用高效二进制序列化工具
    2.使用对象共享池优化小整数对象
    3.数据优先使用整数，比字符串类型更节省空间
    4.优化字符串使用，避免预分配造成的内存浪费
    5.使用ziplist压缩编码优化hash、list等结构，注重效率和空间的平衡
    6.使用intset编码优化整数集合
    7.使用ziplist编码的hash结构降低小对象链规模
```
### 9.缓存失效场景【10+】
[缓存穿透、缓存击穿、缓存雪崩都是什么？怎么解决？](https://www.cnblogs.com/jimoer/p/13677132.html)
[面试官：讲讲什么是缓存穿透？击穿？雪崩？如何解决？](https://www.cnblogs.com/binghe001/p/13661381.html)
[Redis缓存三大问题，一次解决](https://blog.csdn.net/Trunks2009/article/details/105372159)
>> 缓存穿透、缓存击穿、缓存雪崩区别和解决方案。
```markdown
缓存雪崩：**缓存同一时间大面积的失效**，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。
        解决方法：事前：尽量保证整个redis集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。
            ​ 1）缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
            ​ 2）一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
            ​ 3）给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存。
        如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。
缓存穿透:就是**大量请求的key根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层**。
        举个例子：某个黑客故意制造我们缓存中不存在的key发起大量请求，导致大量请求落到数据库。
        解决方法：
             ​ 1）接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
             ​ 2）从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，
                如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击；
             ​ 3）采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
缓存击穿：**由于并发用户特别多，缓存过期时，直接去数据库去取数据，引起数据库压力瞬间增大，造成过大压力**。
        和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库
        解决方案：
        ​ 1）设置热点数据永远不过期
        ​ 2）加互斥锁，互斥锁
```
### 12.redis的并发竞争问题如何解决?
```markdown
Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，
但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是
由于客户端连接混乱造成。对此有2种解决方法：
    1.客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。
    2.服务器角度，利用setnx实现锁。
    注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；
    第二种需要用到Redis的setnx命令，但是需要注意一些问题。
```
### 13、redis常见性能问题和解决方案
```markdown
1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。
2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。
Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。
3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。
4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。
```
### 14.redis事务(CAS操作实现乐观锁)【5+】
[不支持原子性的 Redis 事务也叫事务吗？](https://www.cnblogs.com/lazyegg/p/13625275.html)
```markdown
事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
    事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行，但是Redis中的事务不能保证原子性。
和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。
    相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出
Redis中事务的实现特征：
　　1). 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。
　　2). 和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。
　  3). 我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为"BEGIN TRANSACTION"语句。
        在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。
        这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。
　　4). 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。
        然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。
　　5). 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。
然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。
Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。
此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。
    修复之后我们就可以再次重新启动Redis服务器了。
Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。
    在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。
    总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。
Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的，Redis会将一个事务中的所有命令序列化，然后按顺序执行。
Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。
事务命令：
    MULTI：用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
    EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。
    WATCH：是一个乐观锁，可以为Redis事务提供check-and-set（CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。
    DISCARD：调用该命令，客户端可以清空事务队列，并放弃执行事务，且客户端会从事务状态中退出。
    UNWATCH：命令可以取消watch对所有key的监控。
Redis禁止在multi和exec之间执行watch指令，而必须在multi之前做好盯住关键变量，否则会出错。
事物优化：
    Redis的客户端在执行事务时都会结合pipeline一起使用，这样可以将多次IO操作压缩为单次IO操作。
        pipe = redis.pipeline(transaction=true)
        pipe.multi()
        pipe.incr("books")
        pipe.incr("books")
        values = pipe.execute()
```
```java
//实现对余额的加倍操作
import java.util.List;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.Transaction;
public class TransactionDemo {
     public static void main(String[] args) {
        Jedis jedis = new Jedis();
        String userId = "abc";
        String key = keyFor(userId);
        jedis.setnx(key, String.valueOf(5)); # setnx 做初始化
        System.out.println(doubleAccount(jedis, userId));
        jedis.close();
     }
     public static int doubleAccount(Jedis jedis, String userId) {
        String key = keyFor(userId);
        while (true) {
            jedis.watch(key);
            int value = Integer.parseInt(jedis.get(key));
            value *= 2; // 加倍
            Transaction tx = jedis.multi();
            tx.set(key, String.valueOf(value));
            List<Object> res = tx.exec();
            if (res != null) {
                break; // 成功了
            }
        }
         return Integer.parseInt(jedis.get(key)); // 重新获取余额
     }
    public static String keyFor(String userId) {
        return String.format("account_{}", userId);
    } 
}
```
### 15.WATCH命令和基于CAS的乐观锁
```markdown
在Redis的事务中，WATCH命令可用于提供CAS(check-and-set)功能。假设我们通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Null multi-bulk应答以通知调用者事务
执行失败。例如，我们再次假设Redis中并未提供incr命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：
　　val = GET mykey
　　val = val + 1
　　SET mykey $val
以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景--竞态争用(race condition)。
比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：
　　WATCH mykey
　　val = GET mykey
　　val = val + 1
　　MULTI
　　SET mykey $val
　　EXEC
和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，
如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。
```
### 16.Redis实现分布式锁【5+】
[Redis实现分布式锁](https://www.cnblogs.com/chenyanbin/p/13506946.html)
```markdown
什么是分布式锁？
    分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现。
    如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往通过互斥来防止彼此干扰。
为什么要有分布式锁？
    可以保证在分布式部署的应用集群中，同一个方法在同一操作只能被一台机器上的一个线程执行。
　　首先，为了确保分布式锁可用，至少要满足以下三个条件
        1.互斥性。在任意时刻，只有一个客户端能持有锁
        2.不会发生死锁。即便有一个客户端在持有锁的期间奔溃而没有主动解锁，也能保证后续其他客户端能加锁
        3.解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了
    设计要求#
        1.可重入锁(避免死锁)
        2.获取锁和释放锁高可用
        3.获取锁和释放锁高性能
实现方案#
    1.获取锁，使用setnx()：SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1
    2.若key存在，则什么都不做，返回【0】加锁，锁的value值为当前占有锁服务器内网IP编号拼接任务标识
    3.在释放锁的时候进行判断。并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁
    4.返回1则成功获取锁。还设置一个获取的超时时间，若超过这个时间则放弃获取锁，setex(key,value,expire)过期以秒为单位
    5.释放锁的时候，判断是不是该锁(即value为当前服务器内网IP编号拼接任务标识)，若是该锁，则执行delete进行锁释放
实现终端命令：
    > setnx lock:codehole true  // 获取锁，成功返回OK
    > expire lock:codehelo 5    // 给锁设置一个过期时间，保证锁释放，避免死锁。
    .... do something critical ...  //对锁住的对象进行一些操作，不会出现并发问题
    > del lock:codehole             // 删除锁（释放锁）
    如果在setnx和expire之间服务器进程突然挂掉了，就会导致expire无法执行，也会造成死锁。
简洁版命令：
    > set lock:codehole true ex 5 nx OK   //将setnx和expire组合在一起的原子指令
    ... do something critical ... 
    > del lock:codehole
RLock继承自Java标准的Lock接口,调用lock方法,如果当前锁已被其他客户端获取，那么当前加锁的线程将会被阻塞，直到其他客户端释放这把锁。
Redis分布式锁有什么缺陷：
    Redis分布式锁不能解决超时的问题，分布式锁有一个超时时间，程序的执行如果超出了锁的超时时间就会出现问题。
    因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程逻辑执行完之间拿到了锁。
    为了解决这个问题：Redis分布式锁需要避免用于较长时间的任务，如果出现超时，需要人工介入解决。
    Redis分布式锁可重入锁的实现。复杂度较高，不建议使用。
加锁失败处理策略：
    1、直接抛出异常，通知用户稍后重试；比较适合由用户直接发起的请求，用户看到错误对话框后，会先阅读对话框的内容，再点击重试，这样就可以起到人工延时的效果。
    2、sleep 一会再重试； 会导致队列的后续消息处理出现延迟。如果碰撞的比较频繁或者队列里消息比较多，sleep 可能并不合适。
    3、将请求转移至延时队列，过一会再试；比较适合异步消息处理，将当前冲突的请求扔到另一个队列延后处理以避开冲突。
```
### 17.Redis做异步队列和延时队列【5+】
```markdown
一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候（队列为空），要适当sleep一会再重试。
　　如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候（队列为空），它会阻塞住直到消息到来。
　　如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。
　　如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。
　　如果对方追问redis如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。
        但是你很克制，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，
        消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。
Redis实现延时队列：
    延时队列可以通过Redis的zset(有序列表)来实现。我们将消息序列化成一个字符串作为zset的value，这个消息的到期处理时间作为score，
    然后用多个线程轮询zset获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其它线程可以继续处理。
    因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。
```
#### Java Jedis延时队列
```java
import java.lang.reflect.Type; 
import java.util.Set; 
import java.util.UUID;
import com.alibaba.fastjson.JSON;
import com.alibaba.fastjson.TypeReference; 
import redis.clients.jedis.Jedis; 
public class RedisDelayingQueue<T> { 
    static class TaskItem<T> { 
    public String id; 
    public T msg; 
    } 
    // fastjson 序列化对象中存在 generic 类型时，需要使用 TypeReference 
    private Type TaskType = new TypeReference<TaskItem<T>>() { }.getType(); 
    private Jedis jedis; 
    private String queueKey; 
    public RedisDelayingQueue(Jedis jedis, String queueKey) { 
    this.jedis = jedis; 
    this.queueKey = queueKey; 
    } 
    public void delay(T msg) { 
    TaskItem task = new TaskItem(); 
    task.id = UUID.randomUUID().toString(); // 分配唯一的 uuid 
    task.msg = msg; 
    String s = JSON.toJSONString(task); // fastjson 序列化
    jedis.zadd(queueKey, System.currentTimeMillis() + 5000, s); // 塞入延时队列 ,5s 后再试
    } 
    public void loop() { 
        while (!Thread.interrupted()) {
            // 只取一条
            Set values = jedis.zrangeByScore(queueKey, 0, System.currentTimeMillis(), 0, 1); 
            if (values.isEmpty()) { 
                try { 
                    Thread.sleep(500); // 歇会继续
                } catch (InterruptedException e) { 
                    break;
                } 
                continue; 
            } 
            String s = values.iterator().next(); 
            if (jedis.zrem(queueKey, s) > 0) { // 抢到了
                TaskItem task = JSON.parseObject(s, TaskType); // fastjson 反序列化
                this.handleMsg(task.msg); 
            } 
        } 
    } 
    public void handleMsg(T msg) { 
        System.out.println(msg); 
    } 
    public static void main(String[] args) { 
        Jedis jedis = new Jedis(); 
        RedisDelayingQueue queue = new RedisDelayingQueue<>(jedis, "q-demo"); 
        Thread producer = new Thread() { 
            public void run() { 
                for (int i = 0; i < 10; i++) { 
                queue.delay("codehole" + i); 
            } 
        } 
    }; 
    Thread consumer = new Thread() { 
        public void run() { 
            queue.loop(); 
        } 
    }; 
    producer.start(); 
    consumer.start(); 
    try { 
        producer.join(); 
        Thread.sleep(6000); 
        consumer.interrupt(); 
        consumer.join(); 
    } 
    catch (InterruptedException e) { 
    } 
    } 
}
```
### 18.Redis的同步机制：主从复制【5+】
```markdown
Redis同步支持主从同步，从从同步。
复制功能是高可用Redis的基础，后面的哨兵和集群都是在复制的基础上实现高可用的。
    第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。
    加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。
配置复制的方式：
    1）从节点在配置文件中加入slaveof{masterHost}{masterPort}随Redis启动生效。
    2）从节点在redis-server启动命令后加入--slaveof{masterHost}{masterPort}生效。
    3）从节点直接使用命令：slaveof {masterHost} {masterPort}生效。
    slaveof命令不但可以建立复制，还可以从节点执行slaveof no one来断开与主节点复制关系。
    通过slaveof命令还可以实现切主操作，所谓切主是指把当前从节点对主 节点的复制切换到另一个主节点。执行slaveof{newMasterIp} {newMasterPort}命令即可
主从复制原理：当启动一个slave node的时候，它会发送一个PSYNC命令给master node。
    如果这是slave node初次连接到master node，那么会触发一次full resynchronization全量复制。
    此时master会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端client新收到的所有写命令缓存在内存中。
    RDB文件生成完毕后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中，
    接着master会将内存中缓存的写命令发送到slave，slave也会同步这些数据。
    slave node如果跟master node有网络故障，断开了连接，会自动重连，连接之后master node仅会复制给slave部分缺少的数据。
过程原理
​   1、当从库和主库建立MS关系后，会向主数据库发送SYNC命令
​   2、主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来
​   3、当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis
​   4、从Redis接收到后，会载入快照文件并且执行收到的缓存的命令
​   5、之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致
缺点
​   所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决。
    一旦master节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方主节点地址，还需要其他节点去复制新的的主节点。
    主节点的写能力受到单机的限制，主节点的存储能力受到单机的限制。
```
### 19.Redis哨兵和集群的原理【5+】
[多服务器使用Docker设置一主一从三哨兵redis（完整）](https://www.cnblogs.com/lan-blue/p/13951253.html)
```markdown
基于Redis主从复制存在的问题和主节点发生故障时，Redis Sentinel能够自动完成故障发现和故障转移并通知应用方，从而实现真正的高可用。
    Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。
        Redis Sentinel节点主要使用发布订阅机制，实现新节点的发现，以及交换主节点的之间的状态。
        当Redis Sentinel进行主节点故障转移，这个过程各个阶段会通过发布订阅对外提供。
        客户端可以订阅 +switch-master频道，一旦Redis Sentinel结束了对主节点的故障转移就会发布主节点的的消息。
        主要功能：
            1.监控：Sentinel节点会定期检测Redis数据节点、其余Sentinel节点算法可达。
            2.通知：Sentinel节点会将故障转移的结果通知给应用方。
            3.主节点故障转移：实现从节点晋升为主节点并且维护后续周期的主从关系。
            4.配置提供者：在Redis Sentinel结构中，客户端在初始化的时候连接的是Sentinel节点集合，从中获取主节点信息。
    Redis Sentinel实践：
    Redis Sentinel终端命令
        > sentinel masters -- 展示所有被监控的主节点状态以及相关的统计信息。
        > sentinel masters <master name> -- 展示指定<master name>的主节点状态以及相关的提交信息
        > sentinel slaves <master name> -- 展示指定<master name>的从节点状态以及相关的提交信息
        > sentinel sentinels <master name> --展示指定<master name>的sentinel节点集合，不包括当前节点
        > sentinel get-master-addr-by-name <master name> 返回指定<master name>主节点的IP地址和端口
        ........
Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。
    哈希分区（hash(Key)%N节点数量）：离散度好、数据分步业务无关、无法顺序访问。决定数据映射到哪一个节点上。
    一致性哈希分区：为系统中每个节点分配一个token，构成一个哈希环。数据读写执行节点查找操作时，根据key计算hash值，如何顺时针找到第一个大于该哈希值的token节点。
        相比于节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。
    虚拟槽分区：巧妙地使用哈希空间，使用分散度良好的哈希函数吧所有数据映射到一个固定范围的整数集合中，整数定义为槽（slot）。
    Cluster默认会对key值使用crc32算法进行hash得到一个整数值，然后用这个整数值对16384进行取模来得到具体槽位。
    Redis集群一般由多个节点组成，节点数量至少为6个才能保证组成完整高可用的集群。
        数据分布-搭建集群-节点通信-集群伸缩-请求路由-故障转移-集群运维
```
### 25.Redis跳跃表实现，为什么用skipList而不用红黑树【5+】
[跳跃表](https://redisbook.readthedocs.io/en/latest/internal-datastruct/skiplist.html)
[Redis之跳跃表](https://mp.weixin.qq.com/s?__biz=MzIwOTE2MzU4NA==&mid=2247485660&idx=1&sn=e07017245b18da214435a17ddd4afc18&chksm=97794cf3a00ec5e5339df417cb5781a18850b3da06575184598309c3920d9c20ad36d5ee64cc&mpshare=1&scene=23&srcid=0907qcv3VAXuQLpYpodSU0HB&sharer_sharetime=1599439506265&sharer_shareid=d812adcc01829f0f7f8fb06aea118511#rd)
[手写跳表主要参考JDK中的ConcurrentSkipListMap](https://www.cnblogs.com/tong-yuan/p/13630264.html)
```markdown
跳跃表以有序的方式在层次化的链表中保存元素， 效率和平衡树媲美 —— 查找、删除、添加等操作都可以在对数期望时间下完成， 并且比起平衡树来说， 跳跃表的实现要简单直观得多。
跳跃表主要由以下部分构成：
    - 表头（head）：负责维护跳跃表的节点指针。
    - 跳跃表节点：保存着元素值，以及多个层。
    - 层：保存着指向其他元素的指针。高层的指针越过的元素数量大于等于低层的指针，为了提高查找的效率，程序总是从高层先开始访问，然后随着元素值范围的缩小，慢慢降低层次。
    - 表尾：全部由 NULL 组成，表示跳跃表的末尾。
跳跃表在Redis的唯一作用，就是实现有序集数据类型。查询的时间复杂度可以降低到O(logN)。
跳跃表将指向有序集的score值和member域的指针作为元素， 并以score值为索引， 对有序集元素进行排序。
小结
    跳跃表是一种随机化数据结构，查找、添加、删除操作都可以在对数期望时间下完成。
    跳跃表目前在Redis的唯一作用，就是作为有序集类型的底层数据结构（之一，另一个构成有序集的结构是字典）。
    为了满足自身的需求，Redis基 WilliamPugh论文中描述的跳跃表进行了修改，包括：
    1.score值可重复。
    2.对比一个元素需要同时检查它的score和memeber 。
    3.每个节点带有高度为 1 层的后退指针，用于从表尾方向向表头方向迭代。
[为什么用skipList而不用红黑树](https://www.zhihu.com/question/20202931)
1.skiplist的复杂度和红黑树一样，而且实现起来更简单。
2.在并发环境下skiplist有另外一个优势，红黑树在插入和删除的时候可能需要做一些rebalance的操作，这样的操作可能会涉及到整个树的其他部分，
    而skiplist的操作显然更加局部性一些，锁需要盯住的节点更少，因此在这样的情况下性能好一些。
```
### 26.redis的zset怎么实现的？（跳表）那跳表是用什么判断每隔几个选一个呢？（随机算法）【3+】
```markdown
​跳表(skip List)是一种随机化的数据结构，基于并联的链表，实现简单，插入、删除、查找的复杂度均为O(logN)。
    简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供O(logN)的时间复杂度
​Zset数据量少的时候使用压缩链表ziplist实现，有序集合使用紧挨在一起的压缩列表节点来保存，第一个节点保存member，第二个保存score。
    ziplist内的集合元素按score从小到大排序，score较小的排在表头位置。
​数据量大的时候使用跳跃列表skiplist和哈希表hash_map结合实现，查找删除插入的时间复杂度都是O(longN)
搜索
​   跳跃表按score从小到大保存所有集合元素，查找时间复杂度为平均 O(logN)，最坏 O(N) 。
插入
  之前就说了，之所以选用链表作为底层结构支持，也是为了高效地动态增删。单链表在知道删除的节点是谁时，时间复杂度为O(1)，
    因为跳表底层的单链表是有序的，为了维护这种有序性，在插入前需要遍历链表，找到该插入的位置，单链表遍历查找的时间复杂度是O(n)，
    同理可得，跳表的遍历也是需要遍历索引数，所以是O(logn)。
删除
  删除的节点要分两种情况，如果该节点还在索引中，那删除时不仅要删除单链表中的节点，还要删除索引中的节点；另一种情况是删除的节点只在链表中，
   不在索引中，那只需要删除链表中的节点即可。但针对单链表来说，删除时都需要拿到前驱节点才可改变引用关系从而删除目标节点。
```
### Redis阻塞和分布式延迟队列
[基于Redis的分布式延迟队列](https://www.cnblogs.com/hujunzheng/p/12587572.html)
[基于Redis的分布式延迟队列（续）](https://www.cnblogs.com/hujunzheng/p/13767887.html)
```markdown
Redis阻塞
    内在原因：API或者数据结构使用不合理、CPU饱和的问题、持久化相关的阻塞
    外在原因：CPU竞争、内存交换、网络问题

```
### 分布式缓存和本地缓存有啥区别？让你自己设计本地缓存怎么设计？如何解决缓存过期问题？如何解决内存溢出问题？
```markdown
分布式缓存一致性更好一点，用于集群环境下多节点使用同一份缓存的情况；有网络IO，吞吐率与缓存的数据大小有较大关系；
本地缓存非常高效，本地缓存会占用堆内存，影响垃圾回收、影响系统性能。
本地缓存设计：
​   以Java为例，使用自带的map或者guava实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着jvm的销毁而结束，
    并且在多实例的情况，每个实例都需要各自保存一份缓存，缓存不具有一致性。
解决缓存过期：
​ 1、将缓存过期时间调为永久
​ 2、将缓存失效时间分散开，不要将缓存时间长度都设置成一样；比如我们可以在原有的失效时间基础上增加一个随机值，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
解决内存溢出：
​ 第一步，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)
　第二步，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。
　第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。
```
### redis热key问题&如何发现以及如何解决
```markdown
Redis如何发现热点key
    1.凭借经验，进行预估：例如提前知道了某个活动的开启，那么就将此Key作为热点Key。
    2.服务端收集：在操作redis之前，加入一行代码进行数据统计。
    3.抓包进行评估：Redis使用TCP协议与客户端进行通信，通信协议采用的是RESP，所以自己写程序监听端口也能进行拦截包进行解析。
    4.在proxy层，对每一个redis请求进行收集上报。
    5.Redis自带命令查询：Redis4.0.4版本提供了redis-cli–hotkeys就能找出热点Key。
        （如果要用Redis自带命令查询时，要注意需要先把内存逐出策略设置为allkeys-lfu或者volatile-lfu，否则会返回错误。
        进入Redis中使用config set maxmemory-policy allkeys-lfu即可。）
​热点key存在问题：缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，
    这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
Redis的热点key解决方案
    1.服务端缓存：即将热点数据缓存至服务端的内存中.(利用Redis自带的消息通知机制来保证Redis和服务端热点Key的数据一致性，
        对于热点Key客户端建立一个监听，当热点Key有更新操作的时候，服务端也随之更新。)
    2.备份热点Key：即将热点Key+随机数，随机分配至Redis其他节点中。这样访问热点key的时候就不会全部命中到一台机器上了。
利用monitor命令的结果就可以统计出一段时间内的热点key排行榜，命令排行榜，客户端分布等数据。
    //统计近10w条命令中的热点key 伪代码
    // 获取10w条命令
    List<String> keyList = redis.monitor(100000);
    // 存入到字典中，分别是key和对应的次数
    AtomicLongMap<String> ATOMIC_LONG_MAP = AtomicLongMap.create();
    // 统计
    for(String command : commandList){
        ATOMIC_LONG_MAP.incrementAndGet(key);
    }
    // 后续统计和分析热点key
    statHotKey(ATOMIC_LONG_MAP);
```
### redis数据分布方式？有什么优点？一致性hash呢？【2+】
```markdown
Hash：
​   客户端分片：哈希+取余
​   节点伸缩：数据节点关系变化，导致数据迁移
​   迁移数量和添加节点数量有关：建议翻倍扩容
​   一个简单直观的想法是直接用Hash来计算，以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下，均匀性可以获得，
        但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起。
一致性Hash：
​   客户端分片：哈希+顺时针（优化取余）
​   节点伸缩：只影响邻近节点，但是还是有数据迁移
​   翻倍伸缩：保证最小迁移数据和负载均衡
​   一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。
   而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。
   但这有带来均匀性的问题，即使可以将存储节点等距排列，也会在存储节点个数变化时带来数据的不均匀。而这种可能成倍数的不均匀在实际工程中是不可接受的。
```
### redis线程模型和通信协议和内存模型
```markdown
Redis线程模型：
    Redis是个单线程程序！非阻塞IO。事件轮询 (多路复用)。指令队列。响应队列。定时任务。
    非阻塞IO在套接字对象上提供了一个选项Non_Blocking，当这个选项打开时，读写方法不会阻塞，而是能读多少读多少，能写多少写多少。能读多少取决于内核为套接字分配的
    读缓冲区内部的数据字节数，能写多少取决于内核为套接字分配的写缓冲区的空闲空间字节数。读方法和写方法都会通过返回值来告知程序实际读写了多少字节。
Redis通信协议：
    RESP(Redis Serialization Protocol)是Redis序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。
Redis内存回收机制
    Redis并不总是可以将空闲内存立即归还给操作系统。如果当前Redis内存有10G，当你删除了1GB的key后，再去观察内存，你会发现内存变化不会太大。
    原因是操作系统回收内存是以页为单位，如果这个页上只要有一个key还在使用，那么它就不能被回收Redis虽然删除了1GB的key，但是这些key分散到了很多页面中，每个页面都还有其它key存在，这就导致了内存不会立即被回收。
    不过，如果你执行flushdb，然后再观察内存会发现内存确实被回收了。原因是所有的key都干掉了，大部分之前使用的页面都完全干净了，会立即被操作系统回收。
Redis内存分配算法
    内存分配是一个非常复杂的课题，需要适当的算法划分内存页，需要考虑内存碎片，需要平衡性能和效率。
    Redis为了保持自身结构的简单性，在内存分配这里直接做了甩手掌柜，将内存分配的细节丢给了第三方内存分配库去实现。
    目前Redis可以使用jemalloc(facebook)库来管理内存，也可以切换到tcmalloc(google)。因为jemalloc相比tcmalloc的性能要稍好一些，所以Redis默认使用了jemalloc。
    > info memory //指令可以看到 Redis 的 mem_allocator 使用了 jemalloc。
```
### Redis布隆过滤器原理与实现【5+】
```markdown
布隆过滤器:
    1.一定大小的BitAarry位阵列(具体大小和存储规模有关)
    2.N个优秀的哈希函数(N的个数和存储规模和容忍误判率有关)
布隆过滤器的具体使用:
    假如现在有三个哈希函数分别为h1,h2,h3,同时有三个输入x,y,z。三个输入分别通过h1-h3进行哈希计算出对应整数之后，
    对bitarray的长度进行取模运算，获取对应下标再进行置1，这样运算三次就形成了如图的bitmap结构：
描述：一句话概率就是有0一定不存在、全1不一定存在。当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。
布隆过滤器的典型应用
    1.检查单词拼写正确性
    2.检测海量名单嫌疑人
    3.垃圾邮件过滤
    4.搜索爬虫URL去重
    5.缓存穿透过滤
使用Redis的布隆过滤器来实现URL判重。
在Redis中，布隆过滤器的操作命令不多，主要包含以下几个：
    bf.add 添加元素（一次只能添加员工元素）；bf.add key key1  //返回1添加成功，0表示添加失败
    bf.exists 判断某个元素是否存在；bf.exists key key1  //返回1表示元素存在，0表示不存在
    bf.madd 添加多个元素；bf.madd key key1 key2 key3  //每个返回1表示元素添加成功，0表示添加失败
    bf.mexists 判断多个元素是否存在；
    bf.reserve 设置布隆过滤器的准确率。默认的error_rate是0.01，initial_size=100。initial_size过大会浪费存储空间，过小会影响准确率。
import redis.clients.jedis.Jedis;
import utils.JedisUtils;
import java.util.Arrays;

public class BloomExample {
    // 布隆过滤器 key
    private static final String _KEY = "URLREPEAT_KEY";
    // 待去重 URL
    public static final String[] URLS = {
            "www.apigo.cn",
            "www.baidu.com",
            "www.apigo.cn"
    };
    public static void main(String[] args) {
        Jedis jedis = JedisUtils.getJedis();
         for (int i = 0; i < URLS.length; i++) {
            String url = URLS[i];
            boolean exists = bfExists(jedis, _KEY, url);
            if (exists) {
                // 重复的 URL
                System.out.println("URL 已存在了：" + url);
            } else {
                bfAdd(jedis, _KEY, url);
            }
        }
    }
    /**
     * 添加元素
     * @param jedis Redis 客户端
     * @param key   key
     * @param value value
     * @return boolean
     */
    public static boolean bfAdd(Jedis jedis, String key, String value) {
        String luaStr = "return redis.call('bf.add', KEYS[1], KEYS[2])";
        Object result = jedis.eval(luaStr, Arrays.asList(key, value),
                Arrays.asList());
        if (result.equals(1L)) {
            return true;
        }
        return false;
    }
    /**
     * 查询元素是否存在
     * @param jedis Redis 客户端
     * @param key   key
     * @param value value
     * @return boolean
     */
    public static boolean bfExists(Jedis jedis, String key, String value) {
        String luaStr = "return redis.call('bf.exists', KEYS[1], KEYS[2])";
        Object result = jedis.eval(luaStr, Arrays.asList(key, value),
                Arrays.asList());
        if (result.equals(1L)) {
            return true;
        }
        return false;
    }
}
```
### Redis中BitMap的使用场景
[Redis 中 BitMap 的使用场景](https://www.cnblogs.com/54chensongxia/p/13794391.html)
```markdown
BitMap原本的含义是用一个比特位来映射某个元素的状态。由于一个比特位只能表示0和1两种状态，所以BitMap能映射的状态有限，但是使用比特位的优势是能大量的节省内存空间。
Redis的位数组是自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行零扩充。
BitMap终端命令：
    1.设置值 setbit key offset value，设置键的第offset个位的值（从0算起）
    2.获取值 gitbit key offset ，获取键的第offset位的值（从0开始算）
    3.获取Bitmaps指定范围值为1的个数 bitcount [start][end] [start]和[end]代表起始和结束字节数
    4.Bitmaps间的运算 bitop op destkey key[key....] bitop是一个复合操作，它可以做多个Bitmaps的and（交集）、or（并 集）、not（非）、xor（异或）操作并将结果保存在destkey中。
    5.计算Bitmaps中第一个值为targetBit的偏移量 bitpos key targetBit [start] [end]
    6.一次见效多个位的操作 bitfield: bitfield key [get|set|incrby] CharNumber index 批量获取、设置、自增的从第index+1位开始，取Number个位，结果有符号或者无符号数
        Char=u结果是无符号数，Char=i结果有符号。所谓有符号数是指获取的位数组中第一个位是符号位，剩下的才是值。
```
### Redis简单限流和漏斗限流
```markdown
简单限流：
    系统要限定用户的某个行为在指定的时间里只能允许发生N次，如何使用Redis的数据结构来实现这个限流的功能？
    答：用一个zset结构记录用户的行为历史，每一个行为都会作为zset中的一个key保存下来。同一个用户同一种行为用一个zset记录。
      为节省内存，我们只需要保留时间窗口内的行为记录，同时如果用户是冷用户，滑动时间窗口内的行为是空记录，那么这个zset就可以从内存中移除，不再占用空间。
漏斗限流：
    Redis4.0提供了一个限流Redis模块，它叫redis-cell。该模块也使用了漏斗算法，并提供了原子的限流指令。
        > cl.throttle laoqian:reply 15 30 60 //允许【用户老钱回复行为】的频率为每60s最多30次，漏斗的初始容量为15，也就是说一开始可以连续回复15个，然后才开始受到漏水速率的影响。
        1) (integer) 0 # 0 表示允许，1 表示拒绝
        2) (integer) 15 # 漏斗容量 capacity
        3) (integer) 14 # 漏斗剩余空间 left_quota
        4) (integer) -1 # 如果拒绝了，需要多长时间后再试(漏斗有空间了，单位秒)
        5) (integer) 2 # 多长时间后，漏斗完全空出来(left_quota==capacity，单位秒)
    在执行限流指令时，如果被拒绝了，就需要丢弃或重试。
```
#### 简单限流代码实现
```java
// 每一个行为到来时，都维护一次时间窗口。将时间窗口外的记录全部清理掉，只保留窗口内的记录。
// 因为这几个连续的Redis操作都是针对同一个key的，使用pipeline可以显著提升Redis存取效率。
// 但这种方案也有缺点，因为它要记录时间窗口内所有的行为记录，如果这个量很大，比如限定60s内操作不得超过100w次这样的参数，它是不适合做这样的限流的，因为会消耗大量的存储空间。
public class SimpleRateLimiter {
    private Jedis jedis;
    public SimpleRateLimiter(Jedis jedis) {
        this.jedis = jedis;
    }
    public boolean isActionAllowed(String userId, String actionKey, int period, int maxCount) {
        String key = String.format("hist:%s:%s", userId, actionKey);
        long nowTs = System.currentTimeMillis();
        Pipeline pipe = jedis.pipelined();
        pipe.multi();
        pipe.zadd(key, nowTs, "" + nowTs);
        pipe.zremrangeByScore(key, 0, nowTs - period * 1000);
        Response<Long> count = pipe.zcard(key);
        pipe.expire(key, period + 1);
        pipe.exec();
        pipe.close();
        return count.get() <= maxCount;
    }
    public static void main(String[] args) {
        Jedis jedis = new Jedis();
        SimpleRateLimiter limiter = new SimpleRateLimiter(jedis);
        for(int i=0;i<20;i++) {
            System.out.println(limiter.isActionAllowed("laoqian", "reply", 60, 5));
        }
    }
}
```
#### 漏斗限流代码实现
```java
// Funnel对象的make_space方法是漏斗算法的核心，其在每次灌水前都会被调用以触发漏水，给漏斗腾出空间来。能腾出多少空间取决于过去了多久以及流水的速率
// Funnel对象占据的空间大小不再和行为的频率成正比，它的空间占用是一个常量。
public class FunnelRateLimiter {
    static class Funnel {
        int capacity;
        float leakingRate;
        int leftQuota;
        long leakingTs;

        public Funnel(int capacity, float leakingRate) {
            this.capacity = capacity;
            this.leakingRate = leakingRate;
            this.leftQuota = capacity;
            this.leakingTs = System.currentTimeMillis();
        }
        void makeSpace() {
            long nowTs = System.currentTimeMillis();
            long deltaTs = nowTs - leakingTs;
            int deltaQuota = (int) (deltaTs * leakingRate);
            if (deltaQuota < 0) { // 间隔时间太长，整数数字过大溢出
                this.leftQuota = capacity;
                this.leakingTs = nowTs;
                return;
            }
            if (deltaQuota < 1) { // 腾出空间太小，最小单位是 1
                return;
            }
            this.leftQuota += deltaQuota;
            this.leakingTs = nowTs;
            if (this.leftQuota > this.capacity) {
                this.leftQuota = this.capacity;
            }
        }
        boolean watering(int quota) {
            makeSpace();
            if (this.leftQuota >= quota) {
                this.leftQuota -= quota;
                return true;
            }
            return false;
        }
    }
    private Map<String, Funnel> funnels = new HashMap<>();
    public boolean isActionAllowed(String userId, String actionKey, int capacity, float leakingRate) {
        String key = String.format("%s:%s", userId, actionKey);
        Funnel funnel = funnels.get(key);
        if (funnel == null) {
            funnel = new Funnel(capacity, leakingRate);
            funnels.put(key, funnel);
        }
        return funnel.watering(1); // 需要 1 个 quota
    } 
}
```
### 假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？
```markdown
使用keys指令可以扫出指定模式的key列表。
　　对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？
    > keys prefix*
　　 > keys prefix*affix
    这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。
    scan cursor mathch prefix* count limit
    > scan 0 match key* count 1000  //返回从0开始匹配的个数，limit限定服务器单次遍历的字典槽位数量。不是限制返回数量。
    这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。
```




## 二, MongoDB
### 1.MongoDB简介
```markdown
⾮关系型数据库(NoSql),Mongo DB很好的实现了⾯向对象的思想,在MongoDB中 每⼀条记录都是⼀个Document对象。
Mongo DB最⼤的优势在于所有的数据持久操作都⽆需开发⼈员⼿动编写SQL语句,直接调⽤⽅法就可以轻松的实现CRUD操作.
```
### 2.MongoDB特点
```markdown
⾼性能、易部署、易使⽤，存储数据⾮常⽅便。主要功能特性有：
⾯向集合存储，易存储对象类型的数据。
模式⾃由。
⽀持动态查询。
⽀持完全索引，包含内部对象。
⽀持查询。
⽀持复制和故障恢复。
使⽤⾼效的⼆进制数据存储，包括⼤型对象（如视频等）。
⾃动处理碎⽚，以⽀持云计算层次的扩展性
⽀持Python，PHP，Ruby，Java，C，C#，Javascript，Perl及C++语⾔的驱动程序，社区中也
提供了对Erlang及.NET等平台的驱动程序。
⽂件存储格式为BSON（⼀种JSON的扩展）。
可通过⽹络访问。
```
### 3.MongoDB主要功能
```markdown
⾯向集合的存储：适合存储对象及JSON形式的数据。
动态查询：Mongo⽀持丰富的查询表达式。查询指令使⽤JSON形式的标记，可轻易查询⽂档中内嵌的对象及数组。
完整的索引⽀持：包括⽂档内嵌对象及数组。Mongo的查询优化器会分析查询表达式，并⽣成⼀个⾼效的查询计划。
查询监视：Mongo包含⼀个监视⼯具⽤于分析数据库操作的性能。
复制及⾃动故障转移：Mongo数据库⽀持服务器之间的数据复制，⽀持主-从模式及服务器之间的相互复制。复制的主要⽬标是提供冗余及⾃动故障转移。
⾼效的传统存储⽅式：⽀持⼆进制数据及⼤型对象（如照⽚或图⽚）
⾃动分⽚以⽀持云级别的伸缩性：⾃动分⽚功能⽀持⽔平的数据库集群，可动态添加额外的机器
```
### 4.MongoDB适⽤场景
```markdown
⽹站数据：MongoDB⾮常适合实时的插⼊，更新与查询，并具备⽹站实时数据存储所需的复制及⾼度伸缩性。
缓存：由于性能很⾼，MongoDB也适合作为信息基础设施的缓存层。在系统重启之后，由MongoDB搭建的持久化缓存层可以避免下层的数据源 过载。
    ⼤尺⼨，低价值的数据：使⽤传统的关系型数据库存储⼀些数据时可能会⽐较昂贵，在此之前，很多时候程序员往往会选择传统的⽂件进⾏存储。
⾼伸缩性的场景：MongoDB⾮常适合由数⼗或数百台服务器组成的数据库。MongoDB的路线图中已经包含对MapReduce引擎的内置⽀持。
    ⽤于对象及JSON数据的存储：Mongo的BSON数据格式⾮常适合⽂档化格式的存储及查询。
```
### 5.Redis、memcache、MongoDB 对⽐
```markdown
mongodb是⽂档型的⾮关系型数据库，其优势在于查询功能⽐较强⼤，能存储海量数据。
memcached和redis。它们都是内存型数据库，数据保存在内存中，通过tcp直接存取，优势是速度快，并发⾼，缺点是数据类型有限，查询功能不强，⼀般⽤作缓存。
1. 性能
    redis和memcache差不多，要⼤于mongodb。
2. 操作的便利性
    memcache数据结构单⼀。
    redis丰富⼀些，数据操作⽅⾯，redis更好⼀些，较少的⽹络IO次数。
    mongodb⽀持丰富的数据表达，索引，最类似关系型数据库，⽀持的查询语⾔⾮常丰富。
3. 内存空间的⼤⼩和数据量的⼤⼩
    redis在2.0版本后增加了⾃⼰的VM特性，突破物理内存的限制；可以对key value设置过期时间（类似memcache）。
    memcache可以修改最⼤可⽤内存,采⽤LRU算法。
    mongoDB适合⼤数据量的存储，依赖操作系统VM做内存管理，吃内存也⽐较厉害，服务不要和别的服务在⼀起。
4. 可⽤性（单点问题）
    redis对于单点问题，依赖客户端来实现分布式读写；
    主从复制时，每次从节点重新连接主节点都要依赖整个快照,⽆增量复制，因性能和效率问题，所以单点问题⽐较复杂；
    不⽀持⾃动sharding,需要依赖程序设定⼀致hash 机制。
    ⼀种替代⽅案是，不⽤redis本身的复制机制，采⽤⾃⼰做主动复制（多份存储），或者改成增量复制的⽅式（需要⾃⼰实现），⼀致性问题和性能的权衡。
Memcache本身没有数据冗余机制，也没必要；对于故障预防，采⽤依赖成熟的hash或者环状的算法，解决单点故障引起的抖动问题。
mongoDB⽀持master-slave,replicaset（内部采⽤paxos选举算法，⾃动故障恢复）,autosharding机制，对客户端屏蔽了故障转移和切分机制。
5. 可靠性（持久化）
    对于数据持久化和数据恢复，redis⽀持（快照、AOF）：依赖快照进⾏持久化，aof增强了可靠性的同时，对性能有所影响。
    memcache不⽀持，通常⽤在做缓存,提升性能；
    MongoDB从1.8版本开始采⽤binlog⽅式⽀持持久化的可靠性。
6. 数据⼀致性（事务⽀持）
    Memcache 在并发场景下，⽤cas保证⼀致性。
    redis事务⽀持⽐较弱，只能保证事务中的每个操作连续执⾏。
    mongoDB不⽀持事务。
7. 数据分析
    mongoDB内置了数据分析的功能(mapreduce),其他不⽀持。
8. 应⽤场景
    redis：数据量较⼩的更性能操作和运算上。
    memcache：⽤于在动态系统中减少数据库负载，提升性能;做缓存，提⾼性能（适合读多写少，对于数据量⽐较⼤，可以采⽤sharding）。
    MongoDB:主要解决海量数据的访问效率问题。
```

## 三, ElasticSearch
[详尽的 Elasticsearch7.X 安装及集群搭建教程](https://www.cnblogs.com/michael-xiang/p/13715692.html)
>>  2.1 你们公司的ES集群，一个node一般会分配几个分片？
    2.2 Elasticsearch是如何实现Master选举的？
    2.3 你是如何做写入调优的？
    2.4 什么是脑裂？如何避免脑裂？
    2.5 Elasticsearch对于大数据量（上亿量级）的聚合如何实现？
    2.6 ES主分片数量可以在后期更改吗？为什么？
    2.7 如何监控集群状态？
    2.8 ElasticSearch中的副本是什么？
    2.9 ES更新数据的执行流程？
    2.10 shard里面是什么组成的？
    2.11 ElasticSearch中的分析器是什么？
    2.13 客户端在和集群连接时，如何选择特定的节点执行请求的？
    2.14 Elasticsearch中的倒排索引是什么？
    2.15 什么是索引？索引（名词） 一个索引(index)
    2.16 详细描述一下Elasticsearch更新和删除文档的过程
### 1.ElasticSearch介绍
```markdown
Elasticsearch（ES）是一个基于Lucene构建的开源分布式搜索分析引擎，可以近实时的索引、检索数据。具备高可靠、易使用、社区活跃等特点，
在全文检索、日志分析、监控分析等场景具有广泛应用。
由于高可扩展性，集群可扩展至百节点规模，处理PB级数据。通过简单的RESTful API即可实现写入、查询、集群管理等操作。
除了检索，还提供丰富的统计分析功能。以及官方功能扩展包XPack满足其他需求，如数据加密、告警、机器学习等。
另外，可通过自定义插件，如COS备份、QQ分词等满足特定功能需求。
```
### 2.Elasticsearch架构与原理
```markdown
基本概念 ：
    Cluster「集群」：由部署在多个机器的ES节点组成，以处理较大数据集和实现高可用；
    Node「节点」：机器上的ES进程，可配置不同类型的节点；
    Master Node「主节点」：用于集群选主。由其中一个节点担任主节点，负责集群元数据管理，如索引创建，节点离开加入集群等；
    Data Node「数据节点」：负责索引数据存储；
    Index「索引」：索引数据的逻辑集合，可类比关系型数据的DataBase；
    Shard「分片」：索引数据子集，通过将分片分配至集群不同节点，实现数据横向扩展。以解决单个节点CPU、内存、磁盘处理能力不足的情况；
    Primary Shard「主分片」：数据分片采用主从模式，由分片接收索引操作；
    Replica Shard「副本分片」：主分片的拷贝，以提高查询吞吐量和实现数据高可靠。主分片异常时，其中一个副本分片会自动提升为新的主分片。
内置自动发现实现 Zen discovery，当一个节点启动后，通过联系集群成员列表即可加入集群。
由其中一个节点担任主节点，用于集群元数据管理，维护分片在节点间的分配关系。当新节点加入集群后，Master节点会自动迁移部分分片至新节点，均衡集群负载。
分布式集群难免有节点故障。主节点会定期探测集群其他节点存活状态，当节点故障后，会将节点移出集群，并自动在其他节点上恢复故障节点上的分片。
主分片故障时会提升其中一个副本分片为主分片。其他节点也会探活主节点，当主节点故障后，会触发内置的类Raft协议选主，并通过设置最少候选主节点数，避免集群脑裂。
除了集群管理，索引数据读写也是我们关心的重要部分。ES采用peer-to-peer架构，每个节点保存全量分片路由信息，也就是每个节点均可以接收用户读写。

```
### 3.Elasticsearch应用场景
```markdown
ES的典型使用场景有日志分析、时序分析、全文检索等。
    1.日志实时分析场景
        日志从产生到可访问一般在10s级，相比于传统大数据解决方案的几十分钟、小时级时效性非常高。
        ES底层支持倒排索引、列存储等数据结构，使得在日志场景可以利用ES非常灵活的搜索分析能力。通过ES交互式分析能力，即使在万亿级日志的情况下，日志搜索响应时间也是秒级。
        日志处理的基本流程包含：日志采集->数据清洗->存储->可视化分析。Elastic Stack通过完整的日志解决方案，帮助用户完成对日志处理全链路管理。
            1.日志采集：通过轻量级日志采集组件FileBeat实时读取业务日志文件，发送数据至下游组件如Logstash。
            2.文本解析：利用正则解析等机制，将日志文本数据转换成结构化数据。可使用独立的Logstash服务或Elasticsearch内置的轻量级数据处理模块Ingest Pipeline，完成数据清洗和转换。
            3.数据存储：通过Elasticsearch搜索分析平台进行数据持久存储，提供全文搜索和分析能力。
            4.可视化分析：通过功能丰富的图形界面，即可对日志数据进行搜索分析，如可视化组件Kibana。
    2.时序分析场景
        时序数据是按时间顺序记录设备、系统状态变化的数据。典型的时序数据有传统的服务器监控指标数据、应用系统性能监控数据、智能硬件、工业物联网传感器数据等。
        ES提供灵活、多维度的统计分析能力，实现查看监控按照地域、业务模块等灵活的进行统计分析。
        另外，ES支持列存储、高压缩比、副本数按需调整等能力，可实现较低存储成本。最后时序数据也可通过Kibana组件轻松实现可视化。
    3.搜索服务场景
        通过ES高效倒排索引，以及自定义打分、排序能力与丰富的分词插件，实现全文检索需求。
```

## NoSQL
[学了那么多 NoSQL 数据库 NoSQL 究竟是啥](https://www.cnblogs.com/mrhelloworld/p/nosql.html)