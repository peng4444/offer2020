# Redis面试学习总结

## 一, Redis
[Redis的最常被问到知识点总结](https://www.cnblogs.com/Young111/p/11518346.html)
### 1.什么是redis?【5+】
```markdown
Redis是一个基于内存的高性能key-value数据库,是⼀个完全开源免费的key-value内存数据库。 
```
### 2.Reids的特点
```markdown
Redis本质上是一个Key-Value类型的内存数据库，很像memcached，
    整个数据库统统加载在内存当中进行操作，定期通过异步操作把数据库数据flush到硬盘上进行保存。
    因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过10万次读写操作，是已知性能最快的Key-ValueDB。
    Redis的出色之处不仅仅是性能，Redis最大的魅力是支持保存多种数据结构，此外单个value的最大限制是1GB，不像memcached只能保存1MB的数据，
    因此Redis可以用来实现很多有用的功能，比方说用他的List来做FIFO双向链表，实现一个轻量级的高性 能消息队列服务，用他的Set可以做高性能的tag系统等等。
    另外Redis也可以对存入的Key-Value设置expire时间，因此也可以被当作一个功能加强版的memcached来用。
Redis的主要缺点是数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上。
```
### 3.使用redis有哪些好处？ 
```markdown
(1) 速度快，因为数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1) 
(2) 支持丰富数据类型，支持string，list，set，sorted set，hash 
    1）String
    常用命令：set/get/decr/incr/mget等；
    应用场景：String是最常用的一种数据类型，普通的key/value存储都可以归为此类；
    实现方式：String在redis内部存储默认就是一个字符串，被redisObject所引用，当遇到incr、decr等操作时会转成数值型进行计算，此时redisObject的encoding字段为int。
    2）Hash
    常用命令：hget/hset/hgetall等
    应用场景：我们要存储一个用户信息对象数据，其中包括用户ID、用户姓名、年龄和生日，通过用户ID我们希望获取该用户的姓名或者年龄或者生日；
    实现方式：Redis的Hash实际是内部存储的Value为一个HashMap，并提供了直接存取这个Map成员的接口。如图所示，Key是用户ID, value是一个Map。
    这个Map的key是成员的属性名，value是属性值。这样对数据的修改和存取都可以直接通过其内部Map的Key(Redis里称内部Map的key为field), 
    也就是通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据。当前HashMap的实现有两种方式：当HashMap的成员比较少时Redis为了节省内存
    会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，这时对应的value的redisObject的encoding为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。
    3）List
    常用命令：lpush/rpush/lpop/rpop/lrange等；
    应用场景：Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现；
    实现方式：Redis list的实现为一个双向链表，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销，Redis内部的很多实现，包括发送缓冲队列等也都是用的这个数据结构。
    4）Set
    常用命令：sadd/spop/smembers/sunion等；
    应用场景：Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以自动排重的，当你需要存储一个列表数据，又不希望出现重复数据时，
    set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的；
    实现方式：set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。
    5）Sorted Set
    常用命令：zadd/zrange/zrem/zcard等；
    应用场景：Redis sorted set的使用场景与set类似，区别是set不是自动有序的，而sorted set可以通过用户额外提供一个优先级(score)的参数来为成员排序，
    并且是插入有序的，即自动排序。当你需要一个有序的并且不重复的集合列表，那么可以选择sorted set数据结构，比如twitter 的public timeline可以以发表时间作为score来存储，这样获取时就是自动按时间排好序的。
    实现方式：Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序，HashMap里放的是成员到score的映射，而跳跃表里存放的是所有的成员，
    排序依据是HashMap里存的score,使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。  
(3) 支持事务，操作都是原子性，所谓的原子性就是对数据的更改要么全部执行，要么全部不执行 
(4) 丰富的特性：可用于缓存，消息，按key设置过期时间，过期后将会自动删除
```
### 4.redis相比memcached有哪些优势？ 
```markdown
(1) memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型 
(2) redis的速度比memcached快很多 
(3) redis可以持久化其数据
```
### 5.Memcache与Redis的区别都有哪些？  
```markdown
(1)、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。Redis有部份存在硬盘上，这样能保证数据的持久性。 
(2)、数据支持类型Memcache对数据类型支持相对简单。Redis有复杂的数据类型。 
(3)、使用底层模型不同 它们之间底层实现方式 以及与客户端之间通信的应用协议不一样。
    Redis直接自己构建了VM机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。 
```
### 6.redis适用于的场景?【5+】
```markdown
Redis最适合所有数据in-momory的场景，如：
（1）、会话缓存（Session Cache）
　　最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。
（2）、全页缓存（FPC）
　　除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。
（3）、队列
　　Reids在内存存储引擎领域的一大优点是提供list和set操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对list的push/pop操作。
　　如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。
    例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。
（4）、排行榜/计数器
　　Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，
    Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：
　　当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：
　　ZRANGE user_scores 0 10 WITHSCORES
　　Agora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。
（5）、发布/订阅
　　最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。
```
### 7、redis的缓存失效策略和主键失效机制【2+】
```markdown
作为缓存系统都要定期清理无效数据，就需要一个主键失效和淘汰策略.
在Redis当中，有生存期的key被称为volatile。在创建缓存时，要为给定的key设置生存期，当key过期的时候（生存期为0），它可能会被删除。
　　1、影响生存时间的一些操作
　　生存时间可以通过使用DEL命令来删除整个key来移除，或者被SET和GETSET命令覆盖原来的数据，也就是说，修改key对应的value和使用另外相同的key和value来覆盖以后，当前数据的生存时间不同。
　　比如说，对一个key执行INCR命令，对一个列表进行LPUSH命令，或者对一个哈希表执行HSET命令，这类操作都不会修改key本身的生存时间。
    另一方面，如果使用RENAME对一个key进行改名，那么改名后的key的生存时间和改名前一样。
　　RENAME命令的另一种可能是，尝试将一个带生存时间的key改名成另一个带生存时间的another_key，这时旧的another_key(以及它的生存时间)会被删除，
    然后旧的key会改名为another_key，因此，新的another_key的生存时间也和原本的key一样。使用PERSIST命令可以在不删除key的情况下，移除key的生存时间，让key重新成为一个persistent key 。
　　2、如何更新生存时间
　　可以对一个已经带有生存时间的key执行EXPIRE命令，新指定的生存时间会取代旧的生存时间。过期时间的精度已经被控制在1ms之内，主键失效的时间复杂度是O（1），
　　EXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。设置成功返回1；当key不存在或者不能为key设置生存时间时，返回 0 。
　　最大缓存配置
　　在redis中，允许用户设置最大使用内存大小
　　server.maxmemory
　　默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。
　　redis 提供 6种数据淘汰策略：
　　． volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
　　． volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
　　． volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰
　　． allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
　　． allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰
　　． no-enviction（驱逐）：禁止驱逐数据
　　注意这里的6种机制，volatile和allkeys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-enviction永不回收的策略。
　　使用策略规则：
　　  1、如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用allkeys-lru
　　  2、如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random
三种数据淘汰策略：
　　ttl和random比较容易理解，实现也会比较简单。主要是Lru最近最少使用淘汰策略，设计上会对key 按失效时间排序，然后取最先失效的key进行淘汰
```
### 8.redis过期淘汰策略【5+】
```markdown
Redis：它是缓存数据库，数据存在内存中，读写速度非常快(高性能)，高并发 。支持事务、持久化。
常用数据结构有：String、Hash、List、Set、Sorted Set
过期策略：
    即对存储在redis数据库中的值可以设置一个过期时间
    1.定期删除：redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除
    2.惰性删除：定期删除可能会导致很多过期key到了时间并没有被删除掉。所以就有了惰性删除。
        假如你的过期key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个key，才会被redis给删除掉
        如果大量过期key堆积在内存里，导致redis内存块耗尽了。怎么解决这个问题呢？redis内存淘汰机制
    1）全局的键空间选择性移除
    ​   noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。
    ​   allkeys-lru：在键空间中，移除最近最少使用的key。（这个是最常用的）
    ​   allkeys-random：在键空间中，随机移除某个key。
    2）设置过期时间的键空间选择性移除
    ​   volatile-lru：在设置了过期时间的键空间中，移除最近最少使用的key。
    ​   volatile-random：在设置了过期时间的键空间中，随机移除某个key。
    ​   volatile-ttl：在设置了过期时间的键空间中，有更早过期时间的key优先移除。
```
### 9.缓存失效场景【5+】
>> 缓存穿透、缓存击穿、缓存雪崩区别和解决方案。
```markdown
缓存雪崩：缓存同一时间大面积的失效，所以，后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。
        解决方法：事前：尽量保证整个redis集群的高可用性，发现机器宕机尽快补上。选择合适的内存淘汰策略。
            ​ 1）缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
            ​ 2）一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
            ​ 3）给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存。
缓存穿透:说简单点就是大量请求的key根本不存在于缓存中，导致请求直接到了数据库上，根本没有经过缓存这一层。
        举个例子：某个黑客故意制造我们缓存中不存在的 key 发起大量请求，导致大量请求落到数据库。
        解决方法：
             ​ 1）接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
             ​ 2）从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，
                如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击；
             ​ 3）采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
缓存击穿：这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。
        和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库
        解决方案：
        ​ 1）设置热点数据永远不过期
        ​ 2）加互斥锁，互斥锁
```
### 10.为什么redis需要把所有数据放到内存中?　
```markdown
Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。
所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。
在内存越来越便宜的今天，redis将会越来越受欢迎。
如果设置了最大使用的内存，则数据已有记录数达到内存限值后不能继续插入新值。
```
### 11.Redis是单进程为什么快【5+】
```markdown
redis是单线程，快的原因：
​ 1）完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，优势就是查找和操作的时间复杂度都是O(1)；
​ 2）数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
​ 3）采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
​ 4）使用多路I/O复用模型，非阻塞IO；
​ 5）使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；
```
### 12.redis的并发竞争问题如何解决?
```markdown
Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争，
但是在Jedis客户端对Redis进行并发访问时会发生连接超时、数据转换错误、阻塞、客户端关闭连接等问题，这些问题均是
由于客户端连接混乱造成。对此有2种解决方法：
    1.客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化，同时对客户端读写Redis操作采用内部锁synchronized。
    2.服务器角度，利用setnx实现锁。
    注：对于第一种，需要应用程序自己处理资源的同步，可以使用的方法比较通俗，可以使用synchronized也可以使用lock；
    第二种需要用到Redis的setnx命令，但是需要注意一些问题。
```
### 13、redis常见性能问题和解决方案： 
```markdown
1).Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。
2).Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。
Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。
3).Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。
4). Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内。
```
### 14.redis事务CAS(check-and-set操作实现乐观锁)
[不支持原子性的 Redis 事务也叫事务吗？](https://www.cnblogs.com/lazyegg/p/13625275.html)
```markdown
事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
    事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。
和众多其它数据库一样，Redis作为NoSQL数据库也同样提供了事务机制。在Redis中，MULTI/EXEC/DISCARD/WATCH这四个命令是我们实现事务的基石。
    相信对有关系型数据库开发经验的开发者而言这一概念并不陌生，即便如此，我们还是会简要的列出
Redis中事务的实现特征：
　　1). 在事务中的所有命令都将会被串行化的顺序执行，事务执行期间，Redis不会再为其它客户端的请求提供任何服务，从而保证了事物中的所有命令被原子的执行。
　　2). 和关系型数据库中的事务相比，在Redis事务中如果有某一条命令执行失败，其后的命令仍然会被继续执行。
　  3). 我们可以通过MULTI命令开启一个事务，有关系型数据库开发经验的人可以将其理解为"BEGIN TRANSACTION"语句。
        在该语句之后执行的命令都将被视为事务之内的操作，最后我们可以通过执行EXEC/DISCARD命令来提交/回滚该事务内的所有操作。
        这两个Redis命令可被视为等同于关系型数据库中的COMMIT/ROLLBACK语句。
　　4). 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。
        然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务中的所有命令都会被服务器执行。
　　5). 当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。
然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。
Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。
此时，我们就要充分利用Redis工具包中提供的redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。
    修复之后我们就可以再次重新启动Redis服务器了。
Redis 事务的本质是通过MULTI、EXEC、WATCH等一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。
    在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。
    总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。
Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的
Redis会将一个事务中的所有命令序列化，然后按顺序执行。
Redis的事务总是具有ACID中的一致性和隔离性，其他特性是不支持的。当服务器运行在AOF持久化模式下，并且appendfsync选项的值为always时，事务也具有耐久性。
事务命令：
MULTI：用于开启一个事务，它总是返回OK。MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有队列中的命令才会被执行。
EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil 。
WATCH ：是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令。
DISCARD：调用该命令，客户端可以清空事务队列，并放弃执行事务，且客户端会从事务状态中退出。
UNWATCH：命令可以取消watch对所有key的监控。
```
### 15.WATCH命令和基于CAS的乐观锁?
```markdown
在Redis的事务中，WATCH命令可用于提供CAS(check-and-set)功能。假设我们通过WATCH命令在事务执行之前监控了多个Keys，倘若在WATCH之后有任何Key的值发生了变化，EXEC命令执行的事务都将被放弃，同时返回Null multi-bulk应答以通知调用者事务
执行失败。例如，我们再次假设Redis中并未提供incr命令来完成键值的原子性递增，如果要实现该功能，我们只能自行编写相应的代码。其伪码如下：
　　val = GET mykey
　　val = val + 1
　　SET mykey $val
以上代码只有在单连接的情况下才可以保证执行结果是正确的，因为如果在同一时刻有多个客户端在同时执行该段代码，那么就会出现多线程程序中经常出现的一种错误场景--竞态争用(race condition)。
比如，客户端A和B都在同一时刻读取了mykey的原有值，假设该值为10，此后两个客户端又均将该值加一后set回Redis服务器，这样就会导致mykey的结果为11，而不是我们认为的12。为了解决类似的问题，我们需要借助WATCH命令的帮助，见如下代码：
　　WATCH mykey
　　val = GET mykey
　　val = val + 1
　　MULTI
　　SET mykey $val
　　EXEC
和此前代码不同的是，新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，
如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。
```
### 16.使用过Redis实现分布式锁【5+】
[Redis实现分布式锁](https://www.cnblogs.com/chenyanbin/p/13506946.html)
```markdown
什么是分布式锁？
    分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现。
    如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往通过互斥来防止彼此干扰。
为什么要有分布式锁？
    可以保证在分布式部署的应用集群中，同一个方法在同一操作只能被一台机器上的一个线程执行。
　　首先，为了确保分布式锁可用，至少要满足以下三个条件
        1.互斥性。在任意时刻，只有一个客户端能持有锁
        2.不会发生死锁。即便有一个客户端在持有锁的期间奔溃而没有主动解锁，也能保证后续其他客户端能加锁
        3.解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了
    设计要求#
        1.可重入锁(避免死锁)
        2.获取锁和释放锁高可用
        3.获取锁和释放锁高性能
实现方案#
    1.获取锁，使用setnx()：SETNX key val：当且仅当key不存在时，set一个key为val的字符串，返回1
    2.若key存在，则什么都不做，返回【0】加锁，锁的value值为当前占有锁服务器内网IP编号拼接任务标识
    3.在释放锁的时候进行判断。并使用expire命令为锁添加一个超时时间，超过该时间则自动释放锁
    4.返回1则成功获取锁。还设置一个获取的超时时间，若超过这个时间则放弃获取锁，setex(key,value,expire)过期以秒为单位
    5.释放锁的时候，判断是不是该锁(即value为当前服务器内网IP编号拼接任务标识)，若是该锁，则执行delete进行锁释放
Redis分布式锁有什么缺陷：
    Redis分布式锁不能解决超时的问题，分布式锁有一个超时时间，程序的执行如果超出了锁的超时时间就会出现问题。
```
### 17.假如Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？
```markdown
使用keys指令可以扫出指定模式的key列表。
　　对方接着追问：如果这个redis正在给线上的业务提供服务，那使用keys指令会有什么问题？
　　这个时候你要回答redis关键的一个特性：redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。
    这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。
```
### 18.使用过Redis做异步队列么，你是怎么用的？
```markdown
　一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
　　如果对方追问可不可以不用sleep呢？list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。
　　如果对方追问能不能生产一次消费多次呢？使用pub/sub主题订阅者模式，可以实现1:N的消息队列。
　　如果对方追问pub/sub有什么缺点？在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。
　　如果对方追问redis如何实现延时队列？我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。
        但是你很克制，然后神态自若的回答道：使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，
        消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。
　　到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。
```
### 20.如果有大量的key需要设置同一时间过期，一般需要注意什么？
```markdown
如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。
```
### 21.Redis持久化机制【5+】
>> RDB和AOF
```markdown
持久化就是把内存中的数据持久化到本地磁盘，防止服务器宕机了内存数据丢失
Redis提供两种持久化机制RDB（默认）和AOF机制
    RDB：是Redis DataBase缩写快照
    RDB是Redis默认的持久化方式。按照一定的时间将内存的数据以快照的形式保存到硬盘中，对应产生的数据文件为dump.rdb。
        通过配置文件中的save参数来定义快照的周期。
​        优点：
​        1）只有一个文件dump.rdb，方便持久化；
​        2）容灾性好，一个文件可以保存到安全的磁盘。
​        3）性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化。使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能。
​        4）相对于数据集大时，比AOF的启动效率更高。
​        缺点：
​        1）数据安全性低。RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
    AOF：持久化
​        AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中，当重启Redis会重新将持久化的日志中文件恢复数据。
​        优点：
​        1）数据安全，aof持久化可以配置appendfsync属性，有always，每进行一次 命令操作就记录到aof文件中一次。
​        2）通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题。
        缺点：
​        1）AOF文件比RDB文件大，且恢复速度慢。
​        2）数据集大的时候，比rdb启动效率低。
bgsave做镜像全量持久化，aof做增量持久化。因为bgsave会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要aof来配合使用。
在redis实例重启时，会使用bgsave持久化文件重新构建内存，再使用aof重放近期的操作指令来实现完整恢复重启之前的状态。
对方追问那如果突然机器掉电会怎样？取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。
    但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。
对方追问bgsave的原理是什么？你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，
    子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。
```
### 22.Pipeline有什么好处，为什么要用pipeline？
```markdown
可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。
    使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。
对于单线程阻塞式的Redis，Pipeline可以满足批量的操作，把多个命令连续的发送给Redis Server，然后一一解析响应结果。
    Pipelining可以提高批量处理性能，提升的原因主要是TCP连接中减少了“交互往返”的时间。
    pipeline 底层是通过把所有的操作封装成流，redis有定义自己的出入输出流。
    在sync()方法执行操作，每次请求放在队列里面，解析响应包。
```
### 23.Redis的同步机制了解么？【1+】
```markdown
Redis可以使用主从同步，从从同步。
第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，
待完成后将rdb文件全量同步到复制节点，复制节点接受完成后将rdb镜像加载到内存。
加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。
```
### 24.Redis集群，集群的原理是什么？【3+】
```markdown
Redis Sentinal着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。
Redis Cluster着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。
```
### 25.Redis跳跃表实现，为什么用skipList而不用红黑树【4+】
[跳跃表](https://redisbook.readthedocs.io/en/latest/internal-datastruct/skiplist.html)
[Redis之跳跃表](https://mp.weixin.qq.com/s?__biz=MzIwOTE2MzU4NA==&mid=2247485660&idx=1&sn=e07017245b18da214435a17ddd4afc18&chksm=97794cf3a00ec5e5339df417cb5781a18850b3da06575184598309c3920d9c20ad36d5ee64cc&mpshare=1&scene=23&srcid=0907qcv3VAXuQLpYpodSU0HB&sharer_sharetime=1599439506265&sharer_shareid=d812adcc01829f0f7f8fb06aea118511#rd)
[手写跳表主要参考JDK中的ConcurrentSkipListMap](https://www.cnblogs.com/tong-yuan/p/13630264.html)
```markdown
跳跃表以有序的方式在层次化的链表中保存元素， 效率和平衡树媲美 —— 查找、删除、添加等操作都可以在对数期望时间下完成， 并且比起平衡树来说， 跳跃表的实现要简单直观得多。
跳跃表主要由以下部分构成：
    - 表头（head）：负责维护跳跃表的节点指针。
    - 跳跃表节点：保存着元素值，以及多个层。
    - 层：保存着指向其他元素的指针。高层的指针越过的元素数量大于等于低层的指针，为了提高查找的效率，程序总是从高层先开始访问，然后随着元素值范围的缩小，慢慢降低层次。
    - 表尾：全部由 NULL 组成，表示跳跃表的末尾。
跳跃表在Redis的唯一作用， 就是实现有序集数据类型。查询的时间复杂度可以降低到O(logN)。
跳跃表将指向有序集的score值和member域的指针作为元素， 并以score值为索引， 对有序集元素进行排序。
小结
    跳跃表是一种随机化数据结构，查找、添加、删除操作都可以在对数期望时间下完成。
    跳跃表目前在Redis的唯一作用，就是作为有序集类型的底层数据结构（之一，另一个构成有序集的结构是字典）。
    为了满足自身的需求，Redis基 WilliamPugh论文中描述的跳跃表进行了修改，包括：
    1.score值可重复。
    2.对比一个元素需要同时检查它的score和memeber 。
    3.每个节点带有高度为 1 层的后退指针，用于从表尾方向向表头方向迭代。
[为什么用skipList而不用红黑树](https://www.zhihu.com/question/20202931)
1.skiplist的复杂度和红黑树一样，而且实现起来更简单。
2.在并发环境下skiplist有另外一个优势，红黑树在插入和删除的时候可能需要做一些rebalance的操作，这样的操作可能会涉及到整个树的其他部分，
    而skiplist的操作显然更加局部性一些，锁需要盯住的节点更少，因此在这样的情况下性能好一些。
```
### 26.redis的zset怎么实现的？（跳表）那跳表是用什么判断每隔几个选一个呢？（随机算法）【3+】
```markdown
​跳表(skip List)是一种随机化的数据结构，基于并联的链表，实现简单，插入、删除、查找的复杂度均为O(logN)。
    简单说来跳表也是链表的一种，只不过它在链表的基础上增加了跳跃功能，正是这个跳跃的功能，使得在查找元素时，跳表能够提供O(logN)的时间复杂度
​Zset数据量少的时候使用压缩链表ziplist实现，有序集合使用紧挨在一起的压缩列表节点来保存，第一个节点保存member，第二个保存score。
    ziplist内的集合元素按score从小到大排序，score较小的排在表头位置。
​数据量大的时候使用跳跃列表skiplist和哈希表hash_map结合实现，查找删除插入的时间复杂度都是O(longN)
搜索
​   跳跃表按 score 从小到大保存所有集合元素，查找时间复杂度为平均 O(logN)，最坏 O(N) 。
插入
  之前就说了，之所以选用链表作为底层结构支持，也是为了高效地动态增删。单链表在知道删除的节点是谁时，时间复杂度为O(1)，
    因为跳表底层的单链表是有序的，为了维护这种有序性，在插入前需要遍历链表，找到该插入的位置，单链表遍历查找的时间复杂度是O(n)，
    同理可得，跳表的遍历也是需要遍历索引数，所以是O(logn)。
删除
  删除的节点要分两种情况，如果该节点还在索引中，那删除时不仅要删除单链表中的节点，还要删除索引中的节点；另一种情况是删除的节点只在链表中，
   不在索引中，那只需要删除链表中的节点即可。但针对单链表来说，删除时都需要拿到前驱节点才可改变引用关系从而删除目标节点。
```
### redis的string底层是如何存储的【1+】
### redis如何保证实现高可用【2+】
### redis的5种常用数据结构，及其实现原理【6+】
```markdown
Redis主要有5种数据类型，包括String，List，Set，Zset，Hash
类型	       存储值	              应用场景
String	字符串、整数、浮点数	  简单的键值对缓存
List	  列表	            存储列表型数据结构，例如：评论列表、商品列表
Set	      无序集合	        适合交集、并集、查集操作，例如朋友关系
Zset	 有序集合	            去重后排序，适合排名场景
Hash	   哈希	                结构化数据，比如存储对象
String字符串:字符串类型是Redis最基础的数据结构，首先键都是字符串类型，而且其他几种数据结构都是在字符串类型基础上构建的，
    经常使用的set key value命令就是字符串。常用在缓存、计数、共享Session、限速等。字符串长度增加减少怎么处理
Hash哈希:在Redis中，哈希类型是指键值本身又是一个键值对结构，哈希可以用来存放用户信息，比如实现购物车。
List列表（双向链表）:列表（list）类型是用来存储多个有序的字符串。可以做简单的消息队列的功能。
Set集合：集合（set）类型也是用来保存多个的字符串元素，但和列表类型不一 样的是，集合中不允许有重复元素，并且集合中的元素是无序的，
    不能通过索引下标获取元素。利用Set的交集、并集、差集等操作，可以计算共同喜好，全部的喜好，自己独有的喜好等功能。
Sorted Set有序集合（跳表实现）：Sorted Set多了一个权重参数Score，集合中的元素能够按Score进行排列。可以做排行榜应用，取TOP N操作。
```
### redis保证缓存和数据库的数据一致性？【5+】
```markdown
方式一：
​    读请求和写请求串行化，串到一个内存队列里去，这样就可以保证一定不会出现不一致的情况。
    串行化之后，就会导致系统的吞吐量会大幅度的降低，用比正常情况下多几倍的机器去支撑线上的一个请求。
方式二：
​    先更新数据库，假如读缓存失败，先读数据库，再回写缓存的方式实现
1.合理设置缓存的过期时间
2.新增，更改，删除数据库操作时同步更新Redis，可以使用事务机制来保证数据的一致性。
```
### 分布式缓存和本地缓存有啥区别？让你自己设计本地缓存怎么设计？如何解决缓存过期问题？如何解决内存溢出问题？
```markdown
分布式缓存一致性更好一点，用于集群环境下多节点使用同一份缓存的情况；有网络IO，吞吐率与缓存的数据大小有较大关系；
本地缓存非常高效，本地缓存会占用堆内存，影响垃圾回收、影响系统性能。
本地缓存设计：
​   以Java为例，使用自带的map或者guava实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着jvm的销毁而结束，
    并且在多实例的情况，每个实例都需要各自保存一份缓存，缓存不具有一致性。
解决缓存过期：
​ 1、将缓存过期时间调为永久
​ 2、将缓存失效时间分散开，不要将缓存时间长度都设置成一样；比如我们可以在原有的失效时间基础上增加一个随机值，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
解决内存溢出：
​ 第一步，修改JVM启动参数，直接增加内存。(-Xms，-Xmx参数一定不要忘记加。)
　第二步，检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。
　第三步，对代码进行走查和分析，找出可能发生内存溢出的位置。
```
### redis热key问题？如何发现以及如何解决？
```markdown
Redis如何发现热点key
    1.凭借经验，进行预估：例如提前知道了某个活动的开启，那么就将此Key作为热点Key。
    2.服务端收集：在操作redis之前，加入一行代码进行数据统计。
    3.抓包进行评估：Redis使用TCP协议与客户端进行通信，通信协议采用的是RESP，所以自己写程序监听端口也能进行拦截包进行解析。
    4.在proxy层，对每一个 redis 请求进行收集上报。
    5.Redis自带命令查询：Redis4.0.4版本提供了redis-cli–hotkeys就能找出热点Key。
        （如果要用Redis自带命令查询时，要注意需要先把内存逐出策略设置为allkeys-lfu或者volatile-lfu，否则会返回错误。
        进入Redis中使用config set maxmemory-policy allkeys-lfu即可。）
​热点key存在问题：缓存中的一个Key(比如一个促销商品)，在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，
    这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。
Redis的热点key解决方案
    1.服务端缓存：即将热点数据缓存至服务端的内存中.(利用Redis自带的消息通知机制来保证Redis和服务端热点Key的数据一致性，
        对于热点Key客户端建立一个监听，当热点Key有更新操作的时候，服务端也随之更新。)
    2.备份热点Key：即将热点Key+随机数，随机分配至Redis其他节点中。这样访问热点key的时候就不会全部命中到一台机器上了。
```
### redis数据分布方式？有什么优点？一致性hash呢？
```markdown
Hash：
​   客户端分片：哈希+取余
​   节点伸缩：数据节点关系变化，导致数据迁移
​   迁移数量和添加节点数量有关：建议翻倍扩容
​   一个简单直观的想法是直接用Hash来计算，以Key做哈希后对节点数取模。可以看出，在key足够分散的情况下，均匀性可以获得，
        但一旦有节点加入或退出，所有的原有节点都会受到影响，稳定性无从谈起。
一致性Hash：
​   客户端分片：哈希+顺时针（优化取余）
​   节点伸缩：只影响邻近节点，但是还是有数据迁移
​   翻倍伸缩：保证最小迁移数据和负载均衡
​   一致性Hash可以很好的解决稳定问题，可以将所有的存储节点排列在收尾相接的Hash环上，每个key在计算Hash后会顺时针找到先遇到的一组存储节点存放。
   而当有节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续节点，将数据从该节点接收或者给予。
   但这有带来均匀性的问题，即使可以将存储节点等距排列，也会在存储节点个数变化时带来数据的不均匀。而这种可能成倍数的不均匀在实际工程中是不可接受的。
```
### redis主从复制【2+】
```markdown
主从复制原理：当启动一个slave node的时候，它会发送一个PSYNC命令给master node。
    如果这是slave node初次连接到master node，那么会触发一次full resynchronization全量复制。
    此时master会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端client新收到的所有写命令缓存在内存中。
    RDB文件生成完毕后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中，
    接着master会将内存中缓存的写命令发送到slave，slave也会同步这些数据。
    slave node如果跟master node有网络故障，断开了连接，会自动重连，连接之后master node仅会复制给slave部分缺少的数据。
过程原理
​   1、当从库和主库建立MS关系后，会向主数据库发送SYNC命令
​   2、主库接收到SYNC命令后会开始在后台保存快照(RDB持久化过程)，并将期间接收到的写命令缓存起来
​   3、当快照完成后，主Redis会将快照文件和所有缓存的写命令发送给从Redis
​   4、从Redis接收到后，会载入快照文件并且执行收到的缓存的命令
​   5、之后，主Redis每当接收到写命令时就会将命令发送从Redis，从而保证数据的一致
缺点
​   所有的slave节点数据的复制和同步都由master节点来处理，会照成master节点压力太大，使用主从从结构来解决
```
### redis哨兵机制
### redis线程模型和内存模型
### Redis实现布隆过滤器
### Redis实现LRU


## 二, MongoDB
### 1.MongoDB简介
```markdown
⾮关系型数据库(NoSql),Mongo DB很好的实现了⾯向对象的思想,在MongoDB中 每⼀条记录都是⼀个Document对象。
Mongo DB最⼤的优势在于所有的数据持久操作都⽆需开发⼈员⼿动编写SQL语句,直接调⽤⽅法就可以轻松的实现CRUD操作.
```
### 2.MongoDB特点
```markdown
⾼性能、易部署、易使⽤，存储数据⾮常⽅便。主要功能特性有：
⾯向集合存储，易存储对象类型的数据。
模式⾃由。
⽀持动态查询。
⽀持完全索引，包含内部对象。
⽀持查询。
⽀持复制和故障恢复。
使⽤⾼效的⼆进制数据存储，包括⼤型对象（如视频等）。
⾃动处理碎⽚，以⽀持云计算层次的扩展性
⽀持Python，PHP，Ruby，Java，C，C#，Javascript，Perl及C++语⾔的驱动程序，社区中也
提供了对Erlang及.NET等平台的驱动程序。
⽂件存储格式为BSON（⼀种JSON的扩展）。
可通过⽹络访问。
```
### 3.MongoDB主要功能
```markdown
⾯向集合的存储：适合存储对象及JSON形式的数据。
动态查询：Mongo⽀持丰富的查询表达式。查询指令使⽤JSON形式的标记，可轻易查询⽂档中内嵌的对象及数组。
完整的索引⽀持：包括⽂档内嵌对象及数组。Mongo的查询优化器会分析查询表达式，并⽣成⼀个⾼效的查询计划。
查询监视：Mongo包含⼀个监视⼯具⽤于分析数据库操作的性能。
复制及⾃动故障转移：Mongo数据库⽀持服务器之间的数据复制，⽀持主-从模式及服务器之间的相互复制。复制的主要⽬标是提供冗余及⾃动故障转移。
⾼效的传统存储⽅式：⽀持⼆进制数据及⼤型对象（如照⽚或图⽚）
⾃动分⽚以⽀持云级别的伸缩性：⾃动分⽚功能⽀持⽔平的数据库集群，可动态添加额外的机器
```
### 4.MongoDB适⽤场景
```markdown
⽹站数据：MongoDB⾮常适合实时的插⼊，更新与查询，并具备⽹站实时数据存储所需的复制及⾼度伸缩性。
缓存：由于性能很⾼，MongoDB也适合作为信息基础设施的缓存层。在系统重启之后，由MongoDB搭建的持久化缓存层可以避免下层的数据源 过载。
    ⼤尺⼨，低价值的数据：使⽤传统的关系型数据库存储⼀些数据时可能会⽐较昂贵，在此之前，很多时候程序员往往会选择传统的⽂件进⾏存储。
⾼伸缩性的场景：MongoDB⾮常适合由数⼗或数百台服务器组成的数据库。MongoDB的路线图中已经包含对MapReduce引擎的内置⽀持。
    ⽤于对象及JSON数据的存储：Mongo的BSON数据格式⾮常适合⽂档化格式的存储及查询。
```
### 5.Redis、memcache、MongoDB 对⽐
```markdown
mongodb是⽂档型的⾮关系型数据库，其优势在于查询功能⽐较强⼤，能存储海量数据。
memcached和redis。它们都是内存型数据库，数据保存在内存中，通过tcp直接存取，优势是速度快，并发⾼，缺点是数据类型有限，查询功能不强，⼀般⽤作缓存。
1. 性能
    redis和memcache差不多，要⼤于mongodb。
2. 操作的便利性
    memcache数据结构单⼀。
    redis丰富⼀些，数据操作⽅⾯，redis更好⼀些，较少的⽹络IO次数。
    mongodb⽀持丰富的数据表达，索引，最类似关系型数据库，⽀持的查询语⾔⾮常丰富。
3. 内存空间的⼤⼩和数据量的⼤⼩
    redis在2.0版本后增加了⾃⼰的VM特性，突破物理内存的限制；可以对key value设置过期时间（类似memcache）。
    memcache可以修改最⼤可⽤内存,采⽤LRU算法。
    mongoDB适合⼤数据量的存储，依赖操作系统VM做内存管理，吃内存也⽐较厉害，服务不要和别的服务在⼀起。
4. 可⽤性（单点问题）
    redis对于单点问题，依赖客户端来实现分布式读写；
    主从复制时，每次从节点重新连接主节点都要依赖整个快照,⽆增量复制，因性能和效率问题，所以单点问题⽐较复杂；
    不⽀持⾃动sharding,需要依赖程序设定⼀致hash 机制。
    ⼀种替代⽅案是，不⽤redis本身的复制机制，采⽤⾃⼰做主动复制（多份存储），或者改成增量复制的⽅式（需要⾃⼰实现），⼀致性问题和性能的权衡。
Memcache本身没有数据冗余机制，也没必要；对于故障预防，采⽤依赖成熟的hash或者环状的算法，解决单点故障引起的抖动问题。
mongoDB⽀持master-slave,replicaset（内部采⽤paxos选举算法，⾃动故障恢复）,autosharding机制，对客户端屏蔽了故障转移和切分机制。
5. 可靠性（持久化）
    对于数据持久化和数据恢复，redis⽀持（快照、AOF）：依赖快照进⾏持久化，aof增强了可靠性的同时，对性能有所影响。
    memcache不⽀持，通常⽤在做缓存,提升性能；
    MongoDB从1.8版本开始采⽤binlog⽅式⽀持持久化的可靠性。
6. 数据⼀致性（事务⽀持）
    Memcache 在并发场景下，⽤cas保证⼀致性。
    redis事务⽀持⽐较弱，只能保证事务中的每个操作连续执⾏。
    mongoDB不⽀持事务。
7. 数据分析
    mongoDB内置了数据分析的功能(mapreduce),其他不⽀持。
8. 应⽤场景
    redis：数据量较⼩的更性能操作和运算上。
    memcache：⽤于在动态系统中减少数据库负载，提升性能;做缓存，提⾼性能（适合读多写少，对于数据量⽐较⼤，可以采⽤sharding）。
    MongoDB:主要解决海量数据的访问效率问题。
```

## 三, ElasticSearch
>>  2.1 你们公司的ES集群，一个node一般会分配几个分片？
    2.2 Elasticsearch是如何实现Master选举的？
    2.3 你是如何做写入调优的？
    2.4 什么是脑裂？如何避免脑裂？
    2.5 Elasticsearch对于大数据量（上亿量级）的聚合如何实现？
    2.6 ES主分片数量可以在后期更改吗？为什么？
    2.7 如何监控集群状态？
    2.8 ElasticSearch中的副本是什么？
    2.9 ES更新数据的执行流程？
    2.10 shard里面是什么组成的？
    2.11 ElasticSearch中的分析器是什么？
    2.13 客户端在和集群连接时，如何选择特定的节点执行请求的？
    2.14 Elasticsearch中的倒排索引是什么？
    2.15 什么是索引？索引（名词） 一个索引(index)
    2.16 详细描述一下Elasticsearch更新和删除文档的过程
### 1.ElasticSearch介绍
```markdown
Elasticsearch（ES）是一个基于Lucene构建的开源分布式搜索分析引擎，可以近实时的索引、检索数据。具备高可靠、易使用、社区活跃等特点，
在全文检索、日志分析、监控分析等场景具有广泛应用。
由于高可扩展性，集群可扩展至百节点规模，处理PB级数据。通过简单的RESTful API即可实现写入、查询、集群管理等操作。
除了检索，还提供丰富的统计分析功能。以及官方功能扩展包XPack满足其他需求，如数据加密、告警、机器学习等。
另外，可通过自定义插件，如COS备份、QQ分词等满足特定功能需求。
```
### 2.Elasticsearch架构与原理
```markdown
基本概念 ：
    Cluster「集群」：由部署在多个机器的ES节点组成，以处理较大数据集和实现高可用；
    Node「节点」：机器上的ES进程，可配置不同类型的节点；
    Master Node「主节点」：用于集群选主。由其中一个节点担任主节点，负责集群元数据管理，如索引创建，节点离开加入集群等；
    Data Node「数据节点」：负责索引数据存储；
    Index「索引」：索引数据的逻辑集合，可类比关系型数据的DataBase；
    Shard「分片」：索引数据子集，通过将分片分配至集群不同节点，实现数据横向扩展。以解决单个节点CPU、内存、磁盘处理能力不足的情况；
    Primary Shard「主分片」：数据分片采用主从模式，由分片接收索引操作；
    Replica Shard「副本分片」：主分片的拷贝，以提高查询吞吐量和实现数据高可靠。主分片异常时，其中一个副本分片会自动提升为新的主分片。
内置自动发现实现 Zen discovery，当一个节点启动后，通过联系集群成员列表即可加入集群。
由其中一个节点担任主节点，用于集群元数据管理，维护分片在节点间的分配关系。当新节点加入集群后，Master节点会自动迁移部分分片至新节点，均衡集群负载。
分布式集群难免有节点故障。主节点会定期探测集群其他节点存活状态，当节点故障后，会将节点移出集群，并自动在其他节点上恢复故障节点上的分片。
主分片故障时会提升其中一个副本分片为主分片。其他节点也会探活主节点，当主节点故障后，会触发内置的类Raft协议选主，并通过设置最少候选主节点数，避免集群脑裂。
除了集群管理，索引数据读写也是我们关心的重要部分。ES采用peer-to-peer架构，每个节点保存全量分片路由信息，也就是每个节点均可以接收用户读写。

```

 
### 3.Elasticsearch应用场景
```markdown
ES的典型使用场景有日志分析、时序分析、全文检索等。
    1.日志实时分析场景
        日志从产生到可访问一般在10s级，相比于传统大数据解决方案的几十分钟、小时级时效性非常高。
        ES底层支持倒排索引、列存储等数据结构，使得在日志场景可以利用ES非常灵活的搜索分析能力。通过ES交互式分析能力，即使在万亿级日志的情况下，日志搜索响应时间也是秒级。
        日志处理的基本流程包含：日志采集->数据清洗->存储->可视化分析。Elastic Stack通过完整的日志解决方案，帮助用户完成对日志处理全链路管理。
            1.日志采集：通过轻量级日志采集组件FileBeat实时读取业务日志文件，发送数据至下游组件如Logstash。
            2.文本解析：利用正则解析等机制，将日志文本数据转换成结构化数据。可使用独立的Logstash服务或Elasticsearch内置的轻量级数据处理模块Ingest Pipeline，完成数据清洗和转换。
            3.数据存储：通过Elasticsearch搜索分析平台进行数据持久存储，提供全文搜索和分析能力。
            4.可视化分析：通过功能丰富的图形界面，即可对日志数据进行搜索分析，如可视化组件Kibana。
    2.时序分析场景
        时序数据是按时间顺序记录设备、系统状态变化的数据。典型的时序数据有传统的服务器监控指标数据、应用系统性能监控数据、智能硬件、工业物联网传感器数据等。
        ES提供灵活、多维度的统计分析能力，实现查看监控按照地域、业务模块等灵活的进行统计分析。
        另外，ES支持列存储、高压缩比、副本数按需调整等能力，可实现较低存储成本。最后时序数据也可通过Kibana组件轻松实现可视化。
    3.搜索服务场景
        通过ES高效倒排索引，以及自定义打分、排序能力与丰富的分词插件，实现全文检索需求。
```