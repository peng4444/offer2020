# 常用工具中间件面试题

## 六，中间件面试题
### Zookeeper
[ZooKeeper的十二连问，你顶得了嘛？](https://www.cnblogs.com/jay-huaxiao/p/13599519.html)
>>zookeeper节点类型、服务器角色，watch机制。
>>使用zookeeper实现分布式锁和读写锁。
#### 0.Zookeeper是什么？有什么功能？什么用途？
```markdown
zookeeper是一个分布式的开源的分布式应用程序协调服务，是Google chubby的开源实现的，是Hadoop和HBASE的重要组件。
它是一个分布式应用提供一致性服务的组件，功能包括：配置维护，域名服务，分布式同步，组服务等等。
zookeeper的功能：
    1.集群管理：监控节点存活状态，运行请求等等。
    2.主节点选举：主节点挂掉之后进行主节点选举。
    3.分布式锁：Zookeeper提供两种锁，独占锁和共享锁。
    4.命名服务：在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。
1.使用ZooKeeper作为「dubbo的注册中心」，使用ZooKeeper实现「分布式锁」。
2.ZooKeeper，它是一个开放源码的「分布式协调服务」，它是一个集群的管理者，它将简单易用的接口提供给用户。
3.可以基于Zookeeper实现诸如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列「等功能」。
4.Zookeeper的「用途」：命名服务、配置管理、集群管理、分布式锁、队列管理
```
#### 1.CAP定理
```markdown
一个分布式系统不可能在满足分区容错性（P）的情况下同时满足一致性（C）和可用性（A）。
    在此ZooKeeper保证的是CP，ZooKeeper不能保证每次服务请求的可用性，
    在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要重新请求才能获得结果。
    另外在进行leader选举时集群都是不可用，所以说，ZooKeeper不能保证服务可用性。
```
#### 2.BASE理论
```markdown
BASE理论是基本可用，软状态，最终一致性三个短语的缩写。
BASE理论是对CAP中一致性和可用性（CA）权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于CAP定理逐步演化而来的，它大大降低了我们对系统的要求。
    1.基本可用：基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。
        但是，这绝不等价于系统不可用。比如正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒。
    2.软状态：软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。
    3.最终一致性：最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。
        因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。
```
#### 3.ZooKeeper特点/特性
```markdown
Zookeeper 保证了如下分布式一致性特性：
「顺序一致性」：从同一客户端发起的事务请求，最终将会严格地按照顺序被应用到ZooKeeper中去。
「原子性」：所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，也就是说，要么整个集群中所有的机器都成功应用了某一个事务，要么都没有应用。
「单一视图」：无论客户端连到哪一个ZooKeeper服务器上，其看到的服务端数据模型都是一致的。
「可靠性：」 一旦服务端成功地应用了一个事务，并完成对客户端的响应，那么该事务所引起的服务端状态变更将会被一直保留下来。
「实时性（最终一致性）：」Zookeeper仅仅能保证在一定的时间段内，客户端最终一定能够从服务端上读取到最新的数据状态。
```
#### 4.ZAB协议
```markdown
ZAB协议包括两种基本的模式：崩溃恢复和消息广播。当整个Zookeeper集群刚刚启动或者Leader服务器宕机、重启或者网络故障导致不存在过半的服务器与
    Leader服务器保持正常通信时，所有服务器进入崩溃恢复模式，首先选举产生新的Leader服务器，然后集群中Follower服务器开始与新的Leader服务器进行数据同步。
    当集群中超过半数机器与该Leader服务器完成数据同步之后，退出恢复模式进入消息广播模式，Leader服务器开始接收客户端的事务请求生成事物提案（超过半数同意）来进行事务请求处理。
```
#### 5.选举算法和流程：FastLeaderElection(默认提供的选举算法)
```markdown
目前有5台服务器，每台服务器均没有数据，它们的编号分别是1,2,3,4,5,按编号依次启动，它们的选择举过程如下：
    1.服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking。
    2.服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的编号大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。
    3.服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的编号最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为leader，服务器1,2成为follower。
    4.服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的编号大，但之前服务器3已经胜出，所以服务器4只能成为follower。
    5.服务器5启动，后面的逻辑同服务器4成为follower。
```
#### 6.znode节点上的监听机制嘛？讲下Zookeeper watch机制
```markdown
zk类似于linux中的目录节点树方式的数据存储，即分层命名空间，zk并不是专门存储数据的，它的作用是主要是维护和监控存储数据的状态变化，
    通过监控这些数据状态的变化，从而可以达到基于数据的集群管理，zk中的节点的数据上限时1M。
client端会对某个znode建立一个watcher事件，当该znode发生变化时，这些client会收到zk的通知，然后client可以根据znode变化来做出业务上的改变等。
Watcher监听机制:
    Zookeeper允许客户端向服务端的某个Znode注册一个Watcher监听，当服务端的一些指定事件触发了这个Watcher，
    服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据 Watcher通知状态和事件类型做出业务上的改变。
Watcher监听机制的工作原理:
    ZooKeeper的Watcher机制主要包括客户端线程、客户端 WatcherManager、Zookeeper服务器三部分。
    客户端向ZooKeeper服务器注册Watcher的同时，会将Watcher对象存储在客户端的WatchManager中。
    当zookeeper服务器触发watcher事件后，会向客户端发送通知， 客户端线程从 WatcherManager 中取出对应的 Watcher 对象来执行回调逻辑。
Watcher特性总结:
    「一次性:」一个Watch事件是一个一次性的触发器。一次性触发，客户端只会收到一次这样的信息。
    「异步的：」Zookeeper服务器发送watcher的通知事件到客户端是异步的，不能期望能够监控到节点每次的变化，Zookeeper只能保证最终的一致性，而无法保证强一致性。
    「轻量级：」Watcher 通知非常简单，它只是通知发生了事件，而不会传递事件对象内容。
    「客户端串行：」执行客户端 Watcher 回调的过程是一个串行同步的过程。
    注册watcher用getData、exists、getChildren方法
    触发watcher用create、delete、setData方法

```
#### 7，zk部署方式
```markdown
单机部署：一台集群上运行
集群部署：多台集群上运行
伪集群部署：一台集群启动多个zookeeper实例运行
```
#### 8.Zookeeper怎么保证主从节点的状态同步
```markdown
zookeeper的核心是原子广播，这个机制保证了各个server之间的同步,实现这个机制的协议是ZAB协议。
```
#### 9.什么是命名服务，什么是配置管理，又什么是集群管理
```markdown
命名服务是指通过「指定的名字」来获取资源或者服务地址。Zookeeper可以创建一个「全局唯一的路径」，这个路径就可以作为一个名字。
    被命名的实体可以是「集群中的机器，服务的地址，或者是远程的对象」等。一些分布式服务框架（RPC、RMI）中的服务地址列表，通过使用命名服务，
    客户端应用能够根据特定的名字来获取资源的实体、服务地址和提供者信息等。
配置管理：实际项目开发中，我们经常使用.properties或者xml需要配置很多信息，如数据库连接信息、fps地址端口等等。
    因为你的程序一般是分布式部署在不同的机器上（如果你是单机应用当我没说），如果把程序的这些配置信息「保存在zk的znode节点」下，
    当你要修改配置，即znode会发生变化时，可以通过改变zk中某个目录节点的内容，利用「watcher通知给各个客户端」，从而更改配置。
集群管理包括集群监控和集群控制，其实就是监控集群机器状态，剔除机器和加入机器。
    zookeeper可以方便集群机器的管理，它可以实时监控znode节点的变化，一旦发现有机器挂了，该机器就会与zk断开连接，
    对用的临时目录节点会被删除，其他所有机器都收到通知。新机器加入也是类似酱紫，所有机器收到通知：有新兄弟目录加入啦。
```
#### 10.znode有几种类型呢？zookeeper的数据模型是怎样的呢？
```markdown
ZooKeeper的视图数据结构，很像Unix文件系统，也是树状的，这样可以确定每个路径都是唯一的。
zookeeper的节点统一叫做「znode」，它是可以通过「路径来标识」。
znode的4种类型:
    根据节点的生命周期，znode可以分为4种类型，分别是
    持久节点（PERSISTENT）:这类节点被创建后，就会一直存在于Zk服务器上。直到手动删除。
    持久顺序节点（PERSISTENT_SEQUENTIAL）:基本特性同持久节点，不同在于增加了顺序性。父节点会维护一个自增整性数字，用于子节点的创建的先后顺序。
    临时节点（EPHEMERAL）:临时节点的生命周期与客户端的会话绑定，一旦客户端会话失效（非TCP连接断开），那么这个节点就会被自动清理掉。zk规定临时节点只能作为叶子节点。
    临时顺序节点（EPHEMERAL_SEQUENTIAL）:基本特性同临时节点，添加了顺序的特性。
```
#### 11.znode节点里面存储的是什么吗？每个节点的数据最大不能超过多少呢？
```markdown
Znode数据节点的代码如下
public class DataNode implements Record {
    byte data[];                    
    Long acl;                       
    public StatPersisted stat;       
    private Set<String> children = null; 
}
Znode包含了「存储数据、访问权限、子节点引用、节点状态信息」，如
    「data:」  znode存储的业务数据信息
    「ACL:」 记录客户端对znode节点的访问权限，如IP等。
    「child:」 当前节点的子节点引用
    「stat:」 包含Znode节点的状态信息，比如「事务id、版本号、时间戳」等等。
为了保证高吞吐和低延迟，以及数据的一致性，znode只适合存储非常小的数据，不能超过1M，最好都小于1K。
```
#### 12.zookeeper是如何保证事务的顺序一致性
```markdown
聊一聊ZooKeeper的顺序一致性[1] https://time.geekbang.org/column/article/239261
```
#### 13.Zookeeper的服务器有几种角色嘛？Zookeeper下Server工作状态又有几种呢？
```markdown
Zookeeper集群中，有Leader、Follower和Observer三种角色
「Leader」:Leader服务器是整个ZooKeeper集群工作机制中的核心，其主要工作：
    事务请求的唯一调度和处理者，保证集群事务处理的顺序性
    集群内部各服务的调度者
「Follower」:Follower服务器是ZooKeeper集群状态的跟随者，其主要工作：
    处理客户端非事务请求，转发事务请求给Leader服务器
    参与事务请求Proposal的投票
    参与Leader选举投票
「Observer」:Observer是3.3.0 版本开始引入的一个服务器角色，它充当一个观察者角色——观察ZooKeeper集群的最新状态变化并将这些状态变更同步过来。
    其工作：处理客户端的非事务请求，转发事务请求给Leader服务器，不参与任何形式的投票
Zookeeper下Server工作状态
    服务器具有四种状态，分别是LOOKING、FOLLOWING、LEADING、OBSERVING。
    1.LOOKING：寻找Leader状态。当服务器处于该状态时，它会认为当前集群中没有Leader，因此需要进入Leader选举状态。
    2.FOLLOWING：跟随者状态。表明当前服务器角色是Follower。
    3.LEADING：领导者状态。表明当前服务器角色是Leader。
    4.OBSERVING：观察者状态。表明当前服务器角色是Observer。
```
#### 14.ZooKeeper集群部署图，ZooKeeper是如何保证主从节点数据一致性的呢？
![](https://mmbiz.qpic.cn/mmbiz_png/sMmr4XOCBzFFkTh1ZqMYxOHfdvVIATRpqf6IdWazIqAltZXeXIImvB3cd1rHKIg6Qo0l5KC0ouDQ7jVibKIwdLQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
```markdown
ZooKeeper集群是一主多从的结构：
    如果是写入数据，先写入主服务器（主节点），再通知从服务器。
    如果是读取数据，既读主服务器的，也可以读从服务器的。
ZooKeeper如何保证主从节点数据一致性
    我们知道集群是主从部署结构，要保证主从节点一致性问题，无非就是两个主要问题：
「主服务器挂了，或者重启了」
「主从服务器之间同步数据」
Zookeeper是采用ZAB协议（Zookeeper Atomic Broadcast，Zookeeper原子广播协议）来保证主从节点数据一致性的，
ZAB协议支持「崩溃恢复和消息广播」两种模式，很好解决了这两个问题：
    崩溃恢复：Leader挂了，进入该模式，选一个新的leader出来
    消息广播：把更新的数据，从Leader同步到所有Follower
```
#### 15.Zookeeper分布式锁的实现原理
```markdown
Zookeeper就是使用临时顺序节点特性实现分布式锁的。
    获取锁过程 （创建临时节点，检查序号最小）
    释放锁 （删除临时节点，监听通知）
获取锁过程
    当第一个客户端请求过来时，Zookeeper客户端会创建一个持久节点/locks。如果它（Client1）想获得锁，需要在locks节点下创建一个顺序节点lock1
    接着，客户端Client1会查找locks下面的所有临时顺序子节点，判断自己的节点lock1是不是排序最小的那一个，如果是，则成功获得锁。
    这时候如果又来一个客户端client2前来尝试获得锁，它会在locks下再创建一个临时节点lock2
    客户端client2一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock2是不是最小的，此时，发现lock1才是最小的，于是获取锁失败。
    获取锁失败，它是不会甘心的，client2向它排序靠前的节点lock1注册Watcher事件，用来监听lock1是否存在，也就是说client2抢锁失败进入等待状态。
    此时，如果再来一个客户端Client3来尝试获取锁，它会在locks下再创建一个临时节点lock3
    同样的，client3一样也会查找locks下面的所有临时顺序子节点，判断自己的节点lock3是不是最小的，发现自己不是最小的，就获取锁失败。
    它也是不会甘心的，它会向在它前面的节点lock2注册Watcher事件，以监听lock2节点是否存在。
释放锁:
    zookeeper的「客户端业务完成或者故障」，都会删除临时节点，释放锁。如果是任务完成，Client1会显式调用删除lock1的指令
    如果是客户端故障了，根据临时节点得特性，lock1是会自动删除的
    lock1节点被删除后，Client2可开心了，因为它一直监听着lock1。lock1节点删除，Client2立刻收到通知，也会查找locks下面的所有临时顺序子节点，发下lock2是最小，就获得锁。
    同理，Client2获得锁之后，Client3也对它虎视眈眈，啊哈哈~
```
#### 16.dubbo和Zookeeper的关系，为什么选择Zookeeper作为注册中心
```markdown
dubbo的注册中心可以选Zookeeper，memcached，redis等。为什么选择Zookeeper，因为它的功能特性咯~
    命名服务，服务提供者向Zookeeper指定节点写入url，完成服务发布。
    负载均衡，注册中心的承载能力有限，而Zookeeper集群配合web应用很容易达到负载均衡。
    zk支持监听事件，特别适合发布/订阅的场景，dubbo的生产者和消费者就类似这场景。
    数据模型简单，数据存在内存，可谓高性能
    Zookeeper其他特点都可以搬出来讲一下~
```

### Nginx
Nginx 反向代理实现高并发的具体步骤是什么？
Nginx 搭建 Tomcat 集群的核心配置应该怎么写？
#### 负载均衡算法
```markdown
轮询
加权轮询
随机算法
一致性Hash
```
#### 常见的限流算法
```markdown
常见的限流算法有计数器、漏桶和令牌桶算法。
    漏桶算法在分布式环境中消息中间件或者Redis都是可选的方案。
    发放令牌的频率增加可以提升整体数据处理的速度，而通过每次获取令牌的个数增加或者放慢令牌的发放速度和降低整体数据处理速度。
    而漏桶不行，因为它的流出速率是固定的，程序处理速度也是固定的。
```
### Netty
[Netty面试题（2020最新版）](https://blog.csdn.net/ThinkWon/article/details/104391081)
```markdown
说下Netty，bio、nio、aio区别，select、poll、epoll区别，什么是零拷贝机制。
```
## 七, 消息队列
### 消息队列的使用场景
[消息队列的使用场景](https://blog.csdn.net/fygu18/article/details/80863596)
[什么是消息中间件？主要作用是什么？](https://www.cnblogs.com/lm970585581/p/13590761.html)
```markdown
1.异步处理
    如用户注册后，需要发注册邮件和注册短信。传统的做法有两种：串行的方式和并行方式
    注册邮件，发送短信写入消息队列后，直接返回，因此写入消息队列的速度很快，基本可以忽略，因此用户的响应时间可能是50毫秒。
    因此架构改变后，系统的吞吐量提高到每秒20QPS。比串行提高了3倍，比并行提高了两倍！
2.应用解耦
    场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。
    传统模式的缺点：
    假如库存系统无法访问，则订单减库存将失败，从而导致订单失败，订单系统与库存系统耦合。
    引入消息队列后
    订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功
    库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作
    假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。
3.流量削锋
    应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。
    可以控制活动的人数，可以缓解短时间内高流量压垮应用。
4.日志处理
    是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题
5.消息通讯
    消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列，或者聊天室等。
    比如说交易系统下订单后可以通过Kafka去通知其他的系统如广告系统、推荐系统等
    Kafka采用发布订阅模型就是设计模式中的观察者模型
    发布订阅模型（Pub-Sub）使用主题（Topic）作为消息通信载体，类似于广播模式；发布者发布一条消息，该消息通过主题传递给所有的订阅者，在一条消息广播之后才订阅的用户则是收不到该条消息的。
```
### kafka
#### 1.Kafka是否可以脱离zookeeper使用
```markdown
Kafka不能脱离zookeeper单独使用，因为kafka使用zookeeper管理和协调kafka的节点服务器。
```
#### 2.kafka有几种数控保留策略
```markdown
kafka有两种数据保留策略：按照过期时间保留和按照存储的消息大小保留。
```
```markdown
#### Kafka 选主怎么做的？
kafka如何保证生产与消费都是同步的？
kafka 怎么保证不丢消息的
1. Kafka的特性？
2. Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？
3. 消费者重平衡（高可用性、伸缩性）
4. 那些情景下会造成消息漏消费？
5. 如何保证消息不被重复消费（幂等性）
6. KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？
7. Kafka生产者客户端中使用了几个线程来处理？分别是什么？
8. 消费者与生产者的工作流程：
9. topic的分区数可不可以增加？
Kafka、RabbitMQ、RocketMQ区别，为什么RabbitMQ时延最低，知道事务消息吗。
Kafka生产者、消费者、协调者、服务端工作机制，描述数据从生产端到消费端到过程。
如果出现数据丢失或者数据重复消费如何处理。
Kafka为什么高吞吐量。
Kafka是如何实现exactly once语义的。
让你设计一个消息队列，你会怎么设计。
```
#### Kafka的文件存储机制
```markdown
Kafka中消息是以topic进行分类的，生产者通过topic向Kafka broker发送消息，消费者通过topic读取数据。
    然而topic在物理层面又能以partition为分组，一个topic可以分成若干个partition。partition还可以细分为segment，
    一个partition物理上由多个segment组成，segment文件由两部分组成，分别为“.index”文件和“.log”文件，分别表示为segment索引文件和数据文件。
    这两个文件的命令规则为：partition全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。
```
#### Kafka 如何保证可靠性
```markdown
如果我们要往Kafka对应的主题发送消息，我们需要通过Producer完成。前面我们讲过Kafka主题对应了多个分区，每个分区下面又对应了多个副本；
    为了让用户设置数据可靠性，Kafka在Producer里面提供了消息确认机制。也就是说我们可以通过配置来决定消息发送到对应分区的几个副本才算消息发送成功。
    可以在定义Producer时通过acks参数指定。这个参数支持以下三种值：
    1.acks=0：意味着如果生产者能够通过网络把消息发送出去，那么就认为消息已成功写入Kafka。
        在这种情况下还是有可能发生错误，比如发送的对象无能被序列化或者网卡发生故障，但如果是分区离线或整个集群长时间不可用，那就不会收到任何错误。
        在acks=0模式下的运行速度是非常快的（这就是为什么很多基准测试都是基于这个模式），你可以得到惊人的吞吐量和带宽利用率，不过如果选择了这种模式，一定会丢失一些消息。
    2.acks=1：意味若Leader在收到消息并把它写入到分区数据文件（不一定同步到磁盘上）时会返回确认或错误响应。
        在这个模式下，如果发生正常的Leader选举，生产者会在选举时收到一个LeaderNotAvailableException异常，如果生产者能恰当地处理这个错误，
        它会重试发送悄息，最终消息会安全到达新的Leader那里。不过在这个模式下仍然有可能丢失数据，比如消息已经成功写入Leader，但在消息被复制到follower副本之前Leader发生崩溃。
    3.acks=all（这个和request.required.acks=-1 含义一样）：意味着Leader在返回确认或错误响应之前，会等待所有同步副本都收到悄息。
        如果和min.insync.replicas参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到悄息，生产者会一直重试直到消息被成功提交。
        不过这也是最慢的做法，因为生产者在继续发送其他消息之前需要等待所有副本都收到当前的消息。
```
#### Kafka消息是采用Pull模式，还是Push模式
```markdown
Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。
    在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：
        producer将消息推送到broker，consumer从broker拉取消息。
    push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。
    最终Kafka还是选取了传统的pull模式。
    Pull模式的另外一个好处是consumer可以自主决定是否批量的从broker拉取数据。
    Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。
    为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达。
```
#### Kafka是如何实现高吞吐率的
```markdown
1.顺序读写：kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能
2.零拷贝：跳过“用户缓冲区”的拷贝，建立一个磁盘空间和内存的直接映射，数据不再复制到“用户态缓冲区”
3.文件分段：kafka的队列topic被分为了多个区partition，每个partition又分为多个段segment，所以一个队列中的消息实际上是保存在N多个片段文件中
4.批量发送：Kafka允许进行批量发送消息，先将消息缓存在内存中，然后一次请求批量发送出去
5.数据压缩：Kafka还支持对消息集合进行压缩，Producer可以通过GZIP或Snappy格式对消息集合进行压缩
```
#### Kafka判断一个节点还活着的两个条件
```markdown
1.节点必须可以维护和ZooKeeper的连接，Zookeeper通过心跳机制检查每个节点的连接
2.如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久
```
### RocketMQ
[RocketMQ在面试中那些常见问题及答案+汇总](https://www.cnblogs.com/javazhiyin/p/13327925.html)
[消息队列之-RocketMQ入门](https://www.cnblogs.com/feifuzeng/p/13626472.html)
[未读消息（小红点），前端与 RabbitMQ实时消息推送实践，贼简单~](https://www.cnblogs.com/chengxy-nds/p/13633337.html)
#### 01.为什么要用RocketMq？
```markdown
吞吐量高：单机吞吐量可达十万级
可用性高：分布式架构
消息可靠性高：经过参数优化配置，消息可以做到0丢失
功能支持完善：MQ功能较为完善，还是分布式的，扩展性好
支持10亿级别的消息堆积：不会因为堆积导致性能下降
源码是java：方便我们查看源码了解它的每个环节的实现逻辑，并针对不同的业务场景进行扩展
可靠性高：天生为金融互联网领域而生，对于要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况
稳定性高：RoketMQ在上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验
```
#### 02.RocketMq的部署架构了解吗？
![](https://mmbiz.qpic.cn/mmbiz_png/MnVGSgCV6PJpMicR98FicHYo1x8r9QLy8H0WlTK06tPGNJLVlxkJEa1mGia3uFWMyG1CHTMDJDCGqb5Ft4YEMbsDg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
```markdown
rocketMq的集群架构图，里面包含了四个主要部分：NameServer集群,Producer集群,Cosumer集群以及Broker集群。
    NameServer 担任路由消息的提供者。生产者或消费者能够通过NameServer查找各Topic相应的Broker IP列表分别进行发送消息和消费消息。nameServer由多个无状态的节点构成，节点之间无任何信息同步
    broker会定期向NameServer以发送心跳包的方式，轮询向所有NameServer注册以下元数据信息：
        1）broker的基本信息（ip port等）
        2）主题topic的地址信息
        3）broker集群信息
        4）存活的broker信息
        5）filter 过滤器
    也就是说，每个NameServer注册的信息都是一样的，而且是当前系统中的所有broker的元数据信息
    Producer负责生产消息，一般由业务系统负责生产消息。一个消息生产者会把业务应用系统里产生的消息发送到broker服务器。RocketMQ提供多种发送方式，同步发送、异步发送、顺序发送、单向发送。同步和异步方式均需要Broker返回确认信息，单向发送不需要
    Broker，消息中转角色，负责存储消息、转发消息。在RocketMQ系统中负责接收从生产者发送来的消息并存储、同时为消费者的拉取请求作准备
    Consumer负责消费消息，一般是后台系统负责异步消费。一个消息消费者会从Broker服务器拉取消息、并将其提供给应用程序。从用户应用的角度而言提供了两种消费形式：拉取式消费、推动式消费
```
#### 03.它有哪几种部署类型？分别有什么特点？
```markdown
RocketMQ有4种部署类型
1）单Master
    单机模式, 即只有一个Broker, 如果Broker宕机了, 会导致RocketMQ服务不可用, 不推荐使用
2）多Master模式
    组成一个集群, 集群每个节点都是Master节点, 配置简单, 性能也是最高, 某节点宕机重启不会影响RocketMQ服务
    缺点：如果某个节点宕机了, 会导致该节点存在未被消费的消息在节点恢复之前不能被消费
3）多Master多Slave模式，异步复制
    每个Master配置一个Slave, 多对Master-Slave, Master与Slave消息采用异步复制方式, 主从消息一致只会有毫秒级的延迟
    优点是弥补了多Master模式（无slave）下节点宕机后在恢复前不可订阅的问题。在Master宕机后, 消费者还可以从Slave节点进行消费。
    采用异步模式复制，提升了一定的吞吐量。总结一句就是，采用多Master多Slave模式，异步复制模式进行部署，系统将会有较低的延迟和较高的吞吐量
    缺点就是如果Master宕机, 磁盘损坏的情况下, 如果没有及时将消息复制到Slave, 会导致有少量消息丢失
4）多Master多Slave模式，同步双写
    与多Master多Slave模式，异步复制方式基本一致，唯一不同的是消息复制采用同步方式，只有master和slave都写成功以后，才会向客户端返回成功
    优点：数据与服务都无单点，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高
    缺点就是会降低消息写入的效率，并影响系统的吞吐量
    实际部署中，一般会根据业务场景的所需要的性能和消息可靠性等方面来选择后两种
```
#### 04.你自己部署过RocketMq吗？简单说一下你当时部署的过程
#### 05.rocketmq如何保证高可用性？
```markdown
1）集群化部署NameServer。Broker集群会将所有的broker基本信息、topic信息以及两者之间的映射关系，轮询存储在每个NameServer中（也就是说每个NameServer存储的信息完全一样）。
    因此，NameServer集群化，不会因为其中的一两台服务器挂掉，而影响整个架构的消息发送与接收；
2）集群化部署多broker。producer发送消息到broker的master，若当前的master挂掉，则会自动切换到其他的master
    cosumer默认会访问broker的master节点获取消息，那么master节点挂了之后，该怎么办呢？它就会自动切换到同一个broker组的slave节点进行消费
    那么你肯定会想到会有这样一个问题：consumer要是直接消费slave节点，那master在宕机前没有来得及把消息同步到slave节点，那这个时候，不就会出现消费者不就取不到消息的情况了？
    这样，就引出了下一个措施，来保证消息的高可用性
3）设置同步复制
    前面已经提到，消息发送到broker的master节点上，master需要将消息复制到slave节点上，rocketmq提供两种复制方式：同步复制和异步复制
    异步复制，就是消息发送到master节点，只要master写成功，就直接向客户端返回成功，后续再异步写入slave节点
    同步复制，就是等master和slave都成功写入内存之后，才会向客户端返回成功
    那么，要保证高可用性，就需要将复制方式配置成同步复制，这样即使master节点挂了，slave上也有当前master的所有备份数据，那么不仅保证消费者消费到的消息是完整的，
    并且当master节点恢复之后，也容易恢复消息数据，在master的配置文件中直接配置brokerRole：SYNC_MASTER即可。
```
#### 06.rocketmq的工作流程是怎样的？
```markdown
RocketMq的工作流程如下：
1）首先启动NameServer。NameServer启动后监听端口，等待Broker、Producer以及Consumer连上来
2）启动Broker。启动之后，会跟所有的NameServer建立并保持一个长连接，定时发送心跳包。心跳包中包含当前Broker信息(ip、port等)、Topic信息以及Borker与Topic的映射关系
3）创建Topic。创建时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic
4）Producer发送消息。启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic所在的Broker；然后从队列列表中轮询选择一个队列，与队列所在的Broker建立长连接，进行消息的发送
5）Consumer消费消息。跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，进行消息的消费
```
#### 07.RocketMq使用哪种方式消费消息，pull还是push？
```markdown
RocketMq提供两种方式：pull和push进行消息的消费
而RocketMq的push方式，本质上也是采用pull的方式进行实现的。也就是说这两种方式本质上都是采用consumer轮询从broker拉取消息的
push方式里，consumer把轮询过程封装了一层，并注册了MessageListener监听器。当轮询取到消息后，便唤醒MessageListener的consumeMessage()来消费，对用户而言，感觉好像消息是被推送过来的
其实想想，消息统一都发到了broker，而broker又不会主动去push消息，那么消息肯定都是需要消费者主动去拉的喽~
```
#### 08.RocketMq如何负载均衡？
```markdown
1）producer发送消息的负载均衡：默认会轮询向Topic的所有queue发送消息，以达到消息平均落到不同的queue上；而由于queue可以落在不同的broker上，就可以发到不同broker上（当然也可以指定发送到某个特定的queue上）
2）consumer订阅消息的负载均衡：假设有5个队列，两个消费者，则第一个消费者消费3个队列，第二个则消费2个队列，以达到平均消费的效果。
    而需要注意的是，当consumer的数量大于队列的数量的话，根据rocketMq的机制，多出来的队列不会去消费数据，因此建议consumer的数量小于或者等于queue的数量，避免不必要的浪费
```
#### 09.RocketMq的存储机制了解吗？
```markdown
RocketMq采用文件系统进行消息的存储，相对于ActiveMq采用关系型数据库进行存储的方式就更直接，性能更高了
RocketMq与Kafka在写消息与发送消息上，继续沿用了Kafka的这两个方面：顺序写和零拷贝
1）顺序写
我们知道，操作系统每次从磁盘读写数据的时候，都需要找到数据在磁盘上的地址，再进行读写。而如果是机械硬盘，寻址需要的时间往往会比较长
而一般来说，如果把数据存储在内存上面，少了寻址的过程，性能会好很多；但Kafka 的数据存储在磁盘上面，依然性能很好，这是为什么呢？
这是因为，Kafka采用的是顺序写，直接追加数据到末尾。实际上，磁盘顺序写的性能极高，在磁盘个数一定，转数一定的情况下，基本和内存速度一致
因此，磁盘的顺序写这一机制，极大地保证了Kafka本身的性能
2）零拷贝
比如：读取文件，再用socket发送出去这一过程
buffer = File.read
Socket.send(buffer)
传统方式实现：
先读取、再发送，实际会经过以下四次复制
1、将磁盘文件，读取到操作系统内核缓冲区Read Buffer
2、将内核缓冲区的数据，复制到应用程序缓冲区Application Buffer
3、将应用程序缓冲区Application Buffer中的数据，复制到socket网络发送缓冲区
4、将Socket buffer的数据，复制到网卡，由网卡进行网络传输
小结：RocketMq采用文件系统存储消息，并采用顺序写写入消息，使用零拷贝发送消息，极大得保证了RocketMq的性能
```
#### 10.RocketMq的存储结构是怎样的？
```markdown
CommitLog-存储所有的消息元数据，包括Topic、QueueId以及message
CosumerQueue-消费逻辑队列：存储消息在CommitLog的offset
IndexFile-索引文件：存储消息的key和时间戳等信息，使得RocketMq可以采用key和时间区间来查询消息
也就是说，rocketMq将消息均存储在CommitLog中，并分别提供了CosumerQueue和IndexFile两个索引，来快速检索消息
```
#### 11.RocketMq如何进行消息的去重？
```markdown
RocketMq本身并不保证消息不重复，这样肯定会因为每次的判断，导致性能打折扣，所以它将去重操作直接放在了消费端：
1）消费端处理消息的业务逻辑保持幂等性。那么不管来多少条重复消息，可以实现处理的结果都一样
2）还可以建立一张日志表，使用消息主键作为表的主键，在处理消息前，先insert表，再做消息处理。这样可以避免消息重复消费
```
#### 12.RocketMq性能比较高的原因？
```markdown
RocketMq采用文件系统存储消息，采用顺序写的方式写入消息，使用零拷贝发送消息，这三者的结合极大地保证了RocketMq的性能。
```
###

##