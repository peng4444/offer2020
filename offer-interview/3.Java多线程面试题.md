# Java多线程与并发面试题

[TOC]


### 1.进程和线程的区别与联系【4+】
```markdown
进程是资源分配的基本单位。线程是独立调度的基本单位。一个进程中可以有多个线程，它们共享进程资源。
**拥有资源**：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
**调度**：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
**系统开销**：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等，所付出的开销远大于创建或撤销线程时的开销。
    类似地，在进行进程切换时，涉及当前执行进程CPU环境的保存及新调度进程CPU环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
**通信方面**：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC。
```
### 2.创建线程的四种实现方式【4+】
[多线程的四种实现方式](https://www.cnblogs.com/xpybsh/p/12818796.html)
#### 2.1 继承Thread类重写run()方法：
```markdown
  1. 创建一个继承于Thread类的子类
  2. 重写Thread类的run() --> 将此线程执行的操作声明在run()中
  3. 创建Thread类的子类的对象
  4. 通过此对象调用start()
```
#### 2.2 实现Runnable接口：
```markdown
  1. 创建一个实现Runnable接口的类
  2. 实现Runnable中的run()方法
  3. 创建实现类的对象
  4. 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象
  5. 通过Thread类的对象调用start()
```
#### 2.3 实现Callable接口
```markdown
 1.创建Callable的实现类
 2.实现call方法，将此线程需要执行的操作声明在call()中
 3.创建Callable接口实现类的对象
 4.将此Callable接口实现类的对象作为传递到FutureTask构造器中，创建FutureTask的对象
 5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()
 6.获取Callable中call方法的返回值
```
#### 2.4 线程池
```markdown
 1. 提供指定线程数量的线程池
 2.执行指定的线程的操作。需要提供实现Runnable接口或Callable接口实现类的对象
 3.关闭连接池
```
#### 2.5 Thread类和Runnable接口的比较
```markdown
由于Java“单继承，多实现”的特性，Runnable接口使用起来比Thread更灵活。Runnable接口出现更符合面向对象，将线程单独进行对象的封装。
Runnable接口出现，降低了线程对象和线程任务的耦合性。如果使用线程时不需要使用Thread类的诸多方法，显然使用Runnable接口更为轻量。
Runnable接口和Thread类创建线程的run方法没有返回值，Callable接口和Future类可以实现。
```
#### 2.6 如何实现处理线程的返回值
```markdown
1.主线程等待法
2.使用Thread类的join()阻塞当前线程以等待子线程处理完毕
3.通过Callable接口实现：通过FutureTask或者线程池获取
```
[参考资料：并发编程相关面试题四](https://www.cnblogs.com/Zzzzn/p/12586656.html)
[参考资料：Java 并发进阶常见面试题总结](https://www.cnblogs.com/wuwuyong/p/12169102.html)
### 3.Java线程的状态及主要转化⽅法(线程的生命周期？)【5+】
[深入理解Java线程状态转移](https://www.cnblogs.com/darope/p/12748184.html)
![线程状态转换https://www.cnblogs.com/darope/p/12748184.html](https://images.cnblogs.com/cnblogs_com/darope/1747012/o_200421111345%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E8%BD%AC%E7%A7%BB.png)
```markdown
NEW RUNNABLE(runnable&Running) BLOCKED WATTING TIMED_WAITING TERMINATED
1. 新建态(NEW)：一个线程被创建出来时候所处的状态 ；
2. 就绪态(runnable)：线程调用start()方法后，便处于可以被操作系统调度的状态，即就绪态。
            就绪状态可以由三处转化而来，新建态执行了start、线程阻塞结束、锁池等待队列中的线程获得了锁。
3. 运行态(RUNNing)：表示当前线程被操作系统调度，分配了时间片，执行线程中的run方法时的状态。
            运行态只可以由就绪态的线程转化而来，如果多个线程都处在就绪态，就等待操作系统分配。
4. 阻塞态(BLOCKED):表示当前线程被由于某种原因，被挂起，也就是被阻塞，正在运行的线程被阻塞后，
            即使结束阻塞状态也回不去运行态，只能回到就绪态，等待os分配cpu资源去调度。
5. 无限期等待（Waiting）：等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。
            进入方法：                                       退出方法：
            没有设置Timeout参数的Object.wait()方法       Object.notify() / Object.notifyAll()
            没有设置Timeout参数的Thread.join()方法       被调用的线程执行完毕
            LockSupport.park()方法                      LockSupport.unpark(Thread)
6. 限期等待（Timed Waiting）：无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。
            调用Thread.sleep()方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。
            调用Object.wait()方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。
            睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。
            阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用Thread.sleep()和Object.wait()等方法进入。
              进入方法                                       退出方法
            Thread.sleep() 方法                              时间结束
            设置了Timeout参数的Object.wait()方法       时间结束/Object.notify()/Object.notifyAll()
            设置了Timeout参数的Thread.join()方法       时间结束/被调用的线程执行完毕
            LockSupport.parkNanos()方法               LockSupport.unpark(Thread)
            LockSupport.parkUntil()方法               LockSupport.unpark(Thread)
7. 结束（Terminated）：可以是线程结束任务之后自己结束，或者产生了异常而结束。
```
### 4.线程start()的两个问题
```markdown
1. 反复调用同一个线程的start()方法是否可行？ 不可行，在第一次调用之后ThreadStatus的值改变，反复调用会报异常。
2. 假如一个线程执行完毕（此时处于TERMINATED状态），再次调用这个线程的start()方法是否可行？
```
### 5.多线程start()和run()方法的区别，sleep()和yield()方法的区别【2+】
```markdown
start()实际上通过本地方法start0()启动线程，会新运行一个线程，新线程会调用run()方法。
run()方法：target是Runnable对象，run()直接调用Thread线程的Runnable成员的run()方法，并不会新建一个线程。
1.- 依赖线程优先级：sleep()方法暂停当前线程后，会给其他线程执行机会，而不在乎其他线程的优先级；
    yield()方法暂停当前线程后，只会给优先级相同或更高的线程执行机会。
2.- 线程转入状态：sleep()方法将线程转入阻塞状态，知道经过阻塞时间才会转入就绪状态；
    yield()方法不会将线程转入阻塞状态，而是将线程转入就绪状态。
3.- 异常声明：sleep()方法声明抛出了InterruptedException异常；yield()方法未声明抛出异常。
4.- 可移植性：sleep()方法的移植性比yield()方法好，所以一般使用sleep()方法控制并发编程。
```
### 4.CAS无锁机制
```markdown
CAS：Compare and Swap，即比较交换；
　　jdk1.5增加了并发包java.util.concurrent.*，其下面的类使用CAS算法实现了区别于synchronized同步锁的一种乐观锁。
    jdk1.5之前java是靠synchronized关键字保证同步的，是一种独占锁，也是悲观锁；本身无锁，采用乐观锁的思想，
    在数据操作时对比数据是否一致，如果一致代表之前没有线程操作该数据，那么就会更新数据，如果不一致代表有县城更新则重试；
　　CAS当中包含三个参数CAS(V,E,N)，V标识要更新的变量，E标识预期值，N标识新值　　
　　运行过程：
　　　　1.线程访问时，先会将主内存中的数据同步到线程的工作内存当中；
　　　　2.假设线程A和线程B都有对数据进行更改，那么假如线程A先获取到执行权限；
　　　　3.线程A先会对比工作内存当中的数据和主内存当中的数据是否一致，如果一致（V==E）则进行更新，不一致则刷新数据，重新循环判断；
　　　　4.这时更新完毕后，线程B也要进行数据更新，主内存数据和工作内存数据做对比，如果一致则进行更新，
        不一致则将主内存数据重新更新到工作内存，然后循环再次对比两个内存中的数据，直到一致为止；　
　　CAS无锁机制存在一个问题
　　　　ABA问题，如果将原来A的值改为了B，然后又改回了A，虽然最终结果没有发生改变，但是在过程中是对该数据进行了修改操作
　　　　解决该问题：在Java中并发包下有一个原子类：AtomicStampedReference，在该类当中通过版本控制判断值到底是否被修改
　　　　解释：如果对值进行了更改则版本号+1，那么在CAS当中不仅仅对比变量的值，还要对比版本号，如果值和版本号都相等则代表没有被修改，
        如果有一方不相等代表进行过更改，那么就从主内存中重新刷新数据到工作内存然后循环对比，直到成功为止~
```
### 4. AQS【1+】
```markdown
AQS:全称AbstractQueueSynchronizer，抽象队列同步器，这个类在java.util.concurrent.locks包下
它是一个底层同步工具类，比如CountDownLatch,Sammphore，ReentrantLock,ReentrantReadWriteLock等等都是基于AQS底层三个内容：
　　　　　　1.state（用于计数器）
　　　　　　2.线程标记（哪一个线程加的锁）
　　　　　　3.阻塞队列（用于存放阻塞线程）
AQS提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架，如下图所示。AQS为一系列同步器依赖于一个单独的原子变量（state）
的同步器提供了一个非常有用的基础。子类们必须定义改变state变量的protected方法，这些方法定义了state是如何被获取或释放的。
```
### 5. ReentrantLock底层实现【2+】
```markdown
ReentrantLock是基于AQS的，AQS是Java并发包中众多同步组件的构建基础，它通过一个int类型的状态变量state和一个FIFO队列来完成共享资源的获取，
线程的排队等待等。AQS是个底层框架，采用模板方法模式，它定义了通用的较为复杂的逻辑骨架，比如线程的排队，阻塞，唤醒等，将这些复杂但实质通用的部分抽取出来，
这些都是需要构建同步组件的使用者无需关心的，使用者仅需重写一些简单的指定的方法即可（其实就是对于共享变量state的一些简单的获取释放的操作）。
synchronized是ReentrantLock内部实现的一个同步组件，它是Reentrantlock的一个静态内部类，继承于AQS；
```
### 6.Java开发中用过哪些锁【2+】
```markdown
1、乐观锁
　　乐观锁顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。
    乐观锁适用于多读的应用类型，这样可以提高吞吐量，在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS(Compare and Swap 比较并交换)实现的
　　乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升；　　
　　乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。
2、悲观锁
　　悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。
    比如Java里面的同步原语synchronized关键字的实现就是悲观锁。
　　悲观锁适合写操作非常多的场景；悲观锁在Java中的使用，就是利用各种锁；
3、独享锁
　　独享锁是指该锁一次只能被一个线程所持有。
　　独享锁通过AQS来实现的，通过实现不同的方法，来实现独享锁。对于Synchronized而言，当然是独享锁。
4、共享锁
　　共享锁是指该锁可被多个线程所持有。
　　读锁的共享锁可保证并发读是非常高效的，读写，写读，写写的过程是互斥的。
　　共享锁也是通过AQS来实现的，通过实现不同的方法，来实现共享锁。
5、互斥锁
　　互斥锁在Java中的具体实现就是ReentrantLock。
6、读写锁
　　读写锁在Java中的具体实现就是ReadWriteLock。
7、可重入锁　　　　
　　重入锁也叫作递归锁，指的是同一个线程外层函数获取到一把锁后，内层函数同样具有这把锁的控制权限；
　　synchronized和ReentrantLock就是重入锁对应的实现；
　　synchronized重量级的锁 ；ReentrantLock轻量级的锁；
8、公平锁
　　公平锁是指多个线程按照申请锁的顺序来获取锁。
　　对于Java ReetrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。
9、非公平锁
　　非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。　　
　　对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。
10、分段锁
　　分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。
　　我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7和JDK8中HashMap的实现）的结构，
    即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock）。
　　当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在哪一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。
　　但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。
　　分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。
11、偏向锁　　
　　偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
12、轻量级锁
　　轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
13、重量级锁
　　重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让他申请的线程进入阻塞，性能降低。
14、自旋锁
　　在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。
```
### 7.synchronized关键字理解【2+】
```markdown
使用了synchronized关键字可以轻松地解决多线程共享数据同步问题。
　　synchronized关键字修饰实例方法，修饰静态方法，修饰代码块
    synchronized可作用于instance变量、object reference（对象引用）、static函数和class literals(类名称字面常量)身上。 
　　synchronized取得的锁都是对象；每个对象只有一个锁（lock）与之相关联；实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。
　　synchronized的4种用法：
　　　　1. 方法声明时使用,线程获得的是成员锁；
　　　　2. 对某一代码块使用,synchronized后跟括号,括号里是变量,线程获得的是成员锁；
　　　　3. synchronized后面括号里是一对象,此时,线程获得的是对象锁；
　　　　4. synchronized后面括号里是类,此时,线程获得的是对象锁；
庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了。
JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。
synchronized的不足之处:
    1.如果临界区是只读操作，其实可以多线程一起执行，但是使用synchronized的话，同一时间只能有一个线程执行。
    2.synchronized无法知道线程有没有成功获取到锁。
    3.使用synchronized，如果临界区因为IO或者sleep方法等原因阻塞了，而当前线程没有释放锁，就会导致所有线程等待
```
### 8.ReentrantLock和synchronized之间的区别
```markdown
两者都是可重入锁：
原始构成：synchronized是JVM层面实现的；ReentrantLock是JDKAPI层面实现。说白了就是是操作系统来实现，还是用户自己敲代码实现。
使用方法：
1.synchronized加锁和解锁自动进行，不必担心最后是否释放锁；ReentrantLock加锁和解锁需要手动进行，且次数需一样，否则其他线程无法获得锁。
2.synchronized竞争锁时会一直等待；ReentrantLock可以尝试获取锁，并得到获取结果。
3.synchronized不可中断，获取锁无法设置超时；ReentrantLock可以中断，可以设置获取锁的超时时间。
4.synchronized只能是非公平锁，无法实现公平锁；ReentrantLock可以满足公平锁，即先等待先获取到锁,也可以满足非公平锁，默认非公平锁。
5.synchronized控制等待和唤醒需要结合加锁对象的wait()和notify()、notifyAll(),随机唤醒或者全部唤醒；
    ReentrantLock控制等待和唤醒需要结合Condition的await()和signal()、signalAll()方法，可以实现分组精确唤醒线程。
6.synchronized在加锁代码块执行完或者出现异常，自动释放锁；ReentrantLock不会自动释放锁，需要在finally{}代码块显示释放。
ReentrantLock锁的细粒度和灵活度，都明显优于synchronized。
```
```java
//题目:多线程之间按顺序调用，实现A->B->C三个线程启动，要求如下：
//打印5次，BB打印10次，CC打印15次
//紧接着 打印5次，BB打印10次，CC打印15次 来十次
class ShareResource{
    private int number = 1;//A:1,B:2,C:3
    private Lock lock = new ReentrantLock();
    private Condition c1 = lock.newCondition();
    private Condition c2 = lock.newCondition();
    private Condition c3 = lock.newCondition();   
    public void print5(){
        lock.lock();
        try{
            //1判断
            while(number!=1){
               c1.await();
            }
            //2.干活
            for(int i = 1;i<=5;i++){
                System.out.println(Thread.currentThread().getName()+i);
            }
            //3.通知
            number = 2;
            c2.signal();
        }catch (Exception e){
            e.printStackTrace();
        }finally{
            lock.unlock();
        }
    }
    
    public void print10(){
            lock.lock();
            try{
                //1判断
                while(number!=2){
                   c2.await();
                }
                //2.干活
                for(int i = 1;i<=5;i++){
                    System.out.println(Thread.currentThread().getName()+i);
                }
                //3.通知
                number = 2;
                c3.signal();
            }catch (Exception e){
                e.printStackTrace();
            }finally{
                lock.unlock();
            }
        }
    
    public void print15(){
            lock.lock();
            try{
                //1判断
                while(number!=3){
                   c3.await();
                }
                //2.干活
                for(int i = 1;i<=5;i++){
                    System.out.println(Thread.currentThread().getName()+i);
                }
                //3.通知
                number = 1;
                c1.signal();
            }catch (Exception e){
                e.printStackTrace();
            }finally{
                lock.unlock();
            }
        }
    
}
public class Demo{
    public static void main(String[] args){
      ShareResource shareResource = new ShareResource();
      new Thread(()->{
          for(int i = 1;i<=10;i++){
              shareResource.print5();
          }
      },"A").start();
      new Thread(()->{
                for(int i = 1;i<=10;i++){
                    shareResource.print10();
                }
            },"B").start();
      new Thread(()->{
                for(int i = 1;i<=10;i++){
                    shareResource.print15();
                }
            },"C").start();
    }
}
```
### 9.volatile特性【4+】
>> volatile作用？底层实现？禁止重排序的场景？单例模式中volatile的作用？
[面试中的volatile关键字](https://www.cnblogs.com/ArvinYL/p/12827641.html)
```markdown
被volatile修饰的共享变量，就具有了以下两点特性：
    保证了不同线程对该变量操作的**内存可见性**
    禁止指令重排序(有序性)
内存可见性:
    可见性是指一个线程修改了共享变量的值，其他线程能够立即得知这个修改。
    volatile变量保证新值能够立马同步到主内存，使用时也立即从主内存中刷新，保证了多线程操作时变量的可见性。
JMM的特性：原子性，有序性，可见性。
    原子性即一个操作或一系列操作是不可中断的。即使是在多线程的情况下，操作一旦开始，就不会被其他线程干扰。
    有序性是指对于单线程的执行代码，执行是按顺序依次进行的。
    但在多线程环境中，则可能出现乱序现象，因为在编译过程中会出现“指令重排”，重排后的指令与原指令的顺序未必一致。
指令重排：
    CPU和编译器为了提高程序执行的效率，会按照一定的规则允许进行指令优化。
    但代码逻辑之间是存在一定的先后顺序，并发执行时按照不同的执行逻辑会得到不同的结果。    
volatile不能保证原子性，它只是对单个volatile变量的读/写具有原子性，但是对于类似i++的复合操作就无法保证。
volatile+synchronized实现单例模式的双重检查锁
```
### 10.synchronized和volatile的区别
```markdown
volatile本质是在告诉JVM当前变量寄存器(工作内存)中的值是不确定的，需要从主存中读取；
synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
volatile只能用于变量，而synchronized可以修饰方法和代码块。volatile关键字是线程同步的轻量级实现，性能比synchronized要好。
多线程访问volatile不会发生阻塞，而synchronized可能发生阻塞。
volatile能够保证数据的可见性，但是不能保证数据的原子性，synchronized两者都能保证。
volatile主要是解决变量在多个线程之间的可见性，synchronized解决多个线程之间访问资源的同步性。
volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。
```
### 11.当⼀个线程进⼊⼀个对象的⼀个synchronized⽅法后，其它线程是否可进⼊此对象的其它⽅法?
```markdown
其他⽅法前是否加了synchronized关键字，如果没加，则能。
如果这个⽅法内部调⽤了wait，则可以进⼊其他synchronized⽅法。
如果其他个⽅法都加了synchronized关键字，并且内部没有调⽤wait，则不能。
如果其他⽅法是static，它⽤的同步锁是当前类的字节码，与⾮静态的⽅法不能同步，因为⾮静态的⽅法⽤的是this。
```
### 11.sleep()和wait()的区别联系【必考点2+】
```markdown
1.wait()是Object的方法，而sleep()是Thread的静态方法；
2.wait可以指定时间，也可以不指定；而sleep必须指定时间。
3.wait释放cpu资源，同时释放锁；sleep释放cpu资源，但是不释放锁，所以易死锁。
4.wait必须放在同步块或同步方法中，而sleep可以再任意位置。
5.sleep()通常被用于暂停执行，而wait()通常被用于线程间交互和通信。
【加分项】.在调用wait方法之后，线程会变为WATING状态，而调用sleep方法之后，线程会变为TIMED_WAITING状态。
【加分项】.进入wait状态的线程能够被notify和notifyAll线程唤醒，而sleep状态的线程不能被notify方法唤醒。
```
#### [加分项>>如何证明sleep不释放锁，而wait释放锁？](https://mp.weixin.qq.com/s?__biz=MzU1NTkwODE4Mw==&mid=2247487370&idx=1&sn=90c0bd01fd490b680eae9b60515e5e5f&chksm=fbcc62b2ccbbeba43cdaa4e95a8263ac7bd9dc42bf75b9060ff0354e724e0bc2215dda232b10&mpshare=1&scene=23&srcid=0721tKj84e0eLyXf3j5gmaqW&sharer_sharetime=1595339628839&sharer_shareid=d812adcc01829f0f7f8fb06aea118511#rd)
```markdown
wait()释放锁
    给wait()和notify()两个方法上了同一把锁（locker），但在调用完wait()方法之后locker锁就被释放了，所以程序才能正常执行notify()的代码，
    因为是同一把锁，如果不释放锁的话，是不会执行notify()的代码的，这一点也可以从打印的结果中证实（结果输出顺序），所以综合以上情况来说wait()方法是释放锁的。
sleep()不释放锁
    sleep(1000)方法（行号：11）执行之后，调用notify()方法并没有获取到locker锁，从上述执行结果中可以看出，
    而是执行完sleep(1000)方法之后才执行的notify()方法，因此可以证明调用sleep()方法并不会释放锁。
```
```java
public class WaitDemo {
    private static Object locker = new Object();

    public static void main(String[] args) throws InterruptedException {
        WaitDemo waitDemo = new WaitDemo();

        // 启动新线程，防止主线程被休眠
        new Thread(() -> {
            try {
                waitDemo.doWait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();
        Thread.sleep(200); // 此行本身没有意义，是为了确保 wait() 先执行再执行 notify()
        waitDemo.doNotify();
    }

    /**
     * 执行 wait()
     */
    private void doWait() throws InterruptedException {
        synchronized (locker) {
            System.out.println("wait start.");
            locker.wait();
            System.out.println("wait end.");
        }
    }

    /**
     * 执行 notify()
     */
    private void doNotify() {
        synchronized (locker) {
            System.out.println("notify start.");
            locker.notify();
            System.out.println("notify end.");
        }
    }
}
//以上程序的执行结果为：
//  wait start. 
//  notify start. 
//  notify end. 
//  wait end.
```
```java
public class WaitDemo {
    private static Object locker = new Object();

    public static void main(String[] args) throws InterruptedException {
        WaitDemo waitDemo = new WaitDemo();
        // 启动新线程，防止主线程被休眠
        new Thread(() -> {
            synchronized (locker) {
                try {
                    System.out.println("sleep start.");
                    Thread.sleep(1000);
                    System.out.println("sleep end.");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }).start();

        Thread.sleep(200);
        waitDemo.doNotify();
    }

    /**
     * 执行 notify()
     */
    private void doNotify() {
        synchronized (locker) {
            System.out.println("notify start.");
            locker.notify();
            System.out.println("notify end.");
        }
    }
}
//以上程序的执行结果为：
//  sleep start. 
//  sleep end. 
//  notify start. 
//  notify end.
```
### 12.notify()和notifyAll()有什么区别？【2+】
```markdown
notify():方法唤醒一个正在等待池的线程进入锁池去竞争获取锁的机会，如果有多个这样的线程，就会随机唤醒。
notifyAll():唤醒所有正在等待池的线程全部进入锁池区竞争获取锁的机会。
    唤醒不等于就能执行，需要得到锁对象才能有权利继续执行，而锁只有一把，所以多个线程被唤醒时需要争取该锁。
```
### 13. BIO、NIO、AIO有什么区别？
```markdown
BIO：线程发起IO请求，不管内核是否准备好IO操作，从发起请求起，线程一直阻塞，直到操作完成。(InputStream、OutputStream、Reader、Writer)
NIO：线程发起IO请求，立即返回；内核在做好IO操作的准备之后，通过调用注册的回调函数通知线程做IO操作，线程开始阻塞，直到操作完成。
    (Channels、Buffers、Selectors)
AIO：线程发起IO请求，立即返回；内存做好IO操作的准备之后，做IO操作，直到操作完成或者失败，通过调用注册的回调函数通知线程做IO操作完成或者失败。
BIO 是一个连接一个线程。,NIO是一个请求一个线程。,AIO是一个有效请求一个线程。
BIO：同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。
NIO：同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。
AIO：异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的IO请求都是由OS先完成了再通知服务器应用去启动线程进行处理。
IO多路复用：调用系统级别的select、poll、epoll
```
### 14.死锁编码及定位分析【2+】
```markdown
死锁是什么：死锁是指两个或两个以上的进程在执行过程中，因为争夺资源而造成的一种互相等待的现象。
死锁的必要条件：
     互斥条件 (Mutual exclusion)：资源不能被共享，只能由一个进程使用。
     请求与保持条件 (Hold and wait)：已经得到资源的进程可以再次申请新的资源。
     非抢占条件 (No pre-emption)：已经分配的资源不能从相应的进程中被强制地剥夺。
     循环等待条件 (Circular wait)：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源。
发生死锁时，上面的情况必须同时会发生。如果其中任意一个条件不会成立，死锁就不会发生。可以通过破坏其中任意一个条件来破坏死锁。
死锁的处理策略：
     鸵鸟策略：忽略死锁带来的影响
     死锁检测与死锁恢复（检测死锁并回复死锁，死锁发生时对其进行检测，一旦发生死锁后，采取行动解决问题）
        从死锁中恢复：通过抢占进行恢复,通过回滚进行恢复,杀死进程恢复。
     死锁预防（通过仔细分配资源来避免死锁）
     死锁避免（通过破坏死锁产生的四个条件之一来避免死锁）
        单个资源的银行家算法，破坏死锁，破坏互斥条件，破坏保持等待的条件，破坏不可抢占条件，破坏循环等待条件。
```
```java
class HoldLockThed implements Runnable{
    private String lockA;
    private String lockB;
    public HoldLockThread(String lockA,String lockB){
        this.lockA = lockA;
        this.lockB = lockB;
    }
    
    @Override
    public void run(){
        synchronized (lockA){
            System.out.println(Thread.currentThread().getName()+"自己持有："+lockA+"尝试获得："+lockB);
            //暂停一会线程
                            try {
                                TimeUnit.MILLISECONDS.sleep(200);
                            } catch (InterruptedException e) {
                                e.printStackTrace();
                            }
            synchronized (lockB){
                        System.out.println(Thread.currentThread().getName()+"自己持有："+lockA+"尝试获得："+lockB);
                    }
        }
    }
}
public class DeadLockDemo{
    public static void main(String[] args){
      String lockA = "lockA";
      String lockB = "lockB";
      
      new Thread(new HoldLockThread(lockA,lockB),"ThreadAAA").start();//线程持有A,想要获取B
      new Thread(new HoldLockThread(lockB,lockA),"ThreadBBB").start();//线程持有B,想要获取A
    }
}
```
### 线程池【5+】
>> Execuors类实现的几种线程池类型，最后如何返回？
>> 如何构造线程池，它的参数，饱和策略？
>> 公平锁和非公平锁区别？为什么公平锁效率低？
>> Java线程池原理介绍一下
>> 2.不用线程池的话，需要一个线程就创一个线程，会出现什么问题
```markdown

```
### 并发/同步工具类【2+】
>> CountDownLatch、CyclicBarrier、Semaphore介绍
```markdown

```
### 原子类Atomic【1+】
[像宝石一样的Java原子类](https://www.cnblogs.com/upnote/p/12972751.html)
```markdown
 Atomic包中的类基本的特性就是在多线程环境下，当有多个线程同时对单个（包括基本类型及引用类型）变量进行操作时，具有排他性，
即当多个线程同时对该变量的值进行更新时，仅有一个线程能成功，而未成功的线程可以向自旋锁一样，继续尝试，一直等到执行成功。
 Atomic系列的类中的核心方法都会调用unsafe类中的几个本地方法。因此atomic证原子性就是通过:自旋+CAS（乐观锁）
 Lock类和Atomic包底层实现都是通过CAS+自旋的方式解决多线程同步问题。Atomic在竞争激烈时能维持常态，比lock性能好，但是只能同步一个变量。
```
[比AtomicLong更优秀的LongAdder确定不来了解一下吗？](https://www.cnblogs.com/wang-meng/p/12892695.html)
```markdown
count++操作，使用AtomicInteger count = new AtomicInteger();count.addAndGet(1);
如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观锁的重试次数）。
AtomicLong：能保证并发情况下计数的准确性，其内部通过CAS来解决并发安全性的问题。
在使用CAS+自旋的过程中，在高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时AtomicLong的自旋会成为瓶颈。
随着并发的增加，AtomicLong性能是急剧下降的，耗时是LongAdder的数倍。
1、设计思想上，LongAdder采用"分段"的方式降低CAS失败的频次。
2、使用Contended注解来消除伪共享
3、惰性求值
看场景来使用，如果是并发不太高的系统，使用AtomicLong可能会更好一些，而且内存需求也会小一些。
而在高并发统计计数的场景下，才更适合使用LongAdder。
```
### 如何处理从线程的异常
### 