# Java多线程与并发面试题

[TOC]


### 1.进程和线程的区别与联系【5+】
```markdown
进程是资源分配的基本单位。线程是独立调度的基本单位。一个进程中可以有多个线程，它们共享进程资源。
**拥有资源**：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。
**调度**：线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。
**系统开销**：由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O设备等，所付出的开销远大于创建或撤销线程时的开销。
    类似地，在进行进程切换时，涉及当前执行进程CPU环境的保存及新调度进程CPU环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
**通信方面**：线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC。
```
### 2.创建线程的四种实现方式【5+】
[多线程的四种实现方式](https://www.cnblogs.com/xpybsh/p/12818796.html)
#### 2.1 继承Thread类重写run()方法：
```markdown
  1. 创建一个继承于Thread类的子类
  2. 重写Thread类的run() --> 将此线程执行的操作声明在run()中
  3. 创建Thread类的子类的对象
  4. 通过此对象调用start()
```
#### 2.2 实现Runnable接口：
```markdown
  1. 创建一个实现Runnable接口的类
  2. 实现Runnable中的run()方法
  3. 创建实现类的对象
  4. 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象
  5. 通过Thread类的对象调用start()
```
#### 2.3 实现Callable接口
```markdown
 1.创建Callable的实现类
 2.实现call方法，将此线程需要执行的操作声明在call()中
 3.创建Callable接口实现类的对象
 4.将此Callable接口实现类的对象作为传递到FutureTask构造器中，创建FutureTask的对象
 5.将FutureTask的对象作为参数传递到Thread类的构造器中，创建Thread对象，并调用start()
 6.获取Callable中call方法的返回值
```
#### 2.4 线程池
```markdown
 1. 提供指定线程数量的线程池
 2.执行指定的线程的操作。需要提供实现Runnable接口或Callable接口实现类的对象
 3.关闭连接池
```
#### 2.5 Thread类和Runnable接口的比较
```markdown
由于Java“单继承，多实现”的特性，Runnable接口使用起来比Thread更灵活。Runnable接口出现更符合面向对象，将线程单独进行对象的封装。
Runnable接口出现，降低了线程对象和线程任务的耦合性。如果使用线程时不需要使用Thread类的诸多方法，显然使用Runnable接口更为轻量。
Runnable接口和Thread类创建线程的run方法没有返回值，Callable接口和Future类可以实现。
```
#### 2.6 如何实现处理线程的返回值
```markdown
1.主线程等待法
2.使用Thread类的join()阻塞当前线程以等待子线程处理完毕
3.通过Callable接口实现：通过FutureTask或者线程池获取
```
[参考资料：并发编程相关面试题四](https://www.cnblogs.com/Zzzzn/p/12586656.html)
[参考资料：Java 并发进阶常见面试题总结](https://www.cnblogs.com/wuwuyong/p/12169102.html)
### 3.Java线程的状态及主要转化⽅法(线程的生命周期？)【5+】
[深入理解Java线程状态转移](https://www.cnblogs.com/darope/p/12748184.html)
![线程状态转换https://www.cnblogs.com/darope/p/12748184.html](https://images.cnblogs.com/cnblogs_com/darope/1747012/o_200421111345%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E8%BD%AC%E7%A7%BB.png)
```markdown
NEW RUNNABLE(runnable&Running) BLOCKED WATTING TIMED_WAITING TERMINATED
1. 新建态(NEW)：一个线程被创建出来时候所处的状态 ；
2. 就绪态(runnable)：线程调用start()方法后，便处于可以被操作系统调度的状态，即就绪态。
            就绪状态可以由三处转化而来，新建态执行了start、线程阻塞结束、锁池等待队列中的线程获得了锁。
3. 运行态(RUNNing)：表示当前线程被操作系统调度，分配了时间片，执行线程中的run方法时的状态。
            运行态只可以由就绪态的线程转化而来，如果多个线程都处在就绪态，就等待操作系统分配。
4. 阻塞态(BLOCKED):表示当前线程被由于某种原因，被挂起，也就是被阻塞，正在运行的线程被阻塞后，
            即使结束阻塞状态也回不去运行态，只能回到就绪态，等待os分配cpu资源去调度。
5. 无限期等待（Waiting）：等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。
            进入方法：                                       退出方法：
            没有设置Timeout参数的Object.wait()方法       Object.notify() / Object.notifyAll()
            没有设置Timeout参数的Thread.join()方法       被调用的线程执行完毕
            LockSupport.park()方法                      LockSupport.unpark(Thread)
6. 限期等待（Timed Waiting）：无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。
            调用Thread.sleep()方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。
            调用Object.wait()方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。
            睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。
            阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用Thread.sleep()和Object.wait()等方法进入。
              进入方法                                       退出方法
            Thread.sleep() 方法                              时间结束
            设置了Timeout参数的Object.wait()方法       时间结束/Object.notify()/Object.notifyAll()
            设置了Timeout参数的Thread.join()方法       时间结束/被调用的线程执行完毕
            LockSupport.parkNanos()方法               LockSupport.unpark(Thread)
            LockSupport.parkUntil()方法               LockSupport.unpark(Thread)
7. 结束（Terminated）：可以是线程结束任务之后自己结束，或者产生了异常而结束。
```
### 4.线程start()的两个问题【2+】
```markdown
1. 反复调用同一个线程的start()方法是否可行？不可行，在第一次调用之后ThreadStatus的值改变，反复调用会报异常。
2. 假如一个线程执行完毕（此时处于TERMINATED状态），再次调用这个线程的start()方法是否可行？
```
### 5.多线程start()和run()方法的区别，sleep()和yield()方法的区别【3+】
```markdown
start()实际上通过本地方法start0()启动线程，会新运行一个线程，新线程会调用run()方法。
run()方法：target是Runnable对象，run()直接调用Thread线程的Runnable成员的run()方法，并不会新建一个线程。
1.- 依赖线程优先级：sleep()方法暂停当前线程后，会给其他线程执行机会，而不在乎其他线程的优先级；
    yield()方法暂停当前线程后，只会给优先级相同或更高的线程执行机会。
2.- 线程转入状态：sleep()方法将线程转入阻塞状态，知道经过阻塞时间才会转入就绪状态；
    yield()方法不会将线程转入阻塞状态，而是将线程转入就绪状态。
3.- 异常声明：sleep()方法声明抛出了InterruptedException异常；yield()方法未声明抛出异常。
4.- 可移植性：sleep()方法的移植性比yield()方法好，所以一般使用sleep()方法控制并发编程。
```
### 4.CAS无锁机制【3+】
```markdown
CAS：Compare and Swap，即比较交换；
　　jdk1.5增加了并发包java.util.concurrent.*，其下面的类使用CAS算法实现了区别于synchronized同步锁的一种乐观锁。
    jdk1.5之前java是靠synchronized关键字保证同步的，是一种独占锁，也是悲观锁；本身无锁，采用乐观锁的思想，
    在数据操作时对比数据是否一致，如果一致代表之前没有线程操作该数据，那么就会更新数据，如果不一致代表有县城更新则重试；
　　CAS当中包含三个参数CAS(V,E,N)，V标识要更新的变量，E标识预期值，N标识新值　　
　　运行过程：
　　　　1.线程访问时，先会将主内存中的数据同步到线程的工作内存当中；
　　　　2.假设线程A和线程B都有对数据进行更改，那么假如线程A先获取到执行权限；
　　　　3.线程A先会对比工作内存当中的数据和主内存当中的数据是否一致，如果一致（V==E）则进行更新，不一致则刷新数据，重新循环判断；
　　　　4.这时更新完毕后，线程B也要进行数据更新，主内存数据和工作内存数据做对比，如果一致则进行更新，
        不一致则将主内存数据重新更新到工作内存，然后循环再次对比两个内存中的数据，直到一致为止；　
（1）CAS存在ABA问题
　　ABA问题，如果将原来A的值改为了B，然后又改回了A，虽然最终结果没有发生改变，但是在过程中是对该数据进行了修改操作
　　解决该问题：加版本号，在Java中并发包下有一个原子类：AtomicStampedReference，在该类当中通过版本控制判断值到底是否被修改
             加时间戳
　　解释：如果对值进行了更改则版本号+1，那么在CAS当中不仅仅对比变量的值，还要对比版本号，如果值和版本号都相等则代表没有被修改，
        如果有一方不相等代表进行过更改，那么就从主内存中重新刷新数据到工作内存然后循环对比，直到成功为止。
（2）循环开销大
    CAS是乐观锁，如果线程比较多，资源抢占激烈，命中率低的情况下，不断的循环会不断的消耗资源。
    
实际上，可以设置最大循环数，达到最大循环数还没有占有资源就自动放弃，避免无限的循环。
（3）只能保证一个共享变量的原子操作。
```
### 4. AQS思想原理【2+】
```markdown
AQS:全称AbstractQueueSynchronizer，抽象队列同步器，这个类在java.util.concurrent.locks包下
它是一个底层同步工具类，比如CountDownLatch,Sammphore，ReentrantLock,ReentrantReadWriteLock等等都是基于AQS底层三个内容：
　　　　　　1.state（用于计数器）
　　　　　　2.线程标记（哪一个线程加的锁）
　　　　　　3.阻塞队列（用于存放阻塞线程）
AQS提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架，如下图所示。AQS为一系列同步器依赖于一个单独的原子变量（state）
的同步器提供了一个非常有用的基础。子类们必须定义改变state变量的protected方法，这些方法定义了state是如何被获取或释放的。
AQS核⼼思想：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。
    如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是⽤CLH（虚拟的双向队列）队列锁实现的，即将暂时获取不到锁的线程加⼊到队列中。
lock：是一种可重入锁，除了能完成synchronized所能完成的所有工作外，还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。
    默认为非公平锁，但可以初始化为公平锁；通过方法lock()与unlock()来进行加锁与解锁操作；
```
### 5. ReentrantLock底层实现原理【3+】
```markdown
ReentrantLock是基于AQS的，AQS是Java并发包中众多同步组件的构建基础，它通过一个int类型的状态变量state和一个FIFO队列来完成共享资源的获取，
线程的排队等待等。AQS是个底层框架，采用模板方法模式，它定义了通用的较为复杂的逻辑骨架，比如线程的排队，阻塞，唤醒等，将这些复杂但实质通用的部分抽取出来，
这些都是需要构建同步组件的使用者无需关心的，使用者仅需重写一些简单的指定的方法即可（其实就是对于共享变量state的一些简单的获取释放的操作）。
synchronized是ReentrantLock内部实现的一个同步组件，它是Reentrantlock的一个静态内部类，继承于AQS；
```
### 6.Java开发中用过哪些锁【3+】
#### 1.介绍一下Java有哪些锁(synchronized、juc提供的锁如ReentrantLock、CountDownLatch、CyclicBarrier、Semaphore等)
```markdown
1、乐观锁
　　乐观锁顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。
    乐观锁适用于多读的应用类型，这样可以提高吞吐量，在Java中java.util.concurrent.atomic包下面的原子变量类就是使用了乐观锁的一种实现方式CAS(Compare and Swap 比较并交换)实现的
　　乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升；　　
　　乐观锁在Java中的使用，是无锁编程，常常采用的是CAS算法，典型的例子就是原子类，通过CAS自旋实现原子操作的更新。
2、悲观锁
　　悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁。
    比如Java里面的同步原语synchronized关键字的实现就是悲观锁。
　　悲观锁适合写操作非常多的场景；悲观锁在Java中的使用，就是利用各种锁；
3、独享锁
　　独享锁是指该锁一次只能被一个线程所持有。
　　独享锁通过AQS来实现的，通过实现不同的方法，来实现独享锁。对于Synchronized而言，当然是独享锁。
4、共享锁
　　共享锁是指该锁可被多个线程所持有。
　　读锁的共享锁可保证并发读是非常高效的，读写，写读，写写的过程是互斥的。
　　共享锁也是通过AQS来实现的，通过实现不同的方法，来实现共享锁。
5、互斥锁
　　互斥锁在Java中的具体实现就是ReentrantLock。
6、读写锁
　　读写锁在Java中的具体实现就是ReadWriteLock。
7、可重入锁　　　　
　　重入锁也叫作递归锁，指的是同一个线程外层函数获取到一把锁后，内层函数同样具有这把锁的控制权限；
　　synchronized和ReentrantLock就是重入锁对应的实现；
　　synchronized重量级的锁 ；ReentrantLock轻量级的锁；
8、公平锁
　　公平锁是指多个线程按照申请锁的顺序来获取锁。
　　对于Java ReetrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。
9、非公平锁
　　非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。　　
　　对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。
10、分段锁
　　分段锁其实是一种锁的设计，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。
　　我们以ConcurrentHashMap来说一下分段锁的含义以及设计思想，ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7和JDK8中HashMap的实现）的结构，
    即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock）。
　　当需要put元素的时候，并不是对整个hashmap进行加锁，而是先通过hashcode来知道他要放在哪一个分段中，然后对这个分段进行加锁，所以当多线程put的时候，只要不是放在一个分段中，就实现了真正的并行的插入。
　　但是，在统计size的时候，可就是获取hashmap全局信息的时候，就需要获取所有的分段锁才能统计。
　　分段锁的设计目的是细化锁的粒度，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。
11、偏向锁　　
　　偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
12、轻量级锁
　　轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
13、重量级锁
　　 重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，
    该锁膨胀为重量级锁。重量级锁会让他申请的线程进入阻塞，性能降低。
14、自旋锁
　　在Java中，自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。
    缺点：如果锁被其他线程长时间占用，一直不释放CPU，会带来许多的性能开销；自旋次数默认值是10
15.自适应自旋锁：
    对上面自旋锁优化方式的进一步优化，它的自旋的次数不再固定，其自旋的次数由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定，这就解决了自旋锁带来的缺点。
```
#### 2.公平锁和非公平锁区别？为什么公平锁效率低？
```markdown
公平锁：
​   公平锁自然是遵循FIFO（先进先出）原则的，先到的线程会优先获取资源，后到的会进行排队等待
​   优点：所有的线程都能得到资源，不会饿死在队列中。
​   缺点：吞吐量会下降，队列里面除了第一个线程，其他的线程都会阻塞，cpu唤醒阻塞线程的开销大
非公平锁：
​   多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁。
​   优点：可以减少CPU唤醒线程的开销，整体的吞吐效率会高点，CPU也不必取唤醒所有线程，会减少唤起线程的数量。
​   缺点：你们可能也发现了，这样可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁
公平锁效率低原因：
​   公平锁要维护一个队列，后来的线程要加锁，即使锁空闲，也要先检查有没有其他线程在wait，如果有自己要挂起，加到队列后面，然后唤醒队列最前面线程。
这种情况下相比较非公平锁多了一次挂起和唤醒。线程切换的开销，其实就是非公平锁效率高于公平锁的原因，因为非公平锁减少了线程挂起的几率，后来的线程有一定几率逃离被挂起的开销
```
#### 3.锁优化
```markdown
【1】减少锁的时间：
​     不需要同步执行的代码，能不放在同步快里面执行就不要放在同步快内，可以让锁尽快释放；
​【2】减少锁的粒度：
    ​ 它的思想是将物理上的一个锁，拆成逻辑上的多个锁，增加并行度，从而降低锁竞争。它的思想也是用空间来换时间；java中很多数据结构都是采用这种方法提高并发操作的效率，比如：
    ConcurrentHashMap：
​    java中的ConcurrentHashMap在jdk1.8之前的版本，使用一个Segment 数组：Segment<K,V>[] segments
​    Segment继承自ReenTrantLock，所以每个Segment是个可重入锁，每个Segment有一个HashEntry<K,V>数组用来存放数据，put操作时，先确定往哪个Segment放数据，
    只需要锁定这个Segment，执行put，其它的Segment不会被锁定；所以数组中有多少个Segment就允许同一时刻多少个线程存放数据，这样增加了并发能力。
​【3】锁粗化：
​   大部分情况下我们是要让锁的粒度最小化，锁的粗化则是要增大锁的粒度;
​   在以下场景下需要粗化锁的粒度：
​   假如有一个循环，循环内的操作需要加锁，我们应该把锁放到循环外面，否则每次进出循环，都进出一次临界区，效率是非常差的；
​【4】使用读写锁：
​   ReentrantReadWriteLock 是一个读写锁，读操作加读锁，可并发读，写操作使用写锁，只能单线程写；
​【5】使用CAS：
​    如果需要同步的操作执行速度非常快，并且线程竞争并不激烈，这时候使用cas效率会更高，因为加锁会导致线程的上下文切换，
    如果上下文切换的耗时比同步操作本身更耗时，且线程对资源的竞争不激烈，使用volatiled+cas操作会是非常高效的选择；
```
### 7.synchronized理解及底层实现【5+】
>> 22. synchronized用过么，具体用法，同步作用域
   23. synchronized是可重入锁么
   synchronized锁升级过程
```markdown
使用了synchronized关键字可以轻松地解决多线程共享数据同步问题。
　　synchronized关键字修饰实例方法，修饰静态方法，修饰代码块
    synchronized可作用于instance变量、object reference（对象引用）、static函数和class literals(类名称字面常量)身上。 
　　synchronized取得的锁都是对象；每个对象只有一个锁（lock）与之相关联；实现同步是要很大的系统开销作为代价的，甚至可能造成死锁，所以尽量避免无谓的同步控制。
　　synchronized的4种用法：
　　　　1. 方法声明时使用,线程获得的是成员锁；
　　　　2. 对某一代码块使用,synchronized后跟括号,括号里是变量,线程获得的是成员锁；
　　　　3. synchronized后面括号里是一对象,此时,线程获得的是对象锁；
　　　　4. synchronized后面括号里是类,此时,线程获得的是对象锁；
庆幸的是在Java6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了。
JDK1.6对锁的实现引入了大量的优化，如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。
synchronized的不足之处:
    1.如果临界区是只读操作，其实可以多线程一起执行，但是使用synchronized的话，同一时间只能有一个线程执行。
    2.synchronized无法知道线程有没有成功获取到锁。
    3.使用synchronized，如果临界区因为IO或者sleep方法等原因阻塞了，而当前线程没有释放锁，就会导致所有线程等待
```
### 8.ReentrantLock和synchronized之间的区别【4+】
```markdown
两者都是可重入锁：
原始构成：synchronized是JVM层面实现的；ReentrantLock是JDKAPI层面实现。说白了就是是操作系统来实现，还是用户自己敲代码实现。
使用方法：
1.synchronized加锁和解锁自动进行，不必担心最后是否释放锁；ReentrantLock加锁和解锁需要手动进行，且次数需一样，否则其他线程无法获得锁。
2.synchronized竞争锁时会一直等待；ReentrantLock可以尝试获取锁，并得到获取结果。
3.synchronized不可中断，获取锁无法设置超时；ReentrantLock可以中断，可以设置获取锁的超时时间。
4.synchronized只能是非公平锁，无法实现公平锁；ReentrantLock可以满足公平锁，即先等待先获取到锁,也可以满足非公平锁，默认非公平锁。
5.synchronized控制等待和唤醒需要结合加锁对象的wait()和notify()、notifyAll(),随机唤醒或者全部唤醒；
    ReentrantLock控制等待和唤醒需要结合Condition的await()和signal()、signalAll()方法，可以实现分组精确唤醒线程。
6.synchronized在加锁代码块执行完或者出现异常，自动释放锁；ReentrantLock不会自动释放锁，需要在finally{}代码块显示释放。
ReentrantLock锁的细粒度和灵活度，都明显优于synchronized。
```
```java
//题目:多线程之间按顺序调用，实现A->B->C三个线程启动，要求如下：
//打印5次，BB打印10次，CC打印15次
//紧接着 打印5次，BB打印10次，CC打印15次 来十次
class ShareResource{
    private int number = 1;//A:1,B:2,C:3
    private Lock lock = new ReentrantLock();
    private Condition c1 = lock.newCondition();
    private Condition c2 = lock.newCondition();
    private Condition c3 = lock.newCondition();   
    public void print5(){
        lock.lock();
        try{
            //1判断
            while(number!=1){
               c1.await();
            }
            //2.干活
            for(int i = 1;i<=5;i++){
                System.out.println(Thread.currentThread().getName()+i);
            }
            //3.通知
            number = 2;
            c2.signal();
        }catch (Exception e){
            e.printStackTrace();
        }finally{
            lock.unlock();
        }
    }
    
    public void print10(){
            lock.lock();
            try{
                //1判断
                while(number!=2){
                   c2.await();
                }
                //2.干活
                for(int i = 1;i<=5;i++){
                    System.out.println(Thread.currentThread().getName()+i);
                }
                //3.通知
                number = 2;
                c3.signal();
            }catch (Exception e){
                e.printStackTrace();
            }finally{
                lock.unlock();
            }
        }
    
    public void print15(){
            lock.lock();
            try{
                //1判断
                while(number!=3){
                   c3.await();
                }
                //2.干活
                for(int i = 1;i<=5;i++){
                    System.out.println(Thread.currentThread().getName()+i);
                }
                //3.通知
                number = 1;
                c1.signal();
            }catch (Exception e){
                e.printStackTrace();
            }finally{
                lock.unlock();
            }
        }
    
}
public class Demo{
    public static void main(String[] args){
      ShareResource shareResource = new ShareResource();
      new Thread(()->{
          for(int i = 1;i<=10;i++){
              shareResource.print5();
          }
      },"A").start();
      new Thread(()->{
                for(int i = 1;i<=10;i++){
                    shareResource.print10();
                }
            },"B").start();
      new Thread(()->{
                for(int i = 1;i<=10;i++){
                    shareResource.print15();
                }
            },"C").start();
    }
}
```
### 9.volatile特性【5+】
>> volatile作用？底层实现？禁止重排序的场景？单例模式中volatile的作用？
[面试中的volatile关键字](https://www.cnblogs.com/ArvinYL/p/12827641.html)
```markdown
被volatile修饰的共享变量，就具有了以下两点特性：
    保证了不同线程对该变量操作的**内存可见性**
    禁止指令重排序(有序性)
内存可见性:
    可见性是指一个线程修改了共享变量的值，其他线程能够立即得知这个修改。
    volatile变量保证新值能够立马同步到主内存，使用时也立即从主内存中刷新，保证了多线程操作时变量的可见性。
JMM的特性：原子性，有序性，可见性。
    原子性即一个操作或一系列操作是不可中断的。即使是在多线程的情况下，操作一旦开始，就不会被其他线程干扰。
    有序性是指对于单线程的执行代码，执行是按顺序依次进行的。
    但在多线程环境中，则可能出现乱序现象，因为在编译过程中会出现“指令重排”，重排后的指令与原指令的顺序未必一致。
指令重排：
    CPU和编译器为了提高程序执行的效率，会按照一定的规则允许进行指令优化。
    但代码逻辑之间是存在一定的先后顺序，并发执行时按照不同的执行逻辑会得到不同的结果。    
volatile不能保证原子性，它只是对单个volatile变量的读/写具有原子性，但是对于类似i++的复合操作就无法保证。
volatile+synchronized实现单例模式的双重检查锁
单例模式中volatile的作用：防止代码读取到instance不为null时，instance引用的对象有可能还没有完成初始化。
    class Singleton{
        private volatile static Singleton instance = null;   //禁止指令重排
        private Singleton() {
    
        }
        public static Singleton getInstance() {
            if(instance==null) {
                synchronized (Singleton.class) {
                    if(instance==null)
                        instance = new Singleton();
                }
            }
            return instance;
        }
    }
```
### 10.synchronized和volatile的区别
```markdown
volatile本质是在告诉JVM当前变量寄存器(工作内存)中的值是不确定的，需要从主存中读取；
synchronized则是锁定当前变量，只有当前线程可以访问该变量，其他线程被阻塞住。
volatile只能用于变量，而synchronized可以修饰方法和代码块。volatile关键字是线程同步的轻量级实现，性能比synchronized要好。
多线程访问volatile不会发生阻塞，而synchronized可能发生阻塞。
volatile能够保证数据的可见性，但是不能保证数据的原子性，synchronized两者都能保证。
volatile主要是解决变量在多个线程之间的可见性，synchronized解决多个线程之间访问资源的同步性。
volatile标记的变量不会被编译器优化；synchronized标记的变量可以被编译器优化。
```
### 11.当⼀个线程进⼊⼀个对象的⼀个synchronized⽅法后，其它线程是否可进⼊此对象的其它⽅法?
```markdown
其他⽅法前是否加了synchronized关键字，如果没加，则能。
如果这个⽅法内部调⽤了wait，则可以进⼊其他synchronized⽅法。
如果其他个⽅法都加了synchronized关键字，并且内部没有调⽤wait，则不能。
如果其他⽅法是static，它⽤的同步锁是当前类的字节码，与⾮静态的⽅法不能同步，因为⾮静态的⽅法⽤的是this。
```
### 11.sleep()和wait()的区别联系【必考点2+】
```markdown
1.wait()是Object的方法，而sleep()是Thread的静态方法；
2.wait可以指定时间，也可以不指定；而sleep必须指定时间。
3.wait释放cpu资源，同时释放锁；sleep释放cpu资源，但是不释放锁，所以易死锁。
4.wait必须放在同步块或同步方法中，而sleep可以再任意位置。
5.sleep()通常被用于暂停执行，而wait()通常被用于线程间交互和通信。
【加分项】.在调用wait方法之后，线程会变为WATING状态，而调用sleep方法之后，线程会变为TIMED_WAITING状态。
【加分项】.进入wait状态的线程能够被notify和notifyAll线程唤醒，而sleep状态的线程不能被notify方法唤醒。
```
#### [加分项>>如何证明sleep不释放锁，而wait释放锁？](https://mp.weixin.qq.com/s?__biz=MzU1NTkwODE4Mw==&mid=2247487370&idx=1&sn=90c0bd01fd490b680eae9b60515e5e5f&chksm=fbcc62b2ccbbeba43cdaa4e95a8263ac7bd9dc42bf75b9060ff0354e724e0bc2215dda232b10&mpshare=1&scene=23&srcid=0721tKj84e0eLyXf3j5gmaqW&sharer_sharetime=1595339628839&sharer_shareid=d812adcc01829f0f7f8fb06aea118511#rd)
```markdown
wait()释放锁
    给wait()和notify()两个方法上了同一把锁（locker），但在调用完wait()方法之后locker锁就被释放了，所以程序才能正常执行notify()的代码，
    因为是同一把锁，如果不释放锁的话，是不会执行notify()的代码的，这一点也可以从打印的结果中证实（结果输出顺序），所以综合以上情况来说wait()方法是释放锁的。
sleep()不释放锁
    sleep(1000)方法（行号：11）执行之后，调用notify()方法并没有获取到locker锁，从上述执行结果中可以看出，
    而是执行完sleep(1000)方法之后才执行的notify()方法，因此可以证明调用sleep()方法并不会释放锁。
```
```java
public class WaitDemo {
    private static Object locker = new Object();

    public static void main(String[] args) throws InterruptedException {
        WaitDemo waitDemo = new WaitDemo();

        // 启动新线程，防止主线程被休眠
        new Thread(() -> {
            try {
                waitDemo.doWait();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }).start();
        Thread.sleep(200); // 此行本身没有意义，是为了确保 wait() 先执行再执行 notify()
        waitDemo.doNotify();
    }

    /**
     * 执行 wait()
     */
    private void doWait() throws InterruptedException {
        synchronized (locker) {
            System.out.println("wait start.");
            locker.wait();
            System.out.println("wait end.");
        }
    }

    /**
     * 执行 notify()
     */
    private void doNotify() {
        synchronized (locker) {
            System.out.println("notify start.");
            locker.notify();
            System.out.println("notify end.");
        }
    }
}
//以上程序的执行结果为：
//  wait start. 
//  notify start. 
//  notify end. 
//  wait end.
```
```java
public class WaitDemo {
    private static Object locker = new Object();

    public static void main(String[] args) throws InterruptedException {
        WaitDemo waitDemo = new WaitDemo();
        // 启动新线程，防止主线程被休眠
        new Thread(() -> {
            synchronized (locker) {
                try {
                    System.out.println("sleep start.");
                    Thread.sleep(1000);
                    System.out.println("sleep end.");
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }).start();

        Thread.sleep(200);
        waitDemo.doNotify();
    }

    /**
     * 执行 notify()
     */
    private void doNotify() {
        synchronized (locker) {
            System.out.println("notify start.");
            locker.notify();
            System.out.println("notify end.");
        }
    }
}
//以上程序的执行结果为：
//  sleep start. 
//  sleep end. 
//  notify start. 
//  notify end.
```
### 12.notify()和notifyAll()有什么区别？【2+】
```markdown
notify():方法唤醒一个正在等待池的线程进入锁池去竞争获取锁的机会，如果有多个这样的线程，就会随机唤醒。
notifyAll():唤醒所有正在等待池的线程全部进入锁池区竞争获取锁的机会。
    唤醒不等于就能执行，需要得到锁对象才能有权利继续执行，而锁只有一把，所以多个线程被唤醒时需要争取该锁。
```
### 13. BIO、NIO、AIO有什么区别？
```markdown
BIO：线程发起IO请求，不管内核是否准备好IO操作，从发起请求起，线程一直阻塞，直到操作完成。(InputStream、OutputStream、Reader、Writer)
NIO：线程发起IO请求，立即返回；内核在做好IO操作的准备之后，通过调用注册的回调函数通知线程做IO操作，线程开始阻塞，直到操作完成。
    (Channels、Buffers、Selectors)
AIO：线程发起IO请求，立即返回；内存做好IO操作的准备之后，做IO操作，直到操作完成或者失败，通过调用注册的回调函数通知线程做IO操作完成或者失败。
BIO 是一个连接一个线程。,NIO是一个请求一个线程。,AIO是一个有效请求一个线程。
BIO：同步并阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，当然可以通过线程池机制改善。
NIO：同步非阻塞，服务器实现模式为一个请求一个线程，即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有I/O请求时才启动一个线程进行处理。
AIO：异步非阻塞，服务器实现模式为一个有效请求一个线程，客户端的IO请求都是由OS先完成了再通知服务器应用去启动线程进行处理。
IO多路复用：调用系统级别的select、poll、epoll
```
### 14.线程死锁编码及定位分析【3+】
```markdown
死锁是什么：死锁是指两个或两个以上的进程在执行过程中，因为争夺资源而造成的一种互相等待的现象。
死锁的必要条件：
     互斥条件 (Mutual exclusion)：资源不能被共享，只能由一个进程使用。
     请求与保持条件 (Hold and wait)：已经得到资源的进程可以再次申请新的资源。
     非抢占条件 (No pre-emption)：已经分配的资源不能从相应的进程中被强制地剥夺。
     循环等待条件 (Circular wait)：系统中若干进程组成环路，该环路中每个进程都在等待相邻进程正占用的资源。
发生死锁时，上面的情况必须同时会发生。如果其中任意一个条件不会成立，死锁就不会发生。可以通过破坏其中任意一个条件来破坏死锁。
死锁的处理策略：
     鸵鸟策略：忽略死锁带来的影响
     死锁检测与死锁恢复（检测死锁并回复死锁，死锁发生时对其进行检测，一旦发生死锁后，采取行动解决问题）
        从死锁中恢复：通过抢占进行恢复,通过回滚进行恢复,杀死进程恢复。
     死锁预防（通过仔细分配资源来避免死锁）
     死锁避免（通过破坏死锁产生的四个条件之一来避免死锁）
        单个资源的银行家算法，破坏死锁，破坏互斥条件，破坏保持等待的条件，破坏不可抢占条件，破坏循环等待条件。
```
```java
class HoldLockThed implements Runnable{
    private String lockA;
    private String lockB;
    public HoldLockThread(String lockA,String lockB){
        this.lockA = lockA;
        this.lockB = lockB;
    }
    
    @Override
    public void run(){
        synchronized (lockA){
            System.out.println(Thread.currentThread().getName()+"自己持有："+lockA+"尝试获得："+lockB);
            //暂停一会线程
                            try {
                                TimeUnit.MILLISECONDS.sleep(200);
                            } catch (InterruptedException e) {
                                e.printStackTrace();
                            }
            synchronized (lockB){
                        System.out.println(Thread.currentThread().getName()+"自己持有："+lockA+"尝试获得："+lockB);
                    }
        }
    }
}
public class DeadLockDemo{
    public static void main(String[] args){
      String lockA = "lockA";
      String lockB = "lockB";
      
      new Thread(new HoldLockThread(lockA,lockB),"ThreadAAA").start();//线程持有A,想要获取B
      new Thread(new HoldLockThread(lockB,lockA),"ThreadBBB").start();//线程持有B,想要获取A
    }
}
```
### ThreadLocal
```markdown
ThreadLocal简介：通常情况下，我们创建的变量是可以被任何⼀个线程访问并修改的。如果想实现每⼀个线程都有⾃⼰的
    专属本地变量该如何解决呢？JDK中提供的ThreadLocal类正是为了解决这样的问题。
ThreadLocal原理：首先ThreadLocal是一个泛型类，保证可以接受任何类型的对象。因为一个线程内可以存在多个ThreadLocal对象，
    所以其实是ThreadLocal内部维护了一个Map ，这个Map不是直接使用的HashMap，而是ThreadLocal实现的一个叫做ThreadLocalMap的静态内部类。
​    最终的变量是放在了当前线程的ThreadLocalMap中，并不是存在ThreadLocal上，ThreadLocal可以理解为只是ThreadLocalMap的封装，传递了变量值。
    我们使用的get()、set()方法其实都是调用了这个ThreadLocalMap类对应的get()、set()方法。例如下面的
    set 方法：
        public void set(T value) {
            Thread t = Thread.currentThread();
            ThreadLocalMap map = getMap(t);
            if (map != null)
                map.set(this, value);
            else
                createMap(t, value);
        }
    get方法：
        public T get() {   
            Thread t = Thread.currentThread();   
            ThreadLocalMap map = getMap(t);   
            if (map != null)   
                return (T)map.get(this);   
            // 如果不存在，则创建它   
            T value = initialValue();   
            createMap(t, value);   
            return value;   
        }
    createMap方法：
        void createMap(Thread t, T firstValue) {   
            t.threadLocals = new ThreadLocalMap(this, firstValue);   
        } 
    ThreadLocalMap是个静态的内部类：
        static class ThreadLocalMap {   
            ……  
        }  
    ​ 1）存储用户Session
        private static final ThreadLocal threadSession = new ThreadLocal();
        public static Session getSession() throws InfrastructureException {
            Session s = (Session) threadSession.get();
            try {
                if (s == null) {
                    s = getSessionFactory().openSession();
                    threadSession.set(s);
                }
            } catch (HibernateException ex) {
                throw new InfrastructureException(ex);
            }
            return s;
        }
    ​ 2）解决线程安全的问题
        public class DateUtil {
            //SimpleDateFormat不是线程安全的，所以每个线程都要有⾃⼰独⽴的副本
            private static ThreadLocal<SimpleDateFormat> format1 = new                     ThreadLocal<SimpleDateFormat>() {
                @Override
                protected SimpleDateFormat initialValue() {
                    return new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
                }
            };
            public static String formatDate(Date date) {
                return format1.get().format(date);
            }
        }
```
### ThreadLocal内存泄漏
```markdown
实际上ThreadLocalMap中使用的key为ThreadLocal的弱引用，⽽value是强引⽤。
    弱引用的特点是，如果这个对象持有弱引用，那么在下一次垃圾回收的时候必然会被清理掉。
    所以如果ThreadLocal没有被外部强引用的情况下，在垃圾回收的时候会被清理掉的，这样一来ThreadLocalMap中使用这个ThreadLocal的key也会被清理掉。
    但是，value是强引用，不会被清理，这样一来就会出现key为null的value。假如我们不做任何措施的话，value永远⽆法被GC回收，这个时候就可能会产⽣内存泄露。
ThreadLocalMap实现中已经考虑了这种情况，在调用set()、get()、remove()方法的时候，会清理掉key为null的记录。
   如果说会出现内存泄漏，那只有在出现了key为null的记录后，没有手动调用remove()方法，并且之后也不再调用get()、set()、remove()方法的情况下。
​   因此使⽤完ThreadLocal⽅法后，最好⼿动调⽤remove()⽅法。
```
### 线程池【10+】
>> Execuors类实现的几种线程池类型，最后如何返回？
>> 如何构造线程池，它的参数，饱和策略？
>> 公平锁和非公平锁区别？为什么公平锁效率低？
>> Java线程池原理介绍一下
>> 2.不用线程池的话，需要一个线程就创一个线程，会出现什么问题
>> 线程池作用？Java线程池有哪些参数？阻塞队列有几种？拒绝策略有几种？
>> ThreadLocal 是什么，应用场景是什么，原理是怎样的
>> 线程池有哪些参数，执行流程是怎样的？有哪些常用BlockingQueue，区别是什么？拒绝策略有哪些？shutdown()和shutdownNow()有什么区别？
>> 线程池的阻塞队列怎么选择，会出现阻塞的情况吗？
>> ThreadLocal原理，线程池中使用ThreadLocal会有什么问题，为什么？软引用和弱引用有什么区别？
>> Java线程池执行流程
>线程池的参数？
 corepoolsize和maximumPoolSize 的区别？
 为什么用线程池？
 线程的几个状态？
 线程池的工作队列？
#### 1.线程池构造函数7大参数
```markdown
参数	            作用
corePoolSize	核心线程池大小
maximumPoolSize	最大线程池大小
keepAliveTime	线程池中超过corePoolSize数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true)使得核心线程有效时间
TimeUnit	    keepAliveTime时间单位
workQueue	    阻塞任务队列
threadFactory	新建线程工厂
RejectedExecutionHandler	拒绝策略。当提交任务数超过maxmumPoolSize+workQueue之和时，任务会交给RejectedExecutionHandler来处理
/**
* 线程池构造函数7大参数
*/
public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize,long keepAliveTime,
    TimeUnit unit,BlockingQueue<Runnable> workQueue,ThreadFactory threadFactory,
    RejectedExecutionHandler handler) {
        if (corePoolSize < 0 ||maximumPoolSize <= 0 ||maximumPoolSize < corePoolSize ||
                keepAliveTime < 0)
             throw new IllegalArgumentException();
        if (workQueue == null || threadFactory == null || handler == null)
            throw new NullPointerException();
        this.corePoolSize = corePoolSize;
           this.maximumPoolSize = maximumPoolSize;
        this.workQueue = workQueue;
        this.keepAliveTime = unit.toNanos(keepAliveTime);
        this.threadFactory = threadFactory;
        this.handler = handler;
}
```
#### 2.线程拒绝策略：
```markdown
​线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。
JDK 内置的拒绝策略如下：
​   AbortPolicy：直接抛出异常，阻止系统正常运行。
​   CallerRunsPolicy ：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
​   DiscardOldestPolicy ：丢弃最老的一个请求，也就是即将被执行的任务，并尝试再次提交当前任务。
​   DiscardPolicy ：该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。
```
#### 3.Execuors类实现的几种线程池类型
```markdown
Executors.newSingleThreadExecutor()：只有一个线程的线程池，因此所有提交的任务是顺序执行，适用于一个一个任务执行的场景
Executors.newCachedThreadPool()：线程池里有很多线程需要同时执行，老的可用线程将被新的任务触发重新执行，
    如果线程超过60秒内没执行，那么将被终止并从池中删除，适用执行很多短期异步的小程序或者负载较轻的服务
Executors.newFixedThreadPool()：拥有固定线程数的线程池，如果没有任务执行，那么线程会一直等待，适用执行长期的任务，性能好很多。
Executors.newScheduledThreadPool()：用来调度即将执行的任务的线程池
因为以上方式都存在弊端：
    ​ FixedThreadPool和SingleThreadExecutor：允许请求的队列⻓度为Integer.MAX_VALUE，可能堆积⼤量的请求，从⽽导致OOM。
​     CachedThreadPool和ScheduledThreadPool：允许创建的线程数量为Integer.MAX_VALUE，可能会创建⼤量线程，从⽽导致OOM。
```
#### 4.线程处理任务过程：
```markdown
1.当线程池小于corePoolSize，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。
2.当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行。
3.当workQueue已满，且maximumPoolSize大于corePoolSize时，新提交任务会创建新线程执行任务。
4.当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理。
5.当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，关闭空闲线程 。
```
#### 5.线程池大小如何设置？
```markdown
CPU 密集型
    CPU密集的意思是该任务需要大量的运算，而没有阻塞，CPU一直全速运行。
    CPU密集型任务尽可能的少的线程数量，一般为CPU核数+1个线程的线程池。
IO 密集型
    由于IO 集型任务线程并不是一直在执行任务，可以多分配一点线程数，如CPU * 2
    也可以使用公式：CPU核数/(1-阻塞系数)；其中阻塞系数在0.8 ～ 0.9之间。
```
### 并发/同步工具类【3+】
>> CountDownLatch、CyclicBarrier、Semaphore介绍
>讲一下CountDownLatch和cyclicBarrier的区别？
 CountdownLatch 和 Semophore 的作用？
####  CountdownLatch
```markdown
CountDownLatch：通过计数法（倒计时器），让一些线程堵塞直到另一个线程完成一系列操作后才被唤醒；该⼯具通常⽤来控制线程等待，它可以让某⼀个线程等待直到倒计时结束，再开始执⾏。
    假设我们有这么一个场景，教室里有班长和其他6个人在教室上自习，怎么保证班长等其他6个人都走出教室在把教室门给关掉。
        public class CountDownLanchDemo {
            public static void main(String[] args) {
                for (int i = 0; i < 6; i++) {
                    new Thread(() -> {
                        System.out.println(Thread.currentThread().getName() + " 离开了教室...");
                    }, String.valueOf(i)).start();
                }
                System.out.println("班长把门给关了，离开了教室...");
            }
        }
    此时输出：
        0 离开了教室...
        1 离开了教室...
        2 离开了教室...
        3 离开了教室...
        班长把门给关了，离开了教室...
        5 离开了教室...
        4 离开了教室...
    发现班长都没有等其他人理他教室就把门给关了，此时我们就可以使用 CountDownLatch 来控制
        public class CountDownLanchDemo {
            public static void main(String[] args) throws InterruptedException {
                CountDownLatch countDownLatch = new CountDownLatch(6);
                for (int i = 0; i < 6; i++) {
                    new Thread(() -> {
                        countDownLatch.countDown();
                        System.out.println(Thread.currentThread().getName() + " 离开了教室...");
                    }, String.valueOf(i)).start();
                }
                countDownLatch.await();
                System.out.println("班长把门给关了，离开了教室...");
            }
        }
    输出：
       0 离开了教室...
       1 离开了教室...
       2 离开了教室...
       3 离开了教室...
       4 离开了教室...
       5 离开了教室...
       班长把门给关了，离开了教室...
```
#### CyclicBarrier：
```markdown
字面意思是可循环(Cyclic)使用的屏障（Barrier）。他要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，
直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活，线程进入屏障通过CyclicBarrier的await()方法。
    我们假设有这么一个场景，每辆车只能坐4个人，当车满了，就发车。
        public class CyclicBarrierDemo {
            public static void main(String[] args) {
                CyclicBarrier cyclicBarrier = new CyclicBarrier(4, () -> {
                    System.out.println("车满了，开始出发...");
                });
                for (int i = 0; i < 8; i++) {
                    new Thread(() -> {
                        System.out.println(Thread.currentThread().getName() + " 开始上车...");
                        try {
                            cyclicBarrier.await();
                        } catch (InterruptedException e) {
                            e.printStackTrace();
                        } catch (BrokenBarrierException e) {
                            e.printStackTrace();
                        }
                    }).start();
                }
            }
        }
    输出结果：
        Thread-0 开始上车...
        Thread-1 开始上车...
        Thread-3 开始上车...
        Thread-4 开始上车...
        车满了，开始出发...
        Thread-5 开始上车...
        Thread-7 开始上车...
        Thread-2 开始上车...
        Thread-6 开始上车...
        车满了，开始出发...
```
#### Semaphore：
```markdown
​信号量主要用于两个目的，一个是用于多个共享资源的互斥作用，另一个用于并发线程数的控制。
    假设我们有 3 个停车位，6 辆车去抢；指定多个线程同时访问某个资源。
    public class SemaphoreDemo {
      public static void main(String[] args) {
          Semaphore semaphore = new Semaphore(3);
          for (int i = 0; i < 6; i++) {
              new Thread(() -> {
                  try {
                      semaphore.acquire(); // 获取一个许可
                      System.out.println(Thread.currentThread().getName() + " 抢到车位...");
                      Thread.sleep(3000);
                      System.out.println(Thread.currentThread().getName() + " 离开车位");
                  } catch (InterruptedException e) {
                      e.printStackTrace();
                  } finally {
                      semaphore.release(); // 释放一个许可
                  }
              }).start();
          }
      }
    }
    
    /**输出
    Thread-1 抢到车位...
    Thread-2 抢到车位...
    Thread-0 抢到车位...
    Thread-2 离开车位
    Thread-0 离开车位
    Thread-3 抢到车位...
    Thread-1 离开车位
    Thread-4 抢到车位...
    Thread-5 抢到车位...
    Thread-3 离开车位
    Thread-5 离开车位
    Thread-4 离开车位
    */
```
### 原子类Atomic【1+】
[像宝石一样的Java原子类](https://www.cnblogs.com/upnote/p/12972751.html)
```markdown
 Atomic包中的类基本的特性就是在多线程环境下，当有多个线程同时对单个（包括基本类型及引用类型）变量进行操作时，具有排他性，
即当多个线程同时对该变量的值进行更新时，仅有一个线程能成功，而未成功的线程可以向自旋锁一样，继续尝试，一直等到执行成功。
 Atomic系列的类中的核心方法都会调用unsafe类中的几个本地方法。因此atomic证原子性就是通过:自旋+CAS（乐观锁）
 Lock类和Atomic包底层实现都是通过CAS+自旋的方式解决多线程同步问题。Atomic在竞争激烈时能维持常态，比lock性能好，但是只能同步一个变量。
```
[比AtomicLong更优秀的LongAdder确定不来了解一下吗？](https://www.cnblogs.com/wang-meng/p/12892695.html)
```markdown
count++操作，使用AtomicInteger count = new AtomicInteger();count.addAndGet(1);
如果是JDK8，推荐使用LongAdder对象，比AtomicLong性能更好（减少乐观锁的重试次数）。
AtomicLong：能保证并发情况下计数的准确性，其内部通过CAS来解决并发安全性的问题。
在使用CAS+自旋的过程中，在高并发环境下，N个线程同时进行自旋操作，会出现大量失败并不断自旋的情况，此时AtomicLong的自旋会成为瓶颈。
随着并发的增加，AtomicLong性能是急剧下降的，耗时是LongAdder的数倍。
1、设计思想上，LongAdder采用"分段"的方式降低CAS失败的频次。
2、使用Contended注解来消除伪共享
3、惰性求值
看场景来使用，如果是并发不太高的系统，使用AtomicLong可能会更好一些，而且内存需求也会小一些。
而在高并发统计计数的场景下，才更适合使用LongAdder。
```
### 如何处理从线程的异常
